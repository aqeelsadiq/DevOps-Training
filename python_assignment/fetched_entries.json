{"id": "857a12cfdcd585e8b1c38883cf1462509c3fe0dc", "guidislink": false, "title": "Announcing the next generation of Amazon FSx for NetApp ONTAP file systems", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Announcing the next generation of Amazon FSx for NetApp ONTAP file systems"}, "summary": "<p>Today, we\u2019re announcing next-generation Amazon FSx for NetApp ONTAP file systems that provide higher scalability and enhanced flexibility compared to previous-generation file systems. Previous-generation file systems consisted of a single highly-available (HA) pair of file servers with up to 4 GBps of throughput. Next-gen file systems can be created or expanded with up to 12 HA pairs, allowing you to scale up to 72 GB/s of total throughput (up to 6 GBps per pair), giving you the flexibility to scale performance and storage to meet the needs of your most demanding workloads.<br /> <br /> With next-gen FSx for ONTAP file systems, a single HA pair can now deliver up to 6 GBps of throughput, providing workloads running on a single HA even more room to grow. However, customers with the most compute-intensive workloads need the higher throughput provided by a file system with multiple HA pairs. Before today, these customers could create a file system with multiple HA pairs but couldn\u2019t add HA pairs or adjust its throughput at a later time. Now, next-gen file systems allow you to add HA pairs and adjust their throughput capacity, giving you additional flexibility to optimize your workload\u2019s performance over time.<br /> <br /> Next-gen file systems are available today in the following AWS Regions: US East (N. Virginia, Ohio), US West (Oregon), Europe (Ireland), and Asia-Pacific (Sydney). You can create next-gen Multi-AZ file systems with a single HA pair, and Single-AZ file systems with up to 12 HA pairs. To learn more, visit the <a href=\"https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/what-is-fsx-ontap.html\" target=\"_blank\">FSx for ONTAP user guide</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, we\u2019re announcing next-generation Amazon FSx for NetApp ONTAP file systems that provide higher scalability and enhanced flexibility compared to previous-generation file systems. Previous-generation file systems consisted of a single highly-available (HA) pair of file servers with up to 4 GBps of throughput. Next-gen file systems can be created or expanded with up to 12 HA pairs, allowing you to scale up to 72 GB/s of total throughput (up to 6 GBps per pair), giving you the flexibility to scale performance and storage to meet the needs of your most demanding workloads.<br /> <br /> With next-gen FSx for ONTAP file systems, a single HA pair can now deliver up to 6 GBps of throughput, providing workloads running on a single HA even more room to grow. However, customers with the most compute-intensive workloads need the higher throughput provided by a file system with multiple HA pairs. Before today, these customers could create a file system with multiple HA pairs but couldn\u2019t add HA pairs or adjust its throughput at a later time. Now, next-gen file systems allow you to add HA pairs and adjust their throughput capacity, giving you additional flexibility to optimize your workload\u2019s performance over time.<br /> <br /> Next-gen file systems are available today in the following AWS Regions: US East (N. Virginia, Ohio), US West (Oregon), Europe (Ireland), and Asia-Pacific (Sydney). You can create next-gen Multi-AZ file systems with a single HA pair, and Single-AZ file systems with up to 12 HA pairs. To learn more, visit the <a href=\"https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/what-is-fsx-ontap.html\" target=\"_blank\">FSx for ONTAP user guide</a>.</p>"}, "published": "Tue, 09 Jul 2024 21:40:00 GMT", "published_parsed": [2024, 7, 9, 21, 40, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/storage,general:products/amazon-fsx-netapp-ontap", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-fsx-for-netapp-ontap-file-systems/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-fsx-for-netapp-ontap-file-systems/"}
{"id": "8166b21dcb7020dfcdb703d379ac74de2e178934", "guidislink": false, "title": "AWS Glue Data catalog now supports generating statistics for Apache Iceberg tables", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Glue Data catalog now supports generating statistics for Apache Iceberg tables"}, "summary": "<p><a href=\"https://docs.aws.amazon.com/glue/latest/dg/start-data-catalog.html\" target=\"_blank\">AWS Glue Data Catalog</a> now supports generating column-level aggregated statistics for Apache Iceberg tables. These statistics are now integrated with cost-based optimizer (CBO) from Amazon Redshift Spectrum, resulting in improved query performance and potential cost savings.<br /> <br /> Apache Iceberg support statistics such as nulls, min, max, but lacks support for generating aggregation statistics such as number of distinct values (NDV). With this launch, you now have integrated end-to-end experience where NDVs are collected on columns of Apache Iceberg table and stored in <a href=\"https://iceberg.apache.org/puffin-spec/\" target=\"_blank\">Apache Iceberg Puffin</a> files. Amazon Redshift use these aggregation statistics to optimize queries by applying the most restrictive filters as early as possible in the query processing, thereby limiting memory usage and the number of records read to provide the query results.<br /> <br /> To get started, you can generate statistics for an Apache Iceberg table using AWS Glue Console or AWS Glue APIs. With each run, Glue Catalog will compute statistics for current Iceberg table snapshot, store in an Iceberg puffin file and Glue Catalog. As you run queries from <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/c-getting-started-using-spectrum.html\" target=\"_blank\">Amazon Redshift Spectrum</a>, you will automatically get the query performance improvements with built-in integration with Apache Iceberg.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://docs.aws.amazon.com/glue/latest/dg/start-data-catalog.html\" target=\"_blank\">AWS Glue Data Catalog</a> now supports generating column-level aggregated statistics for Apache Iceberg tables. These statistics are now integrated with cost-based optimizer (CBO) from Amazon Redshift Spectrum, resulting in improved query performance and potential cost savings.<br /> <br /> Apache Iceberg support statistics such as nulls, min, max, but lacks support for generating aggregation statistics such as number of distinct values (NDV). With this launch, you now have integrated end-to-end experience where NDVs are collected on columns of Apache Iceberg table and stored in <a href=\"https://iceberg.apache.org/puffin-spec/\" target=\"_blank\">Apache Iceberg Puffin</a> files. Amazon Redshift use these aggregation statistics to optimize queries by applying the most restrictive filters as early as possible in the query processing, thereby limiting memory usage and the number of records read to provide the query results.<br /> <br /> To get started, you can generate statistics for an Apache Iceberg table using AWS Glue Console or AWS Glue APIs. With each run, Glue Catalog will compute statistics for current Iceberg table snapshot, store in an Iceberg puffin file and Glue Catalog. As you run queries from <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/c-getting-started-using-spectrum.html\" target=\"_blank\">Amazon Redshift Spectrum</a>, you will automatically get the query performance improvements with built-in integration with Apache Iceberg.</p>"}, "published": "Tue, 09 Jul 2024 21:40:00 GMT", "published_parsed": [2024, 7, 9, 21, 40, 0, 1, 191, 0], "tags": [{"term": "general:products/aws-lake-formation,marketing:marchitecture/analytics,general:products/aws-glue", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-glue-data-catalog-generating-statistics-apache-iceberg-tables"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-glue-data-catalog-generating-statistics-apache-iceberg-tables"}
{"id": "1142ca12cca15b4beb463f1a1d99a9a09e627d06", "guidislink": false, "title": "Amazon FSx for NetApp ONTAP now allows you to read data during backup restores", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon FSx for NetApp ONTAP now allows you to read data during backup restores"}, "summary": "<p>Amazon FSx for NetApp ONTAP, a fully managed shared storage service built on NetApp\u2019s popular ONTAP file system, now allows you to read data from a volume while it is being restored from a backup. The feature \u201cread-access during backup restores\u201d allows you to improve Recovery Time Objectives by up to 17x for read-only workloads that rely on backup restores for business continuity, such as media streaming and compliance verification.<br /> <br /> You can restore an FSx for ONTAP backup into a new volume at any time. Before today, when you restored a backup, Amazon FSx provided read-write access to data once the backup was fully downloaded onto the volume. The restore process typically took minutes to hours\u2014depending on the backup size. Starting today, Amazon FSx enables read access to data within minutes of initiating a restore, enabling you to browse through your backup and retrieve critical data to resume operations faster in the event of accidental data modification or deletion. The volume becomes writable automatically once data has been fully restored. Now, you can reduce time to recover media streaming applications when the primary volume becomes unavailable by serving reads from a volume being restored, and compliance teams can initiate audits sooner by accessing data without waiting for the restore to complete.<br /> <br /> This feature is available on all new and existing FSx for ONTAP second-generation file systems in all <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\"><u>AWS Regions</u></a> where FSx for ONTAP second-generation file systems are available. See the <a href=\"https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/what-is-fsx-ontap.html\" target=\"_blank\"><u>FSx for ONTAP product documentation</u></a> for more details.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon FSx for NetApp ONTAP, a fully managed shared storage service built on NetApp\u2019s popular ONTAP file system, now allows you to read data from a volume while it is being restored from a backup. The feature \u201cread-access during backup restores\u201d allows you to improve Recovery Time Objectives by up to 17x for read-only workloads that rely on backup restores for business continuity, such as media streaming and compliance verification.<br /> <br /> You can restore an FSx for ONTAP backup into a new volume at any time. Before today, when you restored a backup, Amazon FSx provided read-write access to data once the backup was fully downloaded onto the volume. The restore process typically took minutes to hours\u2014depending on the backup size. Starting today, Amazon FSx enables read access to data within minutes of initiating a restore, enabling you to browse through your backup and retrieve critical data to resume operations faster in the event of accidental data modification or deletion. The volume becomes writable automatically once data has been fully restored. Now, you can reduce time to recover media streaming applications when the primary volume becomes unavailable by serving reads from a volume being restored, and compliance teams can initiate audits sooner by accessing data without waiting for the restore to complete.<br /> <br /> This feature is available on all new and existing FSx for ONTAP second-generation file systems in all <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\"><u>AWS Regions</u></a> where FSx for ONTAP second-generation file systems are available. See the <a href=\"https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/what-is-fsx-ontap.html\" target=\"_blank\"><u>FSx for ONTAP product documentation</u></a> for more details.</p>"}, "published": "Tue, 09 Jul 2024 21:40:00 GMT", "published_parsed": [2024, 7, 9, 21, 40, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/storage,general:products/amazon-fsx-netapp-ontap", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-fsx-netapp-ontap-read-data-backup-restores"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-fsx-netapp-ontap-read-data-backup-restores"}
{"id": "d0531eb2ebc41c3a33aa19ee027b071c9cc1e80a", "guidislink": false, "title": "Amazon FSx for NetApp ONTAP now supports NVMe-over-TCP for simpler, lower-latency shared block storage", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon FSx for NetApp ONTAP now supports NVMe-over-TCP for simpler, lower-latency shared block storage"}, "summary": "<p>Amazon FSx for NetApp ONTAP, a service that provides fully managed shared storage built on NetApp\u2019s popular ONTAP file system, today announced support for the NVMe-over-TCP (NVMe/TCP) block storage protocol. Using NVMe/TCP, you can accelerate your block storage workloads such as databases and Virtual Desktop Infrastructure (VDI) with lower latency compared to traditional iSCSI block storage, and simplify multi-path IO (MPIO) configuration relative to iSCSI.<br /> <br /> FSx for ONTAP provides you with multi-protocol access to fully managed shared storage, including the iSCSI protocol for deploying applications such as databases and VDI that rely on shared block storage. NVMe/TCP is an implementation of the NVMe protocol that transports data over TCP using traditional Ethernet as a fabric. With this launch, you have the option of using NVMe/TCP to provide shared block storage for these applications in order to take advantage of NVMe/TCP\u2019s lower latency and simplified setup.<br /> <br /> NVMe/TCP is available on all second-generation Amazon FSx for ONTAP file systems in all AWS Regions where they\u2019re available. To learn more, visit the <a href=\"https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/what-is-fsx-ontap.html\" target=\"_blank\">FSx for ONTAP user guide</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon FSx for NetApp ONTAP, a service that provides fully managed shared storage built on NetApp\u2019s popular ONTAP file system, today announced support for the NVMe-over-TCP (NVMe/TCP) block storage protocol. Using NVMe/TCP, you can accelerate your block storage workloads such as databases and Virtual Desktop Infrastructure (VDI) with lower latency compared to traditional iSCSI block storage, and simplify multi-path IO (MPIO) configuration relative to iSCSI.<br /> <br /> FSx for ONTAP provides you with multi-protocol access to fully managed shared storage, including the iSCSI protocol for deploying applications such as databases and VDI that rely on shared block storage. NVMe/TCP is an implementation of the NVMe protocol that transports data over TCP using traditional Ethernet as a fabric. With this launch, you have the option of using NVMe/TCP to provide shared block storage for these applications in order to take advantage of NVMe/TCP\u2019s lower latency and simplified setup.<br /> <br /> NVMe/TCP is available on all second-generation Amazon FSx for ONTAP file systems in all AWS Regions where they\u2019re available. To learn more, visit the <a href=\"https://docs.aws.amazon.com/fsx/latest/ONTAPGuide/what-is-fsx-ontap.html\" target=\"_blank\">FSx for ONTAP user guide</a>.</p>"}, "published": "Tue, 09 Jul 2024 21:40:00 GMT", "published_parsed": [2024, 7, 9, 21, 40, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/storage,general:products/amazon-fsx-netapp-ontap", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-fsx-netapp-ontap-nvme-over-tcp"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-fsx-netapp-ontap-nvme-over-tcp"}
{"id": "b3e298bc481f0234071b75f7f453ccf9fcae2ca0", "guidislink": false, "title": "Amazon SageMaker introduces a new generative AI inference optimization capability", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon SageMaker introduces a new generative AI inference optimization capability"}, "summary": "<p>Today, Amazon SageMaker announced general availability of a new inference capability that delivers up to ~2x higher throughput while reducing costs by up to ~50% for generative AI models such as Llama 3, Mistral, and Mixtral models. For example, with a Llama 3-70B model, you can achieve up to ~2400 tokens/sec on a ml.p5.48xlarge instance v/s ~1200 tokens/sec previously without any optimization.<br /> <br /> With this new capability, customers can choose from a menu of the latest model optimization techniques, such as speculative decoding, quantization, and compilation, and apply them to their generative AI models. SageMaker will do the heavy lifting of provisioning required hardware to run the optimization recipe, along with deep learning frameworks and libraries. Customers get out-of-the-box support for a speculative decoding solution from SageMaker that has been tested for performance at scale for various popular open source models, or they can bring their own speculative decoding solution. For quantization, SageMaker ensures compatibility and support for precision types on different model architectures. For compilation, the runtime infrastructure of SageMaker ensures efficient loading and caching of optimized models to reduce auto-scaling time.<br /> <br /> Customers can leverage this new capability from AWS SDK for Python (Boto3), SageMaker Python SDK, or the AWS Command Line Interface (AWS CLI). This capability is now generally available in the US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), Europe (Stockholm), and South America (Sao Paulo) Regions.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, Amazon SageMaker announced general availability of a new inference capability that delivers up to ~2x higher throughput while reducing costs by up to ~50% for generative AI models such as Llama 3, Mistral, and Mixtral models. For example, with a Llama 3-70B model, you can achieve up to ~2400 tokens/sec on a ml.p5.48xlarge instance v/s ~1200 tokens/sec previously without any optimization.<br /> <br /> With this new capability, customers can choose from a menu of the latest model optimization techniques, such as speculative decoding, quantization, and compilation, and apply them to their generative AI models. SageMaker will do the heavy lifting of provisioning required hardware to run the optimization recipe, along with deep learning frameworks and libraries. Customers get out-of-the-box support for a speculative decoding solution from SageMaker that has been tested for performance at scale for various popular open source models, or they can bring their own speculative decoding solution. For quantization, SageMaker ensures compatibility and support for precision types on different model architectures. For compilation, the runtime infrastructure of SageMaker ensures efficient loading and caching of optimized models to reduce auto-scaling time.<br /> <br /> Customers can leverage this new capability from AWS SDK for Python (Boto3), SageMaker Python SDK, or the AWS Command Line Interface (AWS CLI). This capability is now generally available in the US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), Europe (Stockholm), and South America (Sao Paulo) Regions.</p>"}, "published": "Tue, 09 Jul 2024 21:40:00 GMT", "published_parsed": [2024, 7, 9, 21, 40, 0, 1, 191, 0], "tags": [{"term": "general:products/amazon-sagemaker,marketing:marchitecture/artificial-intelligence", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-sagamaker-generative-ai-inference-optimization-capability"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-sagamaker-generative-ai-inference-optimization-capability"}
{"id": "26d0a61c6cdbd62b9475623431c4c80c132b36be", "guidislink": false, "title": "AWS Glue Studio now offers a no code data preparation authoring experience", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Glue Studio now offers a no code data preparation authoring experience"}, "summary": "<p>Today, AWS Glue Studio Visual ETL announces general availability of data preparation authoring, a new no code data preparation user experience for business users and data analysts with a spreadsheet-style UI that runs data integration jobs at scale on AWS Glue for Spark. The new visual data preparation experience makes it easier for data analysts and data scientists to clean and transform data to prepare it for analytics and machine learning (ML). Within this new experience, you can choose from hundreds of prebuilt transformations to automate data preparation tasks, all without the need to write any code.<br /> <br /> Business analysts can now collaborate with data engineers to build data integration jobs. Data engineers can use Glue Studio Visual flow-based view to define connections to the data and set the ordering of the data flow process, while business analysts can use the data preparation experience to define the data transformation and output. Additionally, DataBrew customers can import their existing data cleansing and preparation \u201crecipes\u201d to the new AWS Glue data preparation experience and continue to author them directly in AWS Glue Studio and scale up recipes to process petabytes of data, and at the <a href=\"https://aws.amazon.com/glue/pricing/\" target=\"_blank\">lower price point for AWS Glue jobs</a>.<br /> <br /> The feature is available in <a href=\"https://docs.aws.amazon.com/general/latest/gr/databrew.html\" target=\"_blank\">all commercial AWS Regions where AWS Glue DataBrew is available</a>. To learn more, refer to the <a href=\"https://docs.aws.amazon.com/glue/latest/dg/glue-studio-data-preparation.html\">documentation</a> and read the <a href=\"https://aws.amazon.com/blogs/aws/integrate-your-data-and-collaborate-using-data-preparation-in-aws-glue-studio/\" target=\"_blank\">blog post</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, AWS Glue Studio Visual ETL announces general availability of data preparation authoring, a new no code data preparation user experience for business users and data analysts with a spreadsheet-style UI that runs data integration jobs at scale on AWS Glue for Spark. The new visual data preparation experience makes it easier for data analysts and data scientists to clean and transform data to prepare it for analytics and machine learning (ML). Within this new experience, you can choose from hundreds of prebuilt transformations to automate data preparation tasks, all without the need to write any code.<br /> <br /> Business analysts can now collaborate with data engineers to build data integration jobs. Data engineers can use Glue Studio Visual flow-based view to define connections to the data and set the ordering of the data flow process, while business analysts can use the data preparation experience to define the data transformation and output. Additionally, DataBrew customers can import their existing data cleansing and preparation \u201crecipes\u201d to the new AWS Glue data preparation experience and continue to author them directly in AWS Glue Studio and scale up recipes to process petabytes of data, and at the <a href=\"https://aws.amazon.com/glue/pricing/\" target=\"_blank\">lower price point for AWS Glue jobs</a>.<br /> <br /> The feature is available in <a href=\"https://docs.aws.amazon.com/general/latest/gr/databrew.html\" target=\"_blank\">all commercial AWS Regions where AWS Glue DataBrew is available</a>. To learn more, refer to the <a href=\"https://docs.aws.amazon.com/glue/latest/dg/glue-studio-data-preparation.html\">documentation</a> and read the <a href=\"https://aws.amazon.com/blogs/aws/integrate-your-data-and-collaborate-using-data-preparation-in-aws-glue-studio/\" target=\"_blank\">blog post</a>.</p>"}, "published": "Tue, 09 Jul 2024 21:40:00 GMT", "published_parsed": [2024, 7, 9, 21, 40, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/analytics,general:products/aws-glue", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-glue-studio-no-code-data-preparation-authoring-experience"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-glue-studio-no-code-data-preparation-authoring-experience"}
{"id": "49a7e7e1af3dad7bd068cd9cf036d8077db13c26", "guidislink": false, "title": "Amazon RDS Data API for Aurora PostgreSQL is now available in 10 additional AWS regions", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon RDS Data API for Aurora PostgreSQL is now available in 10 additional AWS regions"}, "summary": "<p><a href=\"https://aws.amazon.com/rds/aurora/features/#:~:text=Secrets%20Manager.-,Data%20API,-Data%20API%20is\" target=\"_blank\">RDS Data API</a> for Aurora Serverless v2 and Aurora provisioned PostgreSQL-Compatible database instances is now available in Asia Pacific (Sydney), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Singapore), Europe (Ireland), Europe (London), Europe (Paris), US West (N. California), US East (Ohio), Canada (Central). RDS Data API allows you to access these Aurora clusters via a secure HTTP endpoint and run SQL statements without the use of database drivers and without managing connections.<br /> <br /> Data API eliminates the use of drivers and improves application scalability by automatically pooling and sharing database connections (connection pooling) rather than requiring customers to manage connections. Customers can call Data API via AWS SDK and CLI. Data API also enables access to Aurora databases via AWS AppSync GraphQL APIs. API commands supported in the Data API for Aurora Serverless v2 and Aurora provisioned are backwards compatible with Data API for Aurora Serverless v1 for easy customer application migrations.<br /> <br /> Data API supports Aurora PostgreSQL 15.3, 14.8, 13.11 and higher versions. Customers currently using Data API for ASv1 are encouraged to migrate to ASv2 to take advantage of the new Data API. To learn more, read the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html\" target=\"_blank\">documentation</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://aws.amazon.com/rds/aurora/features/#:~:text=Secrets%20Manager.-,Data%20API,-Data%20API%20is\" target=\"_blank\">RDS Data API</a> for Aurora Serverless v2 and Aurora provisioned PostgreSQL-Compatible database instances is now available in Asia Pacific (Sydney), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Singapore), Europe (Ireland), Europe (London), Europe (Paris), US West (N. California), US East (Ohio), Canada (Central). RDS Data API allows you to access these Aurora clusters via a secure HTTP endpoint and run SQL statements without the use of database drivers and without managing connections.<br /> <br /> Data API eliminates the use of drivers and improves application scalability by automatically pooling and sharing database connections (connection pooling) rather than requiring customers to manage connections. Customers can call Data API via AWS SDK and CLI. Data API also enables access to Aurora databases via AWS AppSync GraphQL APIs. API commands supported in the Data API for Aurora Serverless v2 and Aurora provisioned are backwards compatible with Data API for Aurora Serverless v1 for easy customer application migrations.<br /> <br /> Data API supports Aurora PostgreSQL 15.3, 14.8, 13.11 and higher versions. Customers currently using Data API for ASv1 are encouraged to migrate to ASv2 to take advantage of the new Data API. To learn more, read the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html\" target=\"_blank\">documentation</a>.</p>"}, "published": "Tue, 09 Jul 2024 21:30:00 GMT", "published_parsed": [2024, 7, 9, 21, 30, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/databases,general:products/amazon-rds", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-rds-data-api-aurora-postgresql-additional-regions"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-rds-data-api-aurora-postgresql-additional-regions"}
{"id": "d70e1fd97c2ceb89f7527453963183912d41f6c9", "guidislink": false, "title": "Amazon MWAA now supports Apache Airflow version 2.9", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon MWAA now supports Apache Airflow version 2.9"}, "summary": "<p>You can now create Apache Airflow version 2.9 environments on Amazon Managed Workflows for Apache Airflow (MWAA). Apache Airflow 2.9 is the latest minor release of the popular open-source tool that helps customers author, schedule, and monitor workflows.<br /> <br /> Amazon MWAA is a managed orchestration service for Apache Airflow that makes it easier to set up and operate end-to-end data pipelines in the cloud. Apache Airflow 2.9 introduces several notable enhancements, such as new API endpoints for improved dataset management, custom names in dynamic task mapping for better readability, and advanced scheduling options including conditional expressions for dataset dependencies and the combination of dataset and time-based schedules.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>You can now create Apache Airflow version 2.9 environments on Amazon Managed Workflows for Apache Airflow (MWAA). Apache Airflow 2.9 is the latest minor release of the popular open-source tool that helps customers author, schedule, and monitor workflows.<br /> <br /> Amazon MWAA is a managed orchestration service for Apache Airflow that makes it easier to set up and operate end-to-end data pipelines in the cloud. Apache Airflow 2.9 introduces several notable enhancements, such as new API endpoints for improved dataset management, custom names in dynamic task mapping for better readability, and advanced scheduling options including conditional expressions for dataset dependencies and the combination of dataset and time-based schedules.</p>"}, "published": "Tue, 09 Jul 2024 20:20:00 GMT", "published_parsed": [2024, 7, 9, 20, 20, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/analytics,general:products/amazon-mwaa,marketing:marchitecture/application-services", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-mwaa-apache-airflow-version-2-9"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-mwaa-apache-airflow-version-2-9"}
{"id": "9f4e77694f0c503864f42c42e41bcabbd04aea57", "guidislink": false, "title": "Amazon EC2 R8g instances powered by AWS Graviton4 now generally available", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon EC2 R8g instances powered by AWS Graviton4 now generally available"}, "summary": "<p>AWS announces the general availability of Amazon Elastic Compute Cloud (Amazon EC2) R8g instances. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances.&nbsp;Amazon EC2 R8g instances are ideal for memory-intensive workloads such as databases, in-memory caches, and real-time big data analytics. These instances are built on the <a href=\"https://aws.amazon.com/ec2/nitro/\" style=\"color: #0563c1; text-decoration: underline;\" target=\"_blank\">AWS Nitro System</a>, which o\ufb04oads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.</p> \n<p>AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. AWS Graviton4-based R8g instances offer larger instance sizes with up to 3x more vCPU (up to 48xlarge) and memory (up to 1.5TB) than Graviton3-based R7g instances. These instances&nbsp;are up to 30% faster for web applications, 40% faster for databases, and 45% faster for large Java applications compared to AWS Graviton3-based R7g instances.&nbsp;R8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS). Elastic Fabric Adapter (EFA) networking support is offered on 24xlarge, 48xlarge, and bare metal sizes, and&nbsp;Elastic Network Adapter (ENA) Express support is available on instance sizes larger than 12xlarge.&nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS announces the general availability of Amazon Elastic Compute Cloud (Amazon EC2) R8g instances. These instances are powered by AWS Graviton4 processors and deliver up to 30% better performance compared to AWS Graviton3-based instances.&nbsp;Amazon EC2 R8g instances are ideal for memory-intensive workloads such as databases, in-memory caches, and real-time big data analytics. These instances are built on the <a href=\"https://aws.amazon.com/ec2/nitro/\" style=\"color: #0563c1; text-decoration: underline;\" target=\"_blank\">AWS Nitro System</a>, which o\ufb04oads CPU virtualization, storage, and networking functions to dedicated hardware and software to enhance the performance and security of your workloads.</p> \n<p>AWS Graviton4-based Amazon EC2 instances deliver the best performance and energy efficiency for a broad range of workloads running on Amazon EC2. AWS Graviton4-based R8g instances offer larger instance sizes with up to 3x more vCPU (up to 48xlarge) and memory (up to 1.5TB) than Graviton3-based R7g instances. These instances&nbsp;are up to 30% faster for web applications, 40% faster for databases, and 45% faster for large Java applications compared to AWS Graviton3-based R7g instances.&nbsp;R8g instances are available in 12 different instance sizes, including two bare metal sizes. They offer up to 50 Gbps enhanced networking bandwidth and up to 40 Gbps of bandwidth to the Amazon Elastic Block Store (Amazon EBS). Elastic Fabric Adapter (EFA) networking support is offered on 24xlarge, 48xlarge, and bare metal sizes, and&nbsp;Elastic Network Adapter (ENA) Express support is available on instance sizes larger than 12xlarge.&nbsp;</p>"}, "published": "Tue, 09 Jul 2024 19:30:00 GMT", "published_parsed": [2024, 7, 9, 19, 30, 0, 1, 191, 0], "tags": [{"term": "general:products/amazon-ec2,marketing:marchitecture/compute", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-ec2-r8g-instances-aws-graviton4-generally-available"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-ec2-r8g-instances-aws-graviton4-generally-available"}
{"id": "786fe18af652272a4afb82206198400e8aaee8f4", "guidislink": false, "title": "Amazon OpenSearch Service announces Natural Language Query Generation for log analysis", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon OpenSearch Service announces Natural Language Query Generation for log analysis"}, "summary": "<p>Amazon OpenSearch Service has added support for AI powered Natural Language Query Generation in OpenSearch Dashboards Log Explorer. With Natural Language Query Generation, you can accelerate analysis by asking log exploration questions in plain English, which are then automatically translated to the relevant <a href=\"https://opensearch.org/docs/latest/search-plugins/sql/ppl/index/\" target=\"_blank\">Piped Processing Language </a>(PPL) queries and executed to fetch the requested data.<br /> <br /> With this new natural language support, you can get started quickly with log analysis without first having to be proficient in PPL. Further, it opens up log analysis to a wider set of team members who can simply explore their log data by asking questions like - \u201cshow me the count of 5xx errors for each of the pages on my website\u201d or \u201cshow me the throughput by hosts\u201d. This also helps advanced users in constructing complex queries by allowing for iterative refinement of both the natural language questions and the generated PPL.<br /> <br /> This feature is available at no cost for customers running managed clusters with OpenSearch 2.13 or above in US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), China (Beijing), China (Ningxia), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), Europe (Stockholm), South America (S\u00e3o Paulo), AWS GovCloud (US-East), and AWS GovCloud (US-West).</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon OpenSearch Service has added support for AI powered Natural Language Query Generation in OpenSearch Dashboards Log Explorer. With Natural Language Query Generation, you can accelerate analysis by asking log exploration questions in plain English, which are then automatically translated to the relevant <a href=\"https://opensearch.org/docs/latest/search-plugins/sql/ppl/index/\" target=\"_blank\">Piped Processing Language </a>(PPL) queries and executed to fetch the requested data.<br /> <br /> With this new natural language support, you can get started quickly with log analysis without first having to be proficient in PPL. Further, it opens up log analysis to a wider set of team members who can simply explore their log data by asking questions like - \u201cshow me the count of 5xx errors for each of the pages on my website\u201d or \u201cshow me the throughput by hosts\u201d. This also helps advanced users in constructing complex queries by allowing for iterative refinement of both the natural language questions and the generated PPL.<br /> <br /> This feature is available at no cost for customers running managed clusters with OpenSearch 2.13 or above in US East (N. Virginia), US East (Ohio), US West (N. California), US West (Oregon), Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Canada (Central), China (Beijing), China (Ningxia), Europe (Frankfurt), Europe (Ireland), Europe (London), Europe (Paris), Europe (Stockholm), South America (S\u00e3o Paulo), AWS GovCloud (US-East), and AWS GovCloud (US-West).</p>"}, "published": "Tue, 09 Jul 2024 18:20:00 GMT", "published_parsed": [2024, 7, 9, 18, 20, 0, 1, 191, 0], "tags": [{"term": "general:products/aws-govcloud-us,marketing:marchitecture/analytics,general:products/amazon-opensearch-service,marketing:marchitecture/artificial-intelligence", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-opensearch-service-natural-language-query-generation"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-opensearch-service-natural-language-query-generation"}
{"id": "9ee916263693321d24561cc0eacb13956a55526b", "guidislink": false, "title": "AWS Partner Central now supports multi-factor authentication", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Partner Central now supports multi-factor authentication"}, "summary": "<p>AWS Partner Central now supports multi-factor authentication (MFA) capabilities at login. Users will be prompted to enter a one-time passcode sent to their registered e-mail address along with login credentials to confirm their identify.<br /> <br /> MFA adds an additional layer of protection, reducing the risk of unauthorized access to AWS Partner Central. Additionally, it ensures only active users are able to access AWS Partner Central, as the registered email address must be accessible. AWS Partners will be automatically enrolled in MFA, but alliance leads and cloud admins have the ability to disable the feature if desired for all AWS Partner Central users.<br /> <br /> To learn more, visit the <a href=\"http://docs.aws.amazon.com/partner-central/latest/getting-started/mfa.html\" target=\"_blank\">AWS Partner Central Getting Started Guide</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS Partner Central now supports multi-factor authentication (MFA) capabilities at login. Users will be prompted to enter a one-time passcode sent to their registered e-mail address along with login credentials to confirm their identify.<br /> <br /> MFA adds an additional layer of protection, reducing the risk of unauthorized access to AWS Partner Central. Additionally, it ensures only active users are able to access AWS Partner Central, as the registered email address must be accessible. AWS Partners will be automatically enrolled in MFA, but alliance leads and cloud admins have the ability to disable the feature if desired for all AWS Partner Central users.<br /> <br /> To learn more, visit the <a href=\"http://docs.aws.amazon.com/partner-central/latest/getting-started/mfa.html\" target=\"_blank\">AWS Partner Central Getting Started Guide</a>.</p>"}, "published": "Tue, 09 Jul 2024 18:15:00 GMT", "published_parsed": [2024, 7, 9, 18, 15, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/partner-network,marketing:marchitecture/aws-marketplace-and-partners", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-partner-central-multi-factor-authentication"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-partner-central-multi-factor-authentication"}
{"id": "3c06693c905713c260e79110d6bbcd4a25a6821f", "guidislink": false, "title": "Simplified service terms for AWS Marketplace sellers", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Simplified service terms for AWS Marketplace sellers"}, "summary": "<p>AWS Partners can now register as sellers in AWS Marketplace with a simplified one-click experience. We have removed the need for AWS partners to review and accept a separate set of terms to sell in AWS Marketplace by including AWS Marketplace Terms into AWS service terms. Instead, partners simply sign in to their AWS account and click to register as an AWS Marketplace seller in the <a href=\"https://aws.amazon.com/marketplace/management/seller-settings/register\" target=\"_blank\">AWS Marketplace management portal</a>.<br /> <br /> AWS Partners such as independent software vendors (ISVs), data providers, and consulting partners can sell their software, services, and data in AWS Marketplace to AWS customers. AWS Marketplace, jointly with <a href=\"https://aws.amazon.com/partners/isv/\" target=\"_blank\">AWS Partner Network (APN)</a>, helps ISVs and consulting partners to build, market, and sell their AWS offerings by providing valuable business, technical, and marketing support. AWS Marketplace is available to customers globally. Partners can discover the benefits of becoming an AWS Marketplace seller and <a href=\"https://aws.amazon.com/marketplace/partners/management-tour?ref_=header_modules_sell_in_aws\" target=\"_blank\">get started</a> on their AWS Marketplace journey.<br /> <br /> To learn more, review the <a href=\"https://aws.amazon.com/legal/seller-terms/\" target=\"_blank\">new simplified Terms</a> for selling in AWS Marketplace.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS Partners can now register as sellers in AWS Marketplace with a simplified one-click experience. We have removed the need for AWS partners to review and accept a separate set of terms to sell in AWS Marketplace by including AWS Marketplace Terms into AWS service terms. Instead, partners simply sign in to their AWS account and click to register as an AWS Marketplace seller in the <a href=\"https://aws.amazon.com/marketplace/management/seller-settings/register\" target=\"_blank\">AWS Marketplace management portal</a>.<br /> <br /> AWS Partners such as independent software vendors (ISVs), data providers, and consulting partners can sell their software, services, and data in AWS Marketplace to AWS customers. AWS Marketplace, jointly with <a href=\"https://aws.amazon.com/partners/isv/\" target=\"_blank\">AWS Partner Network (APN)</a>, helps ISVs and consulting partners to build, market, and sell their AWS offerings by providing valuable business, technical, and marketing support. AWS Marketplace is available to customers globally. Partners can discover the benefits of becoming an AWS Marketplace seller and <a href=\"https://aws.amazon.com/marketplace/partners/management-tour?ref_=header_modules_sell_in_aws\" target=\"_blank\">get started</a> on their AWS Marketplace journey.<br /> <br /> To learn more, review the <a href=\"https://aws.amazon.com/legal/seller-terms/\" target=\"_blank\">new simplified Terms</a> for selling in AWS Marketplace.</p>"}, "published": "Tue, 09 Jul 2024 17:30:00 GMT", "published_parsed": [2024, 7, 9, 17, 30, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/aws-marketplace-and-partners,general:products/aws-marketplace,marketing:marchitecture/partner-network,general:products/aws-govcloud-us", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/simplified-service-terms-aws-marketplace-sellers"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/simplified-service-terms-aws-marketplace-sellers"}
{"id": "255e220dcdbeb31b12b58b42710d32dead3caa0d", "guidislink": false, "title": "Amazon EventBridge Schema Registry now supports AWS PrivateLink VPC endpoints", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon EventBridge Schema Registry now supports AWS PrivateLink VPC endpoints"}, "summary": "<p>Amazon EventBridge Schema Registry now supports <a href=\"https://aws.amazon.com/privatelink/\" target=\"_blank\">AWS PrivateLink</a>, allowing you to access the registry from within your Amazon Virtual Private Cloud (VPC) without traversing the public internet. With today\u2019s launch, you can leverage EventBridge Schema Registry features from a private subnet without the need to deploy an internet gateway, configure firewall rules, or set up proxy servers.<br /> <br /> Amazon EventBridge lets you use events to connect application components, making it easier to build scalable event-driven applications. EventBridge Schema Registry allows you to centrally store schemas, representing the structure of your events, so other teams can discover and consume them. You can add schemas to the registry yourself or use the Schema Discovery feature to capture the schemas of events sent to an EventBridge Event Bus. Once schemas are in your registry, you can download code bindings for those schemas in Java, Python, TypeScript, and Golang and use them in your preferred Integrated Development Environment (IDE) to take advantage of IDE features such as code validation and auto-completion.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon EventBridge Schema Registry now supports <a href=\"https://aws.amazon.com/privatelink/\" target=\"_blank\">AWS PrivateLink</a>, allowing you to access the registry from within your Amazon Virtual Private Cloud (VPC) without traversing the public internet. With today\u2019s launch, you can leverage EventBridge Schema Registry features from a private subnet without the need to deploy an internet gateway, configure firewall rules, or set up proxy servers.<br /> <br /> Amazon EventBridge lets you use events to connect application components, making it easier to build scalable event-driven applications. EventBridge Schema Registry allows you to centrally store schemas, representing the structure of your events, so other teams can discover and consume them. You can add schemas to the registry yourself or use the Schema Discovery feature to capture the schemas of events sent to an EventBridge Event Bus. Once schemas are in your registry, you can download code bindings for those schemas in Java, Python, TypeScript, and Golang and use them in your preferred Integrated Development Environment (IDE) to take advantage of IDE features such as code validation and auto-completion.</p>"}, "published": "Tue, 09 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 9, 17, 0, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/application-services,general:products/amazon-eventBridge,general:products/aws-privatelink,marketing:marchitecture/serverless", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-eventbridge-schema-registry-privatelink-vpc-endpoints"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-eventbridge-schema-registry-privatelink-vpc-endpoints"}
{"id": "289084e0dd3878ff37eb3158bd10517a6de205a2", "guidislink": false, "title": "Amazon FSx for OpenZFS introduces a highly available Single-AZ deployment option", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon FSx for OpenZFS introduces a highly available Single-AZ deployment option"}, "summary": "<p>Amazon FSx for OpenZFS now supports highly available (HA) Single-AZ deployments, offering high availability and consistent sub-millisecond latencies for use cases like data analytics, machine learning, and semiconductor chip design that can benefit from high availability but do not require multi-zone resiliency. Single-AZ HA file systems provide a lower-latency and lower-cost storage option than Multi-AZ file systems for these use cases, while offering all the same data management capabilities and features.<br /> <br /> Before today, FSx for OpenZFS offered Single-AZ non-HA file systems, which provide sub-millisecond read and write latencies, and Multi-AZ file systems, which provide high availability and durability by replicating data synchronously across AZs. With Single-AZ HA file systems, customers can now achieve both high availability and consistent sub-millisecond latencies at a lower cost relative to Multi-AZ file systems for workloads such as data analytics, machine learning, and semiconductor chip design that do not need multi-zone resiliency because they're operating on a secondary copy of the data or data that can be regenerated.<br /> <br /> You can create Single-AZ HA file systems in the following AWS regions: US East (Ohio, N. Virginia), US West (N. California, Oregon), Asia Pacific (Hong Kong, Mumbai, Seoul, Singapore, Sydney, Tokyo), Canada (Central), Europe (Frankfurt, Ireland, London, Stockholm), Middle East (Bahrain). To learn more about Single-AZ HA file systems, please visit <a href=\"https://docs.aws.amazon.com/fsx/latest/OpenZFSGuide/what-is-fsx.html\" target=\"_blank\">FSx for OpenZFS documentation</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon FSx for OpenZFS now supports highly available (HA) Single-AZ deployments, offering high availability and consistent sub-millisecond latencies for use cases like data analytics, machine learning, and semiconductor chip design that can benefit from high availability but do not require multi-zone resiliency. Single-AZ HA file systems provide a lower-latency and lower-cost storage option than Multi-AZ file systems for these use cases, while offering all the same data management capabilities and features.<br /> <br /> Before today, FSx for OpenZFS offered Single-AZ non-HA file systems, which provide sub-millisecond read and write latencies, and Multi-AZ file systems, which provide high availability and durability by replicating data synchronously across AZs. With Single-AZ HA file systems, customers can now achieve both high availability and consistent sub-millisecond latencies at a lower cost relative to Multi-AZ file systems for workloads such as data analytics, machine learning, and semiconductor chip design that do not need multi-zone resiliency because they're operating on a secondary copy of the data or data that can be regenerated.<br /> <br /> You can create Single-AZ HA file systems in the following AWS regions: US East (Ohio, N. Virginia), US West (N. California, Oregon), Asia Pacific (Hong Kong, Mumbai, Seoul, Singapore, Sydney, Tokyo), Canada (Central), Europe (Frankfurt, Ireland, London, Stockholm), Middle East (Bahrain). To learn more about Single-AZ HA file systems, please visit <a href=\"https://docs.aws.amazon.com/fsx/latest/OpenZFSGuide/what-is-fsx.html\" target=\"_blank\">FSx for OpenZFS documentation</a>.</p>"}, "published": "Tue, 09 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 9, 17, 0, 0, 1, 191, 0], "tags": [{"term": "general:products/amazon-fsx-for-openzfs,marketing:marchitecture/storage", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-fsx-openzfs-single-az-deployment-option"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-fsx-openzfs-single-az-deployment-option"}
{"id": "71ea6dd71e9f3778df5a30d3f3c5267393cbcf70", "guidislink": false, "title": "Amazon Q Business now provides responses that are personalized to users", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Q Business now provides responses that are personalized to users"}, "summary": "<p>Amazon Q is excited to announce personalization capabilities in <a href=\"https://aws.amazon.com/q/business/\" target=\"_blank\">Q Business</a>, that help customers further increase employee productivity by considering their user profile to provide more useful responses. Q uses information such as an employee\u2019s location, department and role to improve the relevance of responses.<br /> <br /> Q Business\u2019 personalization capabilities are automatically enabled and will use your enterprise\u2019s employee profile data to improve their user experience, with no additional set-up needed. Q receives employee profile information from your organization\u2019s identity provider that you have connected to <a href=\"https://aws.amazon.com/iam/identity-center/\" target=\"_blank\">AWS IAM Identity Center</a>.<br /> <br /> Amazon Q Business revolutionizes the way that employees interact with organizational knowledge and enterprise systems. It helps users get comprehensive answers to complex questions and take actions in a unified, intuitive web-based chat experience\u2014all using an enterprise\u2019s existing content, data, and systems. Personalization capability is available in all <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regions</a> where Q Business is available. For more information, see <a href=\"https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/what-is.html\" target=\"_blank\">Amazon Q Business User Guide</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Q is excited to announce personalization capabilities in <a href=\"https://aws.amazon.com/q/business/\" target=\"_blank\">Q Business</a>, that help customers further increase employee productivity by considering their user profile to provide more useful responses. Q uses information such as an employee\u2019s location, department and role to improve the relevance of responses.<br /> <br /> Q Business\u2019 personalization capabilities are automatically enabled and will use your enterprise\u2019s employee profile data to improve their user experience, with no additional set-up needed. Q receives employee profile information from your organization\u2019s identity provider that you have connected to <a href=\"https://aws.amazon.com/iam/identity-center/\" target=\"_blank\">AWS IAM Identity Center</a>.<br /> <br /> Amazon Q Business revolutionizes the way that employees interact with organizational knowledge and enterprise systems. It helps users get comprehensive answers to complex questions and take actions in a unified, intuitive web-based chat experience\u2014all using an enterprise\u2019s existing content, data, and systems. Personalization capability is available in all <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regions</a> where Q Business is available. For more information, see <a href=\"https://docs.aws.amazon.com/amazonq/latest/qbusiness-ug/what-is.html\" target=\"_blank\">Amazon Q Business User Guide</a>.<br /> &nbsp;</p>"}, "published": "Tue, 09 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 9, 17, 0, 0, 1, 191, 0], "tags": [{"term": "general:products/amazon-q,marketing:marchitecture/artificial-intelligence,marketing:marchitecture/business-productivity", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-q-business-responses-personalized-users"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-q-business-responses-personalized-users"}
{"id": "c00921e8b90bf1e8c7ac618a5dcbe9c5b4f8ed7b", "guidislink": false, "title": "Announcing Playlist page for PartyRock", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Announcing Playlist page for PartyRock"}, "summary": "<p>Today, PartyRock is announcing a Playlist page to help you showcase a collection of PartyRock apps, curated by you. Everyone can build, use, and share generative AI powered apps using PartyRock, which uses foundation models from Amazon Bedrock.</p> \n<p>On November 26th, 2023, we announced a <a href=\"https://aws.amazon.com/about-aws/whats-new/2023/11/app-discovery-page-partyrock-bedrock-playground/\" target=\"_blank\">Discover page</a> to showcase top community-created PartyRock apps. With this release, you can now add apps to a personalized Playlist page, making it convenient for others to view and use your apps. Previously, PartyRock apps were available in two modes: Private, where only you could view, use, and edit your apps, and Shared using links, where you could share links with anyone to view and use your apps. Starting today, you have an additional mode of making your apps Public, where they are automatically displayed on your Playlist page, making it easy for anyone to view and use your apps. Set up your playlist by navigating to the Playlist page from the side navigation bar on PartyRock. Here, you can review your current apps and add them to your playlist. Once created, your playlist will be available at https://partyrock.aws/u/&lt;PartyRock username&gt;. With playlists, also comes \u2018app views\u2019 displaying the number of times other users viewed or used your apps, whether via a shared link or directly from your Playlist page.</p> \n<p>For a limited time, AWS offers new PartyRock users a free trial without the need to provide a credit card or sign up for an AWS account. To get hands-on with generative AI, visit <a href=\"https://partyrock.aws/\" target=\"_blank\">PartyRock</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, PartyRock is announcing a Playlist page to help you showcase a collection of PartyRock apps, curated by you. Everyone can build, use, and share generative AI powered apps using PartyRock, which uses foundation models from Amazon Bedrock.</p> \n<p>On November 26th, 2023, we announced a <a href=\"https://aws.amazon.com/about-aws/whats-new/2023/11/app-discovery-page-partyrock-bedrock-playground/\" target=\"_blank\">Discover page</a> to showcase top community-created PartyRock apps. With this release, you can now add apps to a personalized Playlist page, making it convenient for others to view and use your apps. Previously, PartyRock apps were available in two modes: Private, where only you could view, use, and edit your apps, and Shared using links, where you could share links with anyone to view and use your apps. Starting today, you have an additional mode of making your apps Public, where they are automatically displayed on your Playlist page, making it easy for anyone to view and use your apps. Set up your playlist by navigating to the Playlist page from the side navigation bar on PartyRock. Here, you can review your current apps and add them to your playlist. Once created, your playlist will be available at https://partyrock.aws/u/&lt;PartyRock username&gt;. With playlists, also comes \u2018app views\u2019 displaying the number of times other users viewed or used your apps, whether via a shared link or directly from your Playlist page.</p> \n<p>For a limited time, AWS offers new PartyRock users a free trial without the need to provide a credit card or sign up for an AWS account. To get hands-on with generative AI, visit <a href=\"https://partyrock.aws/\" target=\"_blank\">PartyRock</a>.</p>"}, "published": "Tue, 09 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 9, 17, 0, 0, 1, 191, 0], "tags": [{"term": "general:products/amazon-bedrock-partyrock,general:products/amazon-machine-learning,marketing:marchitecture/artificial-intelligence", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/playlist-page-for-partyrock/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/playlist-page-for-partyrock/"}
{"id": "e67dfdecec8848341163a026eac7289d60f503ab", "guidislink": false, "title": "Amazon S3 Express One Zone now supports logging of all events in AWS CloudTrail", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon S3 Express One Zone now supports logging of all events in AWS CloudTrail"}, "summary": "<p>With Amazon S3 Express One Zone support for logging of all data plane API actions in AWS CloudTrail, you can get details on who made API calls to S3 Express One Zone and when API calls were made, thereby enhancing data visibility for governance, compliance, and operational auditing. Now, you can use AWS CloudTrail to log S3 Express One Zone object-level activity such as PutObject and GetObject, in addition to directory-bucket level actions such as CreateBucket and DeleteBucket that were already supported.<br /> <br /> With logging of all events in AWS CloudTrail, you can quickly determine which S3 Express One Zone objects were created, read, updated or deleted and identify the source of the API calls. If you detect unauthorized S3 Express One Zone object access, you can take immediate action to restrict access. In addition, you can use CloudTrail features such as advanced event selectors for granular control over which events are logged and CloudTrail integration with Amazon EventBridge to create rule-based workflows for event-driven architectures.<br /> <br /> You can enable AWS CloudTrail data events logging for S3 Express One Zone in <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-express-Endpoints.html\" target=\"_blank\">all AWS Regions where S3 Express One Zone is available</a>. Get started with CloudTrail event logging for S3 Express One Zone by using the <a href=\"https://console.aws.amazon.com/cloudtrail\" target=\"_blank\">CloudTrail console</a>, <a href=\"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-data-events-with-cloudtrail.html#creating-data-event-selectors-with-the-AWS-CLI\">AWS CLI</a>, or AWS SDKs. For pricing information, visit the <a href=\"https://aws.amazon.com/cloudtrail/pricing/\" target=\"_blank\">CloudTrail pricing page</a>. To learn more, see the <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/cloudtrail-logging.html\" target=\"_blank\">S3 User Guide</a>, S3 Express One Zone <a href=\"https://aws.amazon.com/s3/storage-classes/express-one-zone/\" target=\"_blank\">product page</a>&nbsp;and the <a href=\"https://aws.amazon.com/blogs/aws/monitor-data-events-in-amazon-s3-express-one-zone-with-aws-cloudtrail/\" target=\"_blank\">AWS News Blog</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>With Amazon S3 Express One Zone support for logging of all data plane API actions in AWS CloudTrail, you can get details on who made API calls to S3 Express One Zone and when API calls were made, thereby enhancing data visibility for governance, compliance, and operational auditing. Now, you can use AWS CloudTrail to log S3 Express One Zone object-level activity such as PutObject and GetObject, in addition to directory-bucket level actions such as CreateBucket and DeleteBucket that were already supported.<br /> <br /> With logging of all events in AWS CloudTrail, you can quickly determine which S3 Express One Zone objects were created, read, updated or deleted and identify the source of the API calls. If you detect unauthorized S3 Express One Zone object access, you can take immediate action to restrict access. In addition, you can use CloudTrail features such as advanced event selectors for granular control over which events are logged and CloudTrail integration with Amazon EventBridge to create rule-based workflows for event-driven architectures.<br /> <br /> You can enable AWS CloudTrail data events logging for S3 Express One Zone in <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/s3-express-Endpoints.html\" target=\"_blank\">all AWS Regions where S3 Express One Zone is available</a>. Get started with CloudTrail event logging for S3 Express One Zone by using the <a href=\"https://console.aws.amazon.com/cloudtrail\" target=\"_blank\">CloudTrail console</a>, <a href=\"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-data-events-with-cloudtrail.html#creating-data-event-selectors-with-the-AWS-CLI\">AWS CLI</a>, or AWS SDKs. For pricing information, visit the <a href=\"https://aws.amazon.com/cloudtrail/pricing/\" target=\"_blank\">CloudTrail pricing page</a>. To learn more, see the <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/cloudtrail-logging.html\" target=\"_blank\">S3 User Guide</a>, S3 Express One Zone <a href=\"https://aws.amazon.com/s3/storage-classes/express-one-zone/\" target=\"_blank\">product page</a>&nbsp;and the <a href=\"https://aws.amazon.com/blogs/aws/monitor-data-events-in-amazon-s3-express-one-zone-with-aws-cloudtrail/\" target=\"_blank\">AWS News Blog</a>.</p>"}, "published": "Tue, 09 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 9, 17, 0, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/security-identity-and-compliance,general:products/amazon-s3,general:products/aws-cloudtrail,marketing:marchitecture/storage", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-s3-express-one-zone-logging-events-aws-cloudtrail"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-s3-express-one-zone-logging-events-aws-cloudtrail"}
{"id": "43c6bf4aa919c3afb0a17b8a116a53996510f23b", "guidislink": false, "title": "Amazon OpenSearch Serverless expands support for time-series workloads up to 30TB", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon OpenSearch Serverless expands support for time-series workloads up to 30TB"}, "summary": "<p>We are excited to announce that <a href=\"https://aws.amazon.com/opensearch-service/features/serverless/\" target=\"_blank\">Amazon OpenSearch Serverless</a> now supports workloads up to 30TB of data for time-series collections. OpenSearch Serverless is a serverless deployment option for Amazon OpenSearch Service that makes it simple for you to run search and analytics workloads without having to think about infrastructure management. With the support for larger datasets, OpenSearch Serverless now enables more data-intensive use cases such as log analytics, security analytics, real-time application monitoring, and more.<br /> <br /> OpenSearch Serverless\u2019 compute capacity used for indexing and search are measured in OpenSearch Compute Units (OCUs). To accommodate for larger datasets, OpenSearch Serverless now allows customers to independently scale indexing and search operations to use up to 500 OCUs. In addition, the release brings in a new data hydration mechanism that improves scaling and lowering query latency. You configure the maximum OCU limits on search and indexing independently to manage costs. You can also monitor real-time OCU usage with CloudWatch metrics to gain a better perspective on your workload's resource consumption.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>We are excited to announce that <a href=\"https://aws.amazon.com/opensearch-service/features/serverless/\" target=\"_blank\">Amazon OpenSearch Serverless</a> now supports workloads up to 30TB of data for time-series collections. OpenSearch Serverless is a serverless deployment option for Amazon OpenSearch Service that makes it simple for you to run search and analytics workloads without having to think about infrastructure management. With the support for larger datasets, OpenSearch Serverless now enables more data-intensive use cases such as log analytics, security analytics, real-time application monitoring, and more.<br /> <br /> OpenSearch Serverless\u2019 compute capacity used for indexing and search are measured in OpenSearch Compute Units (OCUs). To accommodate for larger datasets, OpenSearch Serverless now allows customers to independently scale indexing and search operations to use up to 500 OCUs. In addition, the release brings in a new data hydration mechanism that improves scaling and lowering query latency. You configure the maximum OCU limits on search and indexing independently to manage costs. You can also monitor real-time OCU usage with CloudWatch metrics to gain a better perspective on your workload's resource consumption.</p>"}, "published": "Tue, 09 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 9, 17, 0, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/serverless,marketing:marchitecture/customer-enablement,marketing:marchitecture/analytics,general:products/amazon-opensearch-service", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-opensearch-serverless-time-series-workloads-30tb"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-opensearch-serverless-time-series-workloads-30tb"}
{"id": "ef62b0ce01a3d61a976f1eeccc171d4316c53c52", "guidislink": false, "title": "Announcing Valkey GLIDE, an open source client library for Valkey and Redis open source", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Announcing Valkey GLIDE, an open source client library for Valkey and Redis open source"}, "summary": "<p>Today, we\u2019re introducing Valkey General Language Independent Driver for the Enterprise (GLIDE), an open source Valkey client library. Valkey is an open source key-value data store that supports a variety of workloads such as caching, and message queues. Valkey GLIDE is one of the official client libraries for Valkey and it supports all Valkey commands. GLIDE supports Valkey 7.2 and above, and Redis open source 6.2, 7.0, and 7.2. Application programmers can use GLIDE to safely and reliably connect their applications to services that are Valkey- and Redis OSS-compatible.<br /> <br /> Valkey GLIDE is designed for reliability, optimized performance, and high-availability, for Valkey- and Redis OSS- based applications. It is supported by AWS, and is preconfigured with best practices learned from over a decade of operating Redis OSS-compatible services used by thousands of customers. To help ensure consistency in application development and operations, GLIDE is implemented using a core driver framework, written in Rust, with language specific extensions. This design ensures consistency in features across languages, and reduces overall complexity. In this release, GLIDE is available for Java and Python, with support for additional languages actively under development.<br /> <br /> Valkey GLIDE is open source, permissively licensed (Apache 2.0 license), and can be used with any Valkey- or Redis OSS-compatible distribution supporting version 6.2, 7.0, and 7.2, including <a href=\"http://aws.amazon.com/elasticache\" target=\"_blank\">Amazon ElastiCache</a> and <a href=\"https://aws.amazon.com/memorydb/\" target=\"_blank\">Amazon MemoryDB</a>. You can get started by downloading it from the major open source package managers. Learn more about it in the <a href=\"https://aws.amazon.com/blogs/database/introducing-valkey-glide-an-open-source-client-library-for-valkey-and-redis-open-source\" target=\"_blank\">blog post</a>, and submit contributions on the <a href=\"https://github.com/valkey-io/valkey-glide\" target=\"_blank\">Valkey GLIDE GitHub repository</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, we\u2019re introducing Valkey General Language Independent Driver for the Enterprise (GLIDE), an open source Valkey client library. Valkey is an open source key-value data store that supports a variety of workloads such as caching, and message queues. Valkey GLIDE is one of the official client libraries for Valkey and it supports all Valkey commands. GLIDE supports Valkey 7.2 and above, and Redis open source 6.2, 7.0, and 7.2. Application programmers can use GLIDE to safely and reliably connect their applications to services that are Valkey- and Redis OSS-compatible.<br /> <br /> Valkey GLIDE is designed for reliability, optimized performance, and high-availability, for Valkey- and Redis OSS- based applications. It is supported by AWS, and is preconfigured with best practices learned from over a decade of operating Redis OSS-compatible services used by thousands of customers. To help ensure consistency in application development and operations, GLIDE is implemented using a core driver framework, written in Rust, with language specific extensions. This design ensures consistency in features across languages, and reduces overall complexity. In this release, GLIDE is available for Java and Python, with support for additional languages actively under development.<br /> <br /> Valkey GLIDE is open source, permissively licensed (Apache 2.0 license), and can be used with any Valkey- or Redis OSS-compatible distribution supporting version 6.2, 7.0, and 7.2, including <a href=\"http://aws.amazon.com/elasticache\" target=\"_blank\">Amazon ElastiCache</a> and <a href=\"https://aws.amazon.com/memorydb/\" target=\"_blank\">Amazon MemoryDB</a>. You can get started by downloading it from the major open source package managers. Learn more about it in the <a href=\"https://aws.amazon.com/blogs/database/introducing-valkey-glide-an-open-source-client-library-for-valkey-and-redis-open-source\" target=\"_blank\">blog post</a>, and submit contributions on the <a href=\"https://github.com/valkey-io/valkey-glide\" target=\"_blank\">Valkey GLIDE GitHub repository</a>.</p>"}, "published": "Tue, 09 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 9, 17, 0, 0, 1, 191, 0], "tags": [{"term": "marketing:marchitecture/developer-tools,general:products/amazon-elasticache", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/valkey-glide-open-source-valkey-redis/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/valkey-glide-open-source-valkey-redis/"}
{"id": "335b4f1df9cd52e0abd1402a6f5c66341b7cd259", "guidislink": false, "title": "Amazon CloudFront announces managed cache policies for web applications", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon CloudFront announces managed cache policies for web applications"}, "summary": "<p>Amazon CloudFront announces two new managed cache policies, UseOriginCacheControlHeaders and UseOriginCacheControlHeaders-QueryStrings, for dynamically generated websites and applications that return Cache-Control headers. With the new managed cache policies, CloudFront caches content based on the <a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html#expiration-individual-objects\" target=\"_blank\">Cache-Control</a> headers returned by the origin, and defaults to not caching when no Cache-Control header is returned. This functionality was previously available to customers that created custom cache policies, but is now available out-of-the-box for all customers as a managed cache policy.<br /> <br /> Cache policies instruct CloudFront when and how to cache, including which request attributes to include in the cache key. Previously, customers had two common options for managed cache policies: CachingOptimized to always cache unless disallowed by a caching directive, and CachingDisabled to disable all caching. For all other cases, customers had to create custom cache policies. Now, customers can use a single managed cache policy for websites backed by content management systems like WordPress or dynamically generated content that has a mix of cacheable and non-cacheable content.<br /> <br /> The new managed cache policies are available for immediate use at no additional cost. This feature can be enabled via the CloudFront Console, SDK, and CLI. The CloudFront console automatically provides recommendations on cache policies based on your origin type. For more information, refer to the <a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-managed-cache-policies.html#managed-cache-policy-origin-cache-headers\" target=\"_blank\">CloudFront Developer Guide</a>. To get started with CloudFront, visit the <a href=\"https://aws.amazon.com/cloudfront/getting-started/\" target=\"_blank\">CloudFront Product Page</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon CloudFront announces two new managed cache policies, UseOriginCacheControlHeaders and UseOriginCacheControlHeaders-QueryStrings, for dynamically generated websites and applications that return Cache-Control headers. With the new managed cache policies, CloudFront caches content based on the <a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html#expiration-individual-objects\" target=\"_blank\">Cache-Control</a> headers returned by the origin, and defaults to not caching when no Cache-Control header is returned. This functionality was previously available to customers that created custom cache policies, but is now available out-of-the-box for all customers as a managed cache policy.<br /> <br /> Cache policies instruct CloudFront when and how to cache, including which request attributes to include in the cache key. Previously, customers had two common options for managed cache policies: CachingOptimized to always cache unless disallowed by a caching directive, and CachingDisabled to disable all caching. For all other cases, customers had to create custom cache policies. Now, customers can use a single managed cache policy for websites backed by content management systems like WordPress or dynamically generated content that has a mix of cacheable and non-cacheable content.<br /> <br /> The new managed cache policies are available for immediate use at no additional cost. This feature can be enabled via the CloudFront Console, SDK, and CLI. The CloudFront console automatically provides recommendations on cache policies based on your origin type. For more information, refer to the <a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/using-managed-cache-policies.html#managed-cache-policy-origin-cache-headers\" target=\"_blank\">CloudFront Developer Guide</a>. To get started with CloudFront, visit the <a href=\"https://aws.amazon.com/cloudfront/getting-started/\" target=\"_blank\">CloudFront Product Page</a>.</p>"}, "published": "Mon, 08 Jul 2024 22:00:00 GMT", "published_parsed": [2024, 7, 8, 22, 0, 0, 0, 190, 0], "tags": [{"term": "general:products/amazon-cloudfront,marketing:marchitecture/networking", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-cloudfront-managed-cache-policies-web-applications"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-cloudfront-managed-cache-policies-web-applications"}
{"id": "6eb52c64599cc3b3529a928f28efc5ddf22ccfe2", "guidislink": false, "title": "FreeRTOS releases new  Long Term Support version", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "FreeRTOS releases new  Long Term Support version"}, "summary": "<p>Today, AWS announced the third release of FreeRTOS Long Term Support (LTS) - <a href=\"https://freertos.org/lts-libraries.html\" target=\"_blank\">FreeRTOS 202406 LTS</a>. FreeRTOS LTS releases provide feature stability with security updates and critical bug fixes for two years. The new LTS release includes the latest FreeRTOS kernel v11.1 that supports Symmetric Multiprocessing (SMP) and Memory Protection Units (MPU) and recently updated libraries, such as the FreeRTOS-Plus-TCP v4.2.1 library and the <a href=\"https://www.freertos.org/freertos-core/over-the-air-updates/index.html\" target=\"_blank\">Over-the-Air (OTA)</a> library, providing you with an improved IPv6 and OTA capabilities. With the FreeRTOS LTS releases, you can continue to maintain your existing FreeRTOS code base and avoid any potential disruptions resulting from FreeRTOS version upgrades.<br /> <br /> Similar to the previous FreeRTOS LTS release, FreeRTOS 202406 LTS includes libraries that have been validated for memory safety with the C Bounded Model Checker (CBMC) and have undergone specific code quality checks, including MISRA-C compliance and Coverity static analysis to help improve code safety, portability, and reliability in embedded systems. For more information, refer to the LTS Code Quality Checklist.<br /> <br /> The support period for the previous LTS release will end on Nov-2024, thus providing you with an overlapping time window to migrate your projects to the new LTS release. Refer to the <a href=\"https://freertos.org/lts-libraries.html\" target=\"_blank\">migration guide</a> and corresponding validation tests to upgrade your project to FreeRTOS 202406 LTS. If you prefer not to upgrade and want to continue receiving critical fixes on the previous LTS version beyond its expiry, consider the <a href=\"https://aws.amazon.com/freertos/features/#FreeRTOS_Extended_Maintenance_Plan\" target=\"_blank\">FreeRTOS Extended Maintenance Plan</a>.<br /> <br /> To learn more, visit the <a href=\"https://freertos.org/lts-libraries.html\" target=\"_blank\">FreeRTOS LTS page</a> and <a href=\"https://github.com/FreeRTOS/FreeRTOS-LTS\" target=\"_blank\">FreeRTOS LTS GitHub repository</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, AWS announced the third release of FreeRTOS Long Term Support (LTS) - <a href=\"https://freertos.org/lts-libraries.html\" target=\"_blank\">FreeRTOS 202406 LTS</a>. FreeRTOS LTS releases provide feature stability with security updates and critical bug fixes for two years. The new LTS release includes the latest FreeRTOS kernel v11.1 that supports Symmetric Multiprocessing (SMP) and Memory Protection Units (MPU) and recently updated libraries, such as the FreeRTOS-Plus-TCP v4.2.1 library and the <a href=\"https://www.freertos.org/freertos-core/over-the-air-updates/index.html\" target=\"_blank\">Over-the-Air (OTA)</a> library, providing you with an improved IPv6 and OTA capabilities. With the FreeRTOS LTS releases, you can continue to maintain your existing FreeRTOS code base and avoid any potential disruptions resulting from FreeRTOS version upgrades.<br /> <br /> Similar to the previous FreeRTOS LTS release, FreeRTOS 202406 LTS includes libraries that have been validated for memory safety with the C Bounded Model Checker (CBMC) and have undergone specific code quality checks, including MISRA-C compliance and Coverity static analysis to help improve code safety, portability, and reliability in embedded systems. For more information, refer to the LTS Code Quality Checklist.<br /> <br /> The support period for the previous LTS release will end on Nov-2024, thus providing you with an overlapping time window to migrate your projects to the new LTS release. Refer to the <a href=\"https://freertos.org/lts-libraries.html\" target=\"_blank\">migration guide</a> and corresponding validation tests to upgrade your project to FreeRTOS 202406 LTS. If you prefer not to upgrade and want to continue receiving critical fixes on the previous LTS version beyond its expiry, consider the <a href=\"https://aws.amazon.com/freertos/features/#FreeRTOS_Extended_Maintenance_Plan\" target=\"_blank\">FreeRTOS Extended Maintenance Plan</a>.<br /> <br /> To learn more, visit the <a href=\"https://freertos.org/lts-libraries.html\" target=\"_blank\">FreeRTOS LTS page</a> and <a href=\"https://github.com/FreeRTOS/FreeRTOS-LTS\" target=\"_blank\">FreeRTOS LTS GitHub repository</a>.</p>"}, "published": "Mon, 08 Jul 2024 21:20:00 GMT", "published_parsed": [2024, 7, 8, 21, 20, 0, 0, 190, 0], "tags": [{"term": "general:products/amazon-freertos,marketing:marchitecture/internet-of-things", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/freertos-long-term-support-version"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/freertos-long-term-support-version"}
{"id": "670a275c7e6cd29a74a905be3e92f44a879687b5", "guidislink": false, "title": "Migration Acceleration Program (MAP) visualizations available in AWS Partner Central- Analytics and Insights Dashboard", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Migration Acceleration Program (MAP) visualizations available in AWS Partner Central- Analytics and Insights Dashboard"}, "summary": "<p>Today, Amazon Web Services, Inc. (AWS) announces new 2024 AWS Migration Acceleration Program (MAP) data visualizations in Analytics and Insights Dashboards, accessible via AWS Partner Central. AWS Partners with the Migration Competency and in Differentiated or Validation Stages of any Partner Path, can now access these new visualizations.<br /> <br /> Previously, Partners' realization of their MAP benefit was based on project or milestone completion. With the 2024 MAP Program changes designed toward revenue-based outcomes, Analytics and Insights surfaces the necessary information needed to maintain visibility and awareness of these outcomes to claim their MAP funding benefits in the AWS Partner Funding Portal (APFP).<br /> <br /> To get started, log into your AWS Partner Central account and navigate to the <a href=\"https://analytics.awspartner.com/auth?code=b0d3723b-4889-4cec-ac8c-007fd64bbd2b\" target=\"_blank\">Investments tab within the Analytics &amp; Insights dashboard</a>. Learn more about the dashboard\u2019s functionality and the latest updates in the <a href=\"https://partnercentral.awspartner.com/partnercentral2/s/resources?categories=a1o8W00000CArhuQAD&amp;redirect=false\" target=\"_blank\">Analytics and Insights User Guide and FAQs </a>(login required). To learn more about the new 2024 MAP funding template, refer to link and&nbsp; blog post.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, Amazon Web Services, Inc. (AWS) announces new 2024 AWS Migration Acceleration Program (MAP) data visualizations in Analytics and Insights Dashboards, accessible via AWS Partner Central. AWS Partners with the Migration Competency and in Differentiated or Validation Stages of any Partner Path, can now access these new visualizations.<br /> <br /> Previously, Partners' realization of their MAP benefit was based on project or milestone completion. With the 2024 MAP Program changes designed toward revenue-based outcomes, Analytics and Insights surfaces the necessary information needed to maintain visibility and awareness of these outcomes to claim their MAP funding benefits in the AWS Partner Funding Portal (APFP).<br /> <br /> To get started, log into your AWS Partner Central account and navigate to the <a href=\"https://analytics.awspartner.com/auth?code=b0d3723b-4889-4cec-ac8c-007fd64bbd2b\" target=\"_blank\">Investments tab within the Analytics &amp; Insights dashboard</a>. Learn more about the dashboard\u2019s functionality and the latest updates in the <a href=\"https://partnercentral.awspartner.com/partnercentral2/s/resources?categories=a1o8W00000CArhuQAD&amp;redirect=false\" target=\"_blank\">Analytics and Insights User Guide and FAQs </a>(login required). To learn more about the new 2024 MAP funding template, refer to link and&nbsp; blog post.</p>"}, "published": "Mon, 08 Jul 2024 18:40:00 GMT", "published_parsed": [2024, 7, 8, 18, 40, 0, 0, 190, 0], "tags": [{"term": "marketing:marchitecture/partner-network,marketing:marchitecture/aws-marketplace-and-partners", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/map-visualizations-aws-partner-central-analytics-insights-dashboard"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/map-visualizations-aws-partner-central-analytics-insights-dashboard"}
{"id": "75d61aa7c8064b4b5096da5c478e41d640eae381", "guidislink": false, "title": "Amazon EMR support for backup and restore for Apache HBase Tables available in Asia Pacific (Seoul)", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon EMR support for backup and restore for Apache HBase Tables available in Asia Pacific (Seoul)"}, "summary": "<p>We are excited to announce that <a href=\"https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hbase-wal.html\" target=\"_blank\">backup and restore for Apache HBase Tables</a> is now available in the AWS region in Asia Pacific (Seoul)<br /> <br /> Apache HBase Write Ahead Log allows recording all changes to data to file-based storage. With the launch today, customers can now write their Apache HBase write-ahead logs to the Amazon EMR WAL, a durable managed storage layer. This ensures business continuity in case of a disaster as well as offer a higher resilience for workloads. In the event that customer\u2019s cluster, or in the rare cases that the Availability Zone becomes unhealthy or unavailable, customers can create a new cluster, point it to the same Amazon S3 root directory and Amazon EMR WAL workspace, and automatically recover data from Amazon EMR WAL within a few minutes. This feature also allows Apache HBase administrators to easily perform common operational tasks like upgrading to the latest versions, rotating your clusters, and cleaning up old write ahead logs.<br /> <br /> Customer who enroll into the feature will be charged based on usage - for Amazon EMR WAL data storage, writes, and reads during recovery operations. This feature is now available for Amazon EMR release 6.15 and 7.0 and later. To learn how to get started, please refer to our <a href=\"https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hbase-wal.html\" target=\"_blank\">documentation</a>, and for pricing information please refer to the <a href=\"https://aws.amazon.com/emr/pricing/\" target=\"_blank\">pricing</a> section.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>We are excited to announce that <a href=\"https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hbase-wal.html\" target=\"_blank\">backup and restore for Apache HBase Tables</a> is now available in the AWS region in Asia Pacific (Seoul)<br /> <br /> Apache HBase Write Ahead Log allows recording all changes to data to file-based storage. With the launch today, customers can now write their Apache HBase write-ahead logs to the Amazon EMR WAL, a durable managed storage layer. This ensures business continuity in case of a disaster as well as offer a higher resilience for workloads. In the event that customer\u2019s cluster, or in the rare cases that the Availability Zone becomes unhealthy or unavailable, customers can create a new cluster, point it to the same Amazon S3 root directory and Amazon EMR WAL workspace, and automatically recover data from Amazon EMR WAL within a few minutes. This feature also allows Apache HBase administrators to easily perform common operational tasks like upgrading to the latest versions, rotating your clusters, and cleaning up old write ahead logs.<br /> <br /> Customer who enroll into the feature will be charged based on usage - for Amazon EMR WAL data storage, writes, and reads during recovery operations. This feature is now available for Amazon EMR release 6.15 and 7.0 and later. To learn how to get started, please refer to our <a href=\"https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hbase-wal.html\" target=\"_blank\">documentation</a>, and for pricing information please refer to the <a href=\"https://aws.amazon.com/emr/pricing/\" target=\"_blank\">pricing</a> section.<br /> &nbsp;</p>"}, "published": "Mon, 08 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 8, 17, 0, 0, 0, 190, 0], "tags": [{"term": "general:products/amazon-emr,marketing:marchitecture/analytics", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-emr-backup-restore-apache-hbase-tables-seoul/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-emr-backup-restore-apache-hbase-tables-seoul/"}
{"id": "1f861599a758710f364991d7b483b957abed94b7", "guidislink": false, "title": "Amazon Connect  launches automated rotation of agent shifts", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Connect  launches automated rotation of agent shifts"}, "summary": "<p>Amazon Connect now supports automated rotation of agent shifts, making it easier for contact center managers to administrate schedules and ensure that agents receive a business-defined sequence of shifts.<br /> <br /> Automated shift rotations speed up the week-to-week scheduling process for contact center managers, eliminating the need to manually move agents between different shifts. With shift rotation, contact center managers can now create a pattern of shifts that agents will repeatedly rotate through (e.g., morning shift, afternoon shift, night shift) and define how many weeks each shift should be scheduled before moving to the next one in the rotation. These shift rotation patterns are automatically applied when new schedules are created, eliminating the need for contact center managers to manually assign shifts to groups of agents. Additionally, contact center managers can bulk upload and download shift rotation and shift profile assignments, making it easy to set up and update shift rotations for thousands of agents.<br /> <br /> There is no additional charge for this feature and it is available in all <a href=\"https://docs.aws.amazon.com/connect/latest/adminguide/regions.html#optimization_region\" target=\"_blank\">AWS Regions</a> where Amazon Connect agent scheduling is available, To get started with Amazon Connect agent scheduling, click <a href=\"https://aws.amazon.com/blogs/contact-center/optimization/\" target=\"_blank\">here</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Connect now supports automated rotation of agent shifts, making it easier for contact center managers to administrate schedules and ensure that agents receive a business-defined sequence of shifts.<br /> <br /> Automated shift rotations speed up the week-to-week scheduling process for contact center managers, eliminating the need to manually move agents between different shifts. With shift rotation, contact center managers can now create a pattern of shifts that agents will repeatedly rotate through (e.g., morning shift, afternoon shift, night shift) and define how many weeks each shift should be scheduled before moving to the next one in the rotation. These shift rotation patterns are automatically applied when new schedules are created, eliminating the need for contact center managers to manually assign shifts to groups of agents. Additionally, contact center managers can bulk upload and download shift rotation and shift profile assignments, making it easy to set up and update shift rotations for thousands of agents.<br /> <br /> There is no additional charge for this feature and it is available in all <a href=\"https://docs.aws.amazon.com/connect/latest/adminguide/regions.html#optimization_region\" target=\"_blank\">AWS Regions</a> where Amazon Connect agent scheduling is available, To get started with Amazon Connect agent scheduling, click <a href=\"https://aws.amazon.com/blogs/contact-center/optimization/\" target=\"_blank\">here</a>.</p>"}, "published": "Mon, 08 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 8, 17, 0, 0, 0, 190, 0], "tags": [{"term": "general:products/amazon-connect,marketing:marchitecture/business-productivity", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-connect-automated-rotation-agent-shifts"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-connect-automated-rotation-agent-shifts"}
{"id": "e8fe3dc980f392fe0b66abbfabbb71eef03f212f", "guidislink": false, "title": "Amazon ECR adds EventBridge support with ECR\u2019s replication feature", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon ECR adds EventBridge support with ECR\u2019s replication feature"}, "summary": "<p>Amazon Elastic Container Registry (Amazon ECR) now emits Amazon EventBridge events when customers successfully replicate images using ECR\u2019s replication capability. <a href=\"https://aws.amazon.com/eventbridge/\" target=\"_blank\">Amazon EventBridge</a> is a serverless service that makes it easy for customers to connect their applications using events generated from a variety of sources.<br /> <br /> ECR\u2019s <a href=\"https://docs.aws.amazon.com/AmazonECR/latest/userguide/replication.html\" target=\"_blank\">replication</a> feature enables you to easily copy container images across multiple AWS accounts and regions, and benefit from in-region pulls, allowing your applications to start faster as pull latency is reduced. Geographically dispersed images also help you meet backup and disaster recovery requirements for your applications. With today\u2019s launch, ECR will automatically generate events when image replication is successfully completed across configured source and destination regions and/or accounts. This allows you to know once your replicated images are available for use in the destination registry, and trigger automated actions following replication completion. To receive ECR events, you can configure a rule using the EventBridge console, and include automated actions that should be triggered when an event matches the rule.<br /> <br /> EventBridge support for ECR replication is available in all commercial AWS Regions. To get started and learn more about EventBridge events with Amazon ECR, see our <a href=\"https://docs.aws.amazon.com/AmazonECR/latest/userguide/ecr-eventbridge.html\" target=\"_blank\">user guide</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Elastic Container Registry (Amazon ECR) now emits Amazon EventBridge events when customers successfully replicate images using ECR\u2019s replication capability. <a href=\"https://aws.amazon.com/eventbridge/\" target=\"_blank\">Amazon EventBridge</a> is a serverless service that makes it easy for customers to connect their applications using events generated from a variety of sources.<br /> <br /> ECR\u2019s <a href=\"https://docs.aws.amazon.com/AmazonECR/latest/userguide/replication.html\" target=\"_blank\">replication</a> feature enables you to easily copy container images across multiple AWS accounts and regions, and benefit from in-region pulls, allowing your applications to start faster as pull latency is reduced. Geographically dispersed images also help you meet backup and disaster recovery requirements for your applications. With today\u2019s launch, ECR will automatically generate events when image replication is successfully completed across configured source and destination regions and/or accounts. This allows you to know once your replicated images are available for use in the destination registry, and trigger automated actions following replication completion. To receive ECR events, you can configure a rule using the EventBridge console, and include automated actions that should be triggered when an event matches the rule.<br /> <br /> EventBridge support for ECR replication is available in all commercial AWS Regions. To get started and learn more about EventBridge events with Amazon ECR, see our <a href=\"https://docs.aws.amazon.com/AmazonECR/latest/userguide/ecr-eventbridge.html\" target=\"_blank\">user guide</a>.<br /> &nbsp;</p>"}, "published": "Mon, 08 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 8, 17, 0, 0, 0, 190, 0], "tags": [{"term": "general:products/amazon-ecr,marketing:marchitecture/containers", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-ecr-eventbridge-ecrs-replication-feature/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-ecr-eventbridge-ecrs-replication-feature/"}
{"id": "f57bf3d6cc3c671cd1567ae64819abc6b49f6ac2", "guidislink": false, "title": "Amazon SNS now supports sending SMS from Canada West (Calgary) region", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon SNS now supports sending SMS from Canada West (Calgary) region"}, "summary": "<p>Customers that use Amazon Simple Notification Service (Amazon SNS) can now host their applications in Canada West (Calgary) region, and send text messages (SMS) to consumers in more than 200 countries and territories. Using Amazon SNS, customers can <a href=\"https://docs.aws.amazon.com/sns/latest/dg/sms_publish-to-phone.html\" target=\"_blank\">send a message directly to one phone number</a>, or <a href=\"https://docs.aws.amazon.com/sns/latest/dg/sms_publish-to-topic.html\" target=\"_blank\">multiple phone numbers</a> at once by subscribing those phone numbers to a topic and sending messages to the topic. With this expansion, Amazon SNS now supports the ability to send SMS from 29 AWS regions.<br /> <br /> More information:</p> \n<ul> \n <li>To learn more about sending SMS messages, visit <a href=\"https://docs.aws.amazon.com/sns/latest/dg/sns-mobile-phone-number-as-subscriber.html\" target=\"_blank\">Mobile text messaging (SMS)</a>.</li> \n <li>For the list of regions from which you can send SMS using Amazon SNS, visit <a href=\"https://docs.aws.amazon.com/sns/latest/dg/sns-supported-regions-countries.html\" target=\"_blank\">Amazon SNS SMS Supported Regions and Countries.</a></li> \n</ul>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Customers that use Amazon Simple Notification Service (Amazon SNS) can now host their applications in Canada West (Calgary) region, and send text messages (SMS) to consumers in more than 200 countries and territories. Using Amazon SNS, customers can <a href=\"https://docs.aws.amazon.com/sns/latest/dg/sms_publish-to-phone.html\" target=\"_blank\">send a message directly to one phone number</a>, or <a href=\"https://docs.aws.amazon.com/sns/latest/dg/sms_publish-to-topic.html\" target=\"_blank\">multiple phone numbers</a> at once by subscribing those phone numbers to a topic and sending messages to the topic. With this expansion, Amazon SNS now supports the ability to send SMS from 29 AWS regions.<br /> <br /> More information:</p> \n<ul> \n <li>To learn more about sending SMS messages, visit <a href=\"https://docs.aws.amazon.com/sns/latest/dg/sns-mobile-phone-number-as-subscriber.html\" target=\"_blank\">Mobile text messaging (SMS)</a>.</li> \n <li>For the list of regions from which you can send SMS using Amazon SNS, visit <a href=\"https://docs.aws.amazon.com/sns/latest/dg/sns-supported-regions-countries.html\" target=\"_blank\">Amazon SNS SMS Supported Regions and Countries.</a></li> \n</ul>"}, "published": "Mon, 08 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 8, 17, 0, 0, 0, 190, 0], "tags": [{"term": "marketing:marchitecture/mobile-services,marketing:marchitecture/serverless,marketing:marchitecture/application-services,general:products/amazon-sns", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-sns-sending-sms-calgary"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-sns-sending-sms-calgary"}
{"id": "380cec443adea6160887c779c2d97fa74bcf8355", "guidislink": false, "title": "Amazon SQS introduces new Amazon CloudWatch metrics for FIFO queues", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon SQS introduces new Amazon CloudWatch metrics for FIFO queues"}, "summary": "<p><a href=\"https://aws.amazon.com/sqs/\" target=\"_blank\">Amazon Simple Queue Service</a> introduces two new Amazon CloudWatch metrics to improve the usage visibility of FIFO queues. Amazon SQS is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications.<br /> <br /> With the new metrics, SQS customers have greater visibility into their FIFO usage. The new metrics are:</p> \n<ul> \n <li>NumberOfDeduplicatedSentMessages - The number of messages sent to a queue that were deduplicated. This metric helps in determining if a producer is sending duplicate messages to an SQS FIFO queue.</li> \n <li>ApproximateNumberOfGroupsWithInflightMessages - The approximate number of message groups with inflight messages, where a message is considered to be <em>in flight</em> after it is received from a queue by a consumer, but not yet deleted from the queue. This metric helps you troubleshoot and optimise your FIFO queue throughput by either increasing FIFO message groups or scaling your consumers.</li> \n</ul> \n<p><br /> Metrics are available on a per-queue basis, and can be <a href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-access-metrics.html\" target=\"_blank\">accessed through SQS and CloudWatch consoles</a>. These metrics are available in all AWS regions where Amazon SQS is available.<br /> <br /> To learn more, see <a href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-available-cloudwatch-metrics.html\" target=\"_blank\">SQS Metrics Documentation</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://aws.amazon.com/sqs/\" target=\"_blank\">Amazon Simple Queue Service</a> introduces two new Amazon CloudWatch metrics to improve the usage visibility of FIFO queues. Amazon SQS is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications.<br /> <br /> With the new metrics, SQS customers have greater visibility into their FIFO usage. The new metrics are:</p> \n<ul> \n <li>NumberOfDeduplicatedSentMessages - The number of messages sent to a queue that were deduplicated. This metric helps in determining if a producer is sending duplicate messages to an SQS FIFO queue.</li> \n <li>ApproximateNumberOfGroupsWithInflightMessages - The approximate number of message groups with inflight messages, where a message is considered to be <em>in flight</em> after it is received from a queue by a consumer, but not yet deleted from the queue. This metric helps you troubleshoot and optimise your FIFO queue throughput by either increasing FIFO message groups or scaling your consumers.</li> \n</ul> \n<p><br /> Metrics are available on a per-queue basis, and can be <a href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-access-metrics.html\" target=\"_blank\">accessed through SQS and CloudWatch consoles</a>. These metrics are available in all AWS regions where Amazon SQS is available.<br /> <br /> To learn more, see <a href=\"https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-available-cloudwatch-metrics.html\" target=\"_blank\">SQS Metrics Documentation</a>.</p>"}, "published": "Fri, 05 Jul 2024 20:50:00 GMT", "published_parsed": [2024, 7, 5, 20, 50, 0, 4, 187, 0], "tags": [{"term": "marketing:marchitecture/serverless,general:products/aws-govcloud-us,general:products/amazon-cloudwatch", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-sqs-cloudwatch-metrics-fifo-queues"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-sqs-cloudwatch-metrics-fifo-queues"}
{"id": "fcacf627ab98af4197e6db2b491997314c685d3e", "guidislink": false, "title": "Amazon RDS Snapshot Export to S3 now available in eight additional AWS regions", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon RDS Snapshot Export to S3 now available in eight additional AWS regions"}, "summary": "<p>Snapshot Export to S3 for Amazon Aurora and Amazon RDS snapshots is now available in Asia Pacific (Hyderabad), Asia Pacific (Jakarta), Asia Pacific (Melbourne), Canada West (Calgary), Europe (Spain), Europe (Zurich), Israel (Tel Aviv), and Middle East (UAE) regions. Snapshot export to S3 exports snapshot data as Apache Parquet, an efficient open columnar storage format. Snapshot export to S3 allows ingestion of data stored in Amazon RDS and Amazon Aurora for purposes such as populating data lakes for analytics or for training machine learning models.<br /> <br /> You can create an export with just a few clicks on the <a href=\"https://console.aws.amazon.com/rds/home\" target=\"_blank\">Amazon RDS Management Console</a> or using the <a href=\"https://aws.amazon.com/tools/\" target=\"_blank\">AWS SDK</a> or <a href=\"https://docs.aws.amazon.com/cli/latest/reference/rds/\" target=\"_blank\">CLI</a>. Extracting data from a snapshot doesn\u2019t impact the performance of your database, as the export operation is performed on your snapshot and not your database. The extracted data in Apache Parquet format is portable, so you can consume it with other AWS services such as Amazon Athena, Amazon SageMaker, or Amazon Redshift Spectrum or with big data processing frameworks such as Apache Spark.<br /> <br /> Amazon RDS Snapshot Export to S3 can export data from Amazon RDS for PostgreSQL, Amazon RDS for MariaDB, Amazon RDS for MySQL, Amazon Aurora PostgreSQL-Compatible Edition and Amazon Aurora MySQL snapshots. For more information, including instructions on getting started, read the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_ExportSnapshot.html\" target=\"_blank\">Aurora documentation</a> or <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ExportSnapshot.html\" target=\"_blank\">Amazon RDS documentation</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Snapshot Export to S3 for Amazon Aurora and Amazon RDS snapshots is now available in Asia Pacific (Hyderabad), Asia Pacific (Jakarta), Asia Pacific (Melbourne), Canada West (Calgary), Europe (Spain), Europe (Zurich), Israel (Tel Aviv), and Middle East (UAE) regions. Snapshot export to S3 exports snapshot data as Apache Parquet, an efficient open columnar storage format. Snapshot export to S3 allows ingestion of data stored in Amazon RDS and Amazon Aurora for purposes such as populating data lakes for analytics or for training machine learning models.<br /> <br /> You can create an export with just a few clicks on the <a href=\"https://console.aws.amazon.com/rds/home\" target=\"_blank\">Amazon RDS Management Console</a> or using the <a href=\"https://aws.amazon.com/tools/\" target=\"_blank\">AWS SDK</a> or <a href=\"https://docs.aws.amazon.com/cli/latest/reference/rds/\" target=\"_blank\">CLI</a>. Extracting data from a snapshot doesn\u2019t impact the performance of your database, as the export operation is performed on your snapshot and not your database. The extracted data in Apache Parquet format is portable, so you can consume it with other AWS services such as Amazon Athena, Amazon SageMaker, or Amazon Redshift Spectrum or with big data processing frameworks such as Apache Spark.<br /> <br /> Amazon RDS Snapshot Export to S3 can export data from Amazon RDS for PostgreSQL, Amazon RDS for MariaDB, Amazon RDS for MySQL, Amazon Aurora PostgreSQL-Compatible Edition and Amazon Aurora MySQL snapshots. For more information, including instructions on getting started, read the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/USER_ExportSnapshot.html\" target=\"_blank\">Aurora documentation</a> or <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ExportSnapshot.html\" target=\"_blank\">Amazon RDS documentation</a>.<br /> &nbsp;</p>"}, "published": "Wed, 03 Jul 2024 21:55:00 GMT", "published_parsed": [2024, 7, 3, 21, 55, 0, 2, 185, 0], "tags": [{"term": "marketing:marchitecture/databases,general:products/amazon-rds,general:products/amazon-aurora", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-rds-snapshot-export-s3-additional-aws-regions"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-rds-snapshot-export-s3-additional-aws-regions"}
{"id": "7ca2c5f78143ac53263aa1f9c67b5576ce65f218", "guidislink": false, "title": "AWS Lambda introduces new controls to make it easier to search, filter, and aggregate Lambda function logs", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Lambda introduces new controls to make it easier to search, filter, and aggregate Lambda function logs"}, "summary": "<p>AWS Lambda announces advanced logging controls that enable you to natively capture logs in JSON structured format, adjust log levels, and select the Amazon CloudWatch log group for your Lambda functions.<br /> <br /> You can now capture your Lambda logs in JSON structured format without having to bring your own logging libraries. JSON format allows logs to be structured as a series of key-value pairs, enabling you to quickly search, filter, and analyze your function logs. You can also control the log level (e.g. ERROR, DEBUG, INFO, etc.) of your Lambda logs without making any code changes. This enables you to choose the desired logging granularity level for your function, eliminating the need to sift through large volumes of logs while debugging and troubleshooting critical errors. Lastly, you can choose the CloudWatch log group to which Lambda sends your logs. This allows you to easily aggregate logs from multiple functions within an application in one place, and apply security, governance, and retention policies at the application level, rather than applying them individually to every function.<br /> <br /> To get started, you can specify advanced logging controls for your Lambda functions using Lambda API, Lambda console, AWS CLI, AWS Serverless Application Model (SAM), and AWS CloudFormation. To learn more, visit the <a href=\"https://aws.amazon.com/blogs/compute/introducing-advanced-logging-controls-for-aws-lambda-functions/\" target=\"_blank\">launch blog post</a> or <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/monitoring-cloudwatchlogs.html#monitoring-cloudwatchlogs-advanced\" target=\"_blank\">Lambda Developer Guide</a>.<br /> <br /> Lambda advanced logging controls are now available in AWS GovCloud (US) Regions, at no additional cost. For more information, see the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Region table</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS Lambda announces advanced logging controls that enable you to natively capture logs in JSON structured format, adjust log levels, and select the Amazon CloudWatch log group for your Lambda functions.<br /> <br /> You can now capture your Lambda logs in JSON structured format without having to bring your own logging libraries. JSON format allows logs to be structured as a series of key-value pairs, enabling you to quickly search, filter, and analyze your function logs. You can also control the log level (e.g. ERROR, DEBUG, INFO, etc.) of your Lambda logs without making any code changes. This enables you to choose the desired logging granularity level for your function, eliminating the need to sift through large volumes of logs while debugging and troubleshooting critical errors. Lastly, you can choose the CloudWatch log group to which Lambda sends your logs. This allows you to easily aggregate logs from multiple functions within an application in one place, and apply security, governance, and retention policies at the application level, rather than applying them individually to every function.<br /> <br /> To get started, you can specify advanced logging controls for your Lambda functions using Lambda API, Lambda console, AWS CLI, AWS Serverless Application Model (SAM), and AWS CloudFormation. To learn more, visit the <a href=\"https://aws.amazon.com/blogs/compute/introducing-advanced-logging-controls-for-aws-lambda-functions/\" target=\"_blank\">launch blog post</a> or <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/monitoring-cloudwatchlogs.html#monitoring-cloudwatchlogs-advanced\" target=\"_blank\">Lambda Developer Guide</a>.<br /> <br /> Lambda advanced logging controls are now available in AWS GovCloud (US) Regions, at no additional cost. For more information, see the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Region table</a>.</p>"}, "published": "Wed, 03 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 3, 17, 0, 0, 2, 185, 0], "tags": [{"term": "general:products/aws-govcloud-us,marketing:marchitecture/serverless,general:products/aws-lambda", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-lambda-search-filter-aggregate-function-logs"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-lambda-search-filter-aggregate-function-logs"}
{"id": "63375510d97051fccf5ab3f7d3c6b3c2f30a2526", "guidislink": false, "title": "Amazon Q Developer is now generally available (GA) in the Visual Studio IDE", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Q Developer is now generally available (GA) in the Visual Studio IDE"}, "summary": "<p>Today, Amazon Web Services, Inc. launches the general availability of <a href=\"https://aws.amazon.com/q/developer/\" target=\"_blank\">Amazon Q Developer</a> in the Visual Studio IDE, available as part of the AWS Toolkit extension. You can now chat with Amazon Q about your project and ask Amazon Q to scan your project for security vulnerabilities.<br /> <br /> Amazon Q Developer helps simplify the software development lifecycle by answering questions about technical topics, generating code, and explaining code. You can ask Amazon Q to answer questions such as \u201cHow do I debug issues with my Lambda functions locally before deploying to AWS?\u201d. You can also request Amazon Q to generate code with prompts like \u201cGenerate test cases for [function name]\u201d, where you reference a function name in an open file.<br /> <br /> Amazon Q Developer can also keep your software secure by highlighting security vulnerabilities. You can click \u201cRun Security Scan\u201d from the margin menu, which will return with a list of vulnerabilities. Currently, security scans only support C#.<br /> <br /> You can ask Amazon Q questions, update your code, and initiate actions with quick commands all from the Amazon Q chat panel in your IDE. When you ask Amazon Q a question, it uses the current file that is open in your IDE as context, including the programming language and the file path.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, Amazon Web Services, Inc. launches the general availability of <a href=\"https://aws.amazon.com/q/developer/\" target=\"_blank\">Amazon Q Developer</a> in the Visual Studio IDE, available as part of the AWS Toolkit extension. You can now chat with Amazon Q about your project and ask Amazon Q to scan your project for security vulnerabilities.<br /> <br /> Amazon Q Developer helps simplify the software development lifecycle by answering questions about technical topics, generating code, and explaining code. You can ask Amazon Q to answer questions such as \u201cHow do I debug issues with my Lambda functions locally before deploying to AWS?\u201d. You can also request Amazon Q to generate code with prompts like \u201cGenerate test cases for [function name]\u201d, where you reference a function name in an open file.<br /> <br /> Amazon Q Developer can also keep your software secure by highlighting security vulnerabilities. You can click \u201cRun Security Scan\u201d from the margin menu, which will return with a list of vulnerabilities. Currently, security scans only support C#.<br /> <br /> You can ask Amazon Q questions, update your code, and initiate actions with quick commands all from the Amazon Q chat panel in your IDE. When you ask Amazon Q a question, it uses the current file that is open in your IDE as context, including the programming language and the file path.</p>"}, "published": "Wed, 03 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 3, 17, 0, 0, 2, 185, 0], "tags": [{"term": "general:products/amazon-q,marketing:marchitecture/artificial-intelligence,marketing:marchitecture/developer-tools", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-q-developer-ga-visual-studio-ide"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-q-developer-ga-visual-studio-ide"}
{"id": "e00f0809bbe20f64afbde13e911272913e629e44", "guidislink": false, "title": "AWS Lambda adds support for runtime management controls in the AWS GovCloud (US) Regions", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Lambda adds support for runtime management controls in the AWS GovCloud (US) Regions"}, "summary": "<p>AWS Lambda now supports runtime management controls in the AWS GovCloud (US) Regions. The operational simplicity of automatic runtime updates is one of the features customers most like about Lambda. This release provides customers running critical production workloads with more visibility and control over when runtime updates are applied to their functions.<br /> <br /> For each runtime, Lambda provides a managed execution environment which includes the underlying Amazon Linux OS, programming language runtime, and SDKs. Lambda takes care of applying patches and security updates to all these components. These runtime updates allow customers to delegate responsibility for patching from the customer to Lambda. With this release, the updates made to the managed runtimes provided by Lambda are now visible to customers as distinct runtime versions. Customers also have more control over when Lambda updates their functions to a new runtime version, either automatically or synchronized with customer-driven function updates. In the very rare event of an unexpected runtime incompatibility with an existing function, they can also roll back to an earlier runtime version.<br /> <br /> Visit our <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/runtimes-update.html\" target=\"_blank\">product documentation</a> for more information about runtime management controls. Sign in to the <a href=\"https://console.aws.amazon.com/lambda/home\" target=\"_blank\">AWS Lambda console</a> to get started.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS Lambda now supports runtime management controls in the AWS GovCloud (US) Regions. The operational simplicity of automatic runtime updates is one of the features customers most like about Lambda. This release provides customers running critical production workloads with more visibility and control over when runtime updates are applied to their functions.<br /> <br /> For each runtime, Lambda provides a managed execution environment which includes the underlying Amazon Linux OS, programming language runtime, and SDKs. Lambda takes care of applying patches and security updates to all these components. These runtime updates allow customers to delegate responsibility for patching from the customer to Lambda. With this release, the updates made to the managed runtimes provided by Lambda are now visible to customers as distinct runtime versions. Customers also have more control over when Lambda updates their functions to a new runtime version, either automatically or synchronized with customer-driven function updates. In the very rare event of an unexpected runtime incompatibility with an existing function, they can also roll back to an earlier runtime version.<br /> <br /> Visit our <a href=\"https://docs.aws.amazon.com/lambda/latest/dg/runtimes-update.html\" target=\"_blank\">product documentation</a> for more information about runtime management controls. Sign in to the <a href=\"https://console.aws.amazon.com/lambda/home\" target=\"_blank\">AWS Lambda console</a> to get started.</p>"}, "published": "Wed, 03 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 3, 17, 0, 0, 2, 185, 0], "tags": [{"term": "general:products/aws-govcloud-us,general:products/aws-lambda,marketing:marchitecture/serverless", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-lambda-runtime-management-controls-govcloud-regions"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-lambda-runtime-management-controls-govcloud-regions"}
{"id": "352b3982a8d8de39dc4dfe30e45795ed92d6bbff", "guidislink": false, "title": "Amazon DataZone introduces fine-grained access control", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon DataZone introduces fine-grained access control"}, "summary": "<p>Today, Amazon DataZone has introduced fine-grained access control, providing data owners granular control over their data at row and column levels. Customers use Amazon DataZone to catalog, discover, analyze, share, and govern data at scale across organizational boundaries with governance and access controls. Data owners can now restrict access to specific records of data, instead of granting access to the entire dataset. For example, if your table contains data for multiple regions, you can create row filters to grant access to rows with different regions to different projects. Additionally, column filters allow you to restrict access to specific columns, such as those containing Personally Identifiable Information (PII), ensuring that subscribers can only access the necessary and less sensitive data.<br /> <br /> To get started, you can create row and column filters within the Amazon DataZone portal. When a user requests access to your data asset, you can approve the subscription by applying the appropriate filters. Amazon DataZone enforces these filters using AWS Lake Formation and Amazon Redshift, ensuring that the subscriber can only access the rows and columns that you have authorized.<br /> <br /> Fine-grained access control support for both Amazon Redshift and AWS Lake Formation is now generally available in the following <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regions</a>: US East (Ohio), US East (N. Virginia), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Asia Pacific (Seoul), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (Stockholm), Europe (London), and South America (S\u00e3o Paulo).<br /> <br /> Learn more about fine-grained access control in the <a href=\"https://docs.aws.amazon.com/datazone/latest/userguide/fine-grained-access-control.html\" target=\"_blank\">user documentation</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, Amazon DataZone has introduced fine-grained access control, providing data owners granular control over their data at row and column levels. Customers use Amazon DataZone to catalog, discover, analyze, share, and govern data at scale across organizational boundaries with governance and access controls. Data owners can now restrict access to specific records of data, instead of granting access to the entire dataset. For example, if your table contains data for multiple regions, you can create row filters to grant access to rows with different regions to different projects. Additionally, column filters allow you to restrict access to specific columns, such as those containing Personally Identifiable Information (PII), ensuring that subscribers can only access the necessary and less sensitive data.<br /> <br /> To get started, you can create row and column filters within the Amazon DataZone portal. When a user requests access to your data asset, you can approve the subscription by applying the appropriate filters. Amazon DataZone enforces these filters using AWS Lake Formation and Amazon Redshift, ensuring that the subscriber can only access the rows and columns that you have authorized.<br /> <br /> Fine-grained access control support for both Amazon Redshift and AWS Lake Formation is now generally available in the following <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regions</a>: US East (Ohio), US East (N. Virginia), US West (Oregon), Asia Pacific (Singapore), Asia Pacific (Sydney), Asia Pacific (Tokyo), Asia Pacific (Seoul), Canada (Central), Europe (Frankfurt), Europe (Ireland), Europe (Stockholm), Europe (London), and South America (S\u00e3o Paulo).<br /> <br /> Learn more about fine-grained access control in the <a href=\"https://docs.aws.amazon.com/datazone/latest/userguide/fine-grained-access-control.html\" target=\"_blank\">user documentation</a>.<br /> &nbsp;</p>"}, "published": "Wed, 03 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 3, 17, 0, 0, 2, 185, 0], "tags": [{"term": "marketing:marchitecture/analytics,general:products/amazon-datazone", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-datazone-fine-grained-access-control/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-datazone-fine-grained-access-control/"}
{"id": "551aa1738aa2d92d6335adb858a5c300cdfd3b95", "guidislink": false, "title": "Amazon RDS now supports M6gd and R6gd database instances in the AWS GovCloud (US) Regions", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon RDS now supports M6gd and R6gd database instances in the AWS GovCloud (US) Regions"}, "summary": "<p><a href=\"https://aws.amazon.com/rds/\" target=\"_blank\">Amazon Relational Database Service (Amazon RDS)</a> for PostgreSQL, MySQL, and MariaDB now supports AWS Graviton2-based M6gd and R6gd database instances in the AWS GovCloud (US) Regions.<br /> <br /> With this regional expansion, M6gd instances are now available for Amazon RDS for PostgreSQL, MySQL, and MariaDB in US East (Ohio, N. Virginia), US West (Oregon), Asia Pacific (Hong Kong, Hyderabad, Jakarta, Melbourne, Mumbai, Osaka, Seoul, Singapore, Sydney, Tokyo), Canada (Calgary, Central), Europe (Frankfurt, Ireland, London, Milan, Paris, Spain, Stockholm, Zurich), Middle East (Bahrain, UAE), and the AWS GovCloud (US) Regions. R6gd instances are available for Amazon RDS for PostgreSQL, MySQL, and MariaDB in US East (Ohio, N. Virginia), US West (Oregon), Asia Pacific (Jakarta, Mumbai, Singapore, Sydney, Tokyo), Canada (Central), Europe (Frankfurt, Ireland, Paris), and the AWS GovCloud (US) Regions. For complete information on pricing and regional availability, please refer to the <a href=\"https://aws.amazon.com/rds/pricing/\" target=\"_blank\">Amazon RDS pricing page</a>.<br /> <br /> M6gd and R6gd database instances are available on Amazon RDS for PostgreSQL version 16.1 and higher, 15.2 and higher, 14.5 and higher, and 13.4 and higher. M6gd and R6gd database instances are available on Amazon RDS for MySQL version 8.0.32 and higher, and Amazon RDS for MariaDB version 10.11.4 and higher, 10.6.13 and higher, 10.5.20 and higher, and 10.4.29 and higher. Get started by creating a fully managed M6gd database instance using the Amazon RDS Management Console. For more details, refer to the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html\" target=\"_blank\">Amazon RDS User Guide</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://aws.amazon.com/rds/\" target=\"_blank\">Amazon Relational Database Service (Amazon RDS)</a> for PostgreSQL, MySQL, and MariaDB now supports AWS Graviton2-based M6gd and R6gd database instances in the AWS GovCloud (US) Regions.<br /> <br /> With this regional expansion, M6gd instances are now available for Amazon RDS for PostgreSQL, MySQL, and MariaDB in US East (Ohio, N. Virginia), US West (Oregon), Asia Pacific (Hong Kong, Hyderabad, Jakarta, Melbourne, Mumbai, Osaka, Seoul, Singapore, Sydney, Tokyo), Canada (Calgary, Central), Europe (Frankfurt, Ireland, London, Milan, Paris, Spain, Stockholm, Zurich), Middle East (Bahrain, UAE), and the AWS GovCloud (US) Regions. R6gd instances are available for Amazon RDS for PostgreSQL, MySQL, and MariaDB in US East (Ohio, N. Virginia), US West (Oregon), Asia Pacific (Jakarta, Mumbai, Singapore, Sydney, Tokyo), Canada (Central), Europe (Frankfurt, Ireland, Paris), and the AWS GovCloud (US) Regions. For complete information on pricing and regional availability, please refer to the <a href=\"https://aws.amazon.com/rds/pricing/\" target=\"_blank\">Amazon RDS pricing page</a>.<br /> <br /> M6gd and R6gd database instances are available on Amazon RDS for PostgreSQL version 16.1 and higher, 15.2 and higher, 14.5 and higher, and 13.4 and higher. M6gd and R6gd database instances are available on Amazon RDS for MySQL version 8.0.32 and higher, and Amazon RDS for MariaDB version 10.11.4 and higher, 10.6.13 and higher, 10.5.20 and higher, and 10.4.29 and higher. Get started by creating a fully managed M6gd database instance using the Amazon RDS Management Console. For more details, refer to the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.DBInstanceClass.html\" target=\"_blank\">Amazon RDS User Guide</a>.<br /> &nbsp;</p>"}, "published": "Wed, 03 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 3, 17, 0, 0, 2, 185, 0], "tags": [{"term": "general:products/amazon-rds,marketing:marchitecture/databases,general:products/aws-govcloud-us", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-rds-m6gd-r6gd-database-instances-govcloud/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-rds-m6gd-r6gd-database-instances-govcloud/"}
{"id": "159d4aa7de3ac9bd821464396e9d6902c6c7a193", "guidislink": false, "title": "AWS Launch Wizard now adds programmatic deployments through APIs and Cloudformation templates", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Launch Wizard now adds programmatic deployments through APIs and Cloudformation templates"}, "summary": "<p>AWS Launch Wizard now enables customers to programmatically deploy workloads on AWS using Application Programming Interface (API) or CloudFormation templates while still leveraging built-in automation and best practice recommendations. With this launch, customers now have a choice to deploy third-party applications on AWS such as SQL Server - SingleNode, HA, or FCI, SAP, and all supported workloads through AWS Launch Wizard APIs or CloudFormation resources, in addition to the existing console-based experience. Additionally, AWS Launch Wizard has also introduced APIs to programmatically retrieve application specifications for a simplified deployment experience.<br /> <br /> AWS Launch Wizard offers a guided way of sizing, configuring, and deploying AWS resources for third party applications, such as Microsoft SQL Server Always On and HANA based SAP systems, without the need to manually identify and provision individual AWS resources.<br /> <br /> AWS Launch Wizard is available in 29 Regions including US East (N. Virginia, Ohio), Europe (Frankfurt, Ireland, London, Paris, Stockholm and Milan), South America (Sao Paulo), US West (N. California, Oregon), Canada (Central), Asia Pacific (Mumbai, Seoul, Tokyo, Hong Kong, Hyderabad, Singapore, and Sydney), Middle East (Bahrain, UAE), Africa (Cape Town), Europe (Spain), Europe (Zurich), Asia Pacific (Melbourne), China (Beijing, operated by Sinnet), China (Ningxia, operated by NWCD), and the AWS GovCloud (US) Regions.<br /> <br /> To learn more about AWS Launch Wizard, visit the <a href=\"https://aws.amazon.com/launchwizard/\" target=\"_blank\">Launch Wizard Page</a>. To get started, check out the<a href=\"https://docs.aws.amazon.com/launchwizard/\" target=\"_blank\"> Launch Wizard User Guide</a> and the <a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-launchwizard-deployment.html\" target=\"_blank\">API Page</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS Launch Wizard now enables customers to programmatically deploy workloads on AWS using Application Programming Interface (API) or CloudFormation templates while still leveraging built-in automation and best practice recommendations. With this launch, customers now have a choice to deploy third-party applications on AWS such as SQL Server - SingleNode, HA, or FCI, SAP, and all supported workloads through AWS Launch Wizard APIs or CloudFormation resources, in addition to the existing console-based experience. Additionally, AWS Launch Wizard has also introduced APIs to programmatically retrieve application specifications for a simplified deployment experience.<br /> <br /> AWS Launch Wizard offers a guided way of sizing, configuring, and deploying AWS resources for third party applications, such as Microsoft SQL Server Always On and HANA based SAP systems, without the need to manually identify and provision individual AWS resources.<br /> <br /> AWS Launch Wizard is available in 29 Regions including US East (N. Virginia, Ohio), Europe (Frankfurt, Ireland, London, Paris, Stockholm and Milan), South America (Sao Paulo), US West (N. California, Oregon), Canada (Central), Asia Pacific (Mumbai, Seoul, Tokyo, Hong Kong, Hyderabad, Singapore, and Sydney), Middle East (Bahrain, UAE), Africa (Cape Town), Europe (Spain), Europe (Zurich), Asia Pacific (Melbourne), China (Beijing, operated by Sinnet), China (Ningxia, operated by NWCD), and the AWS GovCloud (US) Regions.<br /> <br /> To learn more about AWS Launch Wizard, visit the <a href=\"https://aws.amazon.com/launchwizard/\" target=\"_blank\">Launch Wizard Page</a>. To get started, check out the<a href=\"https://docs.aws.amazon.com/launchwizard/\" target=\"_blank\"> Launch Wizard User Guide</a> and the <a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-launchwizard-deployment.html\" target=\"_blank\">API Page</a>.<br /> &nbsp;</p>"}, "published": "Wed, 03 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 3, 17, 0, 0, 2, 185, 0], "tags": [{"term": "general:products/aws-launch-wizard,marketing:marchitecture/management-and-governance", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-launch-wizard-deployments-apis-cloudformation-templates/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-launch-wizard-deployments-apis-cloudformation-templates/"}
{"id": "815920147613325584be4e1a67686e3da41f8b2b", "guidislink": false, "title": "AWS Private CA is now available in the Beijing and Ningxia Regions in China", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Private CA is now available in the Beijing and Ningxia Regions in China"}, "summary": "<p>AWS Private Certificate Authority (AWS Private CA) is now available in the AWS China (Beijing) Region, operated by Sinnet, and in the AWS China (Ningxia) Region, operated by NWCD. AWS Private CA is a managed, highly-available, cloud certificate authority (CA) with private keys secured in AWS-managed hardware security modules (HSMs). By using AWS Private CA, you can reduce the operational costs and complexity of using public key infrastructure (PKI) at scale across industries and use cases including financial services, automotive, manufacturing, healthcare, electronics, technology, energy, and smart home.<br /> <br /> AWS Private CA enables you to create customizable private certificates for a broad range of scenarios. AWS services such as AWS Certificate Manager, Amazon Managed Streaming for Apache Kafka (MSK), AWS IAM Roles Anywhere and Amazon Elastic Kubernetes Service (EKS) can all leverage private certificates from AWS Private CA. You can use AWS Private CA to create private certificates for Internet of Things (IoT) devices including Matter smart home devices.<br /> <br /> For regions where AWS Private CA is available, see <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Services by Region</a>.<br /> <br /> To learn more about AWS Private CA, visit the <a href=\"https://aws.amazon.com/private-ca/\" target=\"_blank\">product page</a> and <a href=\"https://docs.aws.amazon.com/privateca/latest/userguide/PcaWelcome.html\" target=\"_blank\">documentation</a>. To learn how to use AWS Private CA to create and operate Matter-compliant CAs, see <a href=\"https://docs.aws.amazon.com/privateca/latest/userguide/matter.html\" target=\"_blank\">Using the Matter standard</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS Private Certificate Authority (AWS Private CA) is now available in the AWS China (Beijing) Region, operated by Sinnet, and in the AWS China (Ningxia) Region, operated by NWCD. AWS Private CA is a managed, highly-available, cloud certificate authority (CA) with private keys secured in AWS-managed hardware security modules (HSMs). By using AWS Private CA, you can reduce the operational costs and complexity of using public key infrastructure (PKI) at scale across industries and use cases including financial services, automotive, manufacturing, healthcare, electronics, technology, energy, and smart home.<br /> <br /> AWS Private CA enables you to create customizable private certificates for a broad range of scenarios. AWS services such as AWS Certificate Manager, Amazon Managed Streaming for Apache Kafka (MSK), AWS IAM Roles Anywhere and Amazon Elastic Kubernetes Service (EKS) can all leverage private certificates from AWS Private CA. You can use AWS Private CA to create private certificates for Internet of Things (IoT) devices including Matter smart home devices.<br /> <br /> For regions where AWS Private CA is available, see <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Services by Region</a>.<br /> <br /> To learn more about AWS Private CA, visit the <a href=\"https://aws.amazon.com/private-ca/\" target=\"_blank\">product page</a> and <a href=\"https://docs.aws.amazon.com/privateca/latest/userguide/PcaWelcome.html\" target=\"_blank\">documentation</a>. To learn how to use AWS Private CA to create and operate Matter-compliant CAs, see <a href=\"https://docs.aws.amazon.com/privateca/latest/userguide/matter.html\" target=\"_blank\">Using the Matter standard</a>.<br /> &nbsp;</p>"}, "published": "Tue, 02 Jul 2024 18:00:00 GMT", "published_parsed": [2024, 7, 2, 18, 0, 0, 1, 184, 0], "tags": [{"term": "marketing:marchitecture/security-identity-and-compliance", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-private-ca-beijing-ningxia-regions"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-private-ca-beijing-ningxia-regions"}
{"id": "137b190da61bbab97f06b011c921ea3e74f719f4", "guidislink": false, "title": "AWS Managed Services (AMS) Accelerate now includes Trusted Remediator", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Managed Services (AMS) Accelerate now includes Trusted Remediator"}, "summary": "<p>AWS Managed Services (AMS) Accelerate customers can now use Trusted Remediator to automatically remediate recommendations based on Trusted Advisor checks. By eliminating human effort required to fix misconfigurations on the accounts, Trusted Remediator improves security, fault tolerance, performance, while simultaneously reducing cost for AMS customers. AMS helps you operate AWS efficiently and securely. It extends your operations team\u2019s capabilities with operational and security monitoring, incident detection and management, patch, backup, and cost optimization.<br /> <br /> Trusted Remediator uses tested and proven automation solutions to not only minimize security risks but also scales operations processes by consistently providing quality remediations. Examples of supported checks include underutilized Amazon EBS Volumes and Amazon Redshift should have automatic upgrades to major versions enabled. Trusted Remediator provides customers with the flexibility to configure remediations across single or multiple accounts. Customers can choose to remediate checks at the account level or resource level, with the ability to apply tag-based exceptions.<br /> <br /> To learn more, see <a href=\"https://docs.aws.amazon.com/managedservices/latest/accelerate-guide/trusted-remediator.html\" target=\"_blank\">Trusted Remediator</a>. Learn more about AMS <a href=\"https://aws.amazon.com/managed-services/\" target=\"_blank\"><u>here</u></a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS Managed Services (AMS) Accelerate customers can now use Trusted Remediator to automatically remediate recommendations based on Trusted Advisor checks. By eliminating human effort required to fix misconfigurations on the accounts, Trusted Remediator improves security, fault tolerance, performance, while simultaneously reducing cost for AMS customers. AMS helps you operate AWS efficiently and securely. It extends your operations team\u2019s capabilities with operational and security monitoring, incident detection and management, patch, backup, and cost optimization.<br /> <br /> Trusted Remediator uses tested and proven automation solutions to not only minimize security risks but also scales operations processes by consistently providing quality remediations. Examples of supported checks include underutilized Amazon EBS Volumes and Amazon Redshift should have automatic upgrades to major versions enabled. Trusted Remediator provides customers with the flexibility to configure remediations across single or multiple accounts. Customers can choose to remediate checks at the account level or resource level, with the ability to apply tag-based exceptions.<br /> <br /> To learn more, see <a href=\"https://docs.aws.amazon.com/managedservices/latest/accelerate-guide/trusted-remediator.html\" target=\"_blank\">Trusted Remediator</a>. Learn more about AMS <a href=\"https://aws.amazon.com/managed-services/\" target=\"_blank\"><u>here</u></a>.</p>"}, "published": "Tue, 02 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 2, 17, 0, 0, 1, 184, 0], "tags": [{"term": "marketing:marchitecture/management-and-governance,general:products/aws-managed-services", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-managed-services-accelerate-trusted-remediator/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-managed-services-accelerate-trusted-remediator/"}
{"id": "6eb1941de9dc4ebde47cad9a71e91dcdafb10e3e", "guidislink": false, "title": "RDS for Db2 now supports Private Offers on licensing through AWS Marketplace", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "RDS for Db2 now supports Private Offers on licensing through AWS Marketplace"}, "summary": "<p>Amazon RDS for Db2 customers using hourly Db2 licensing through AWS Marketplace can now obtain customized contract terms from IBM, using <a href=\"https://aws.amazon.com/marketplace/partners/private-offers\" target=\"_blank\">AWS Marketplace Private Offers</a>. This complements the existing options of <a href=\"https://aws.amazon.com/about-aws/whats-new/2024/05/amazon-rds-db2-hourly-licensing-ibm-aws-marketplace/\" target=\"_blank\">using the public hourly license price</a> to get started instantly, or using the Bring-Your-Own-License (BYOL) option.<br /> <br /> Customers can request a Private Offer from IBM and, if available, get individualized quotes on Db2 hourly licensing through AWS Marketplace.<br /> <br /> <a href=\"https://aws.amazon.com/rds/db2/\" target=\"_blank\">Amazon RDS for Db2</a> makes it easy to set up, operate, and scale Db2 databases in the cloud. See the <a href=\"https://aws.amazon.com/rds/db2/pricing/\" target=\"_blank\">Amazon RDS for Db2 Pricing page</a> for pricing and regional availability information. To learn more about the AWS Marketplace license option, visit the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/db2-licensing.html#db2-licensing-options-marketplace\" target=\"_blank\">AWS Documentation</a> to get started.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon RDS for Db2 customers using hourly Db2 licensing through AWS Marketplace can now obtain customized contract terms from IBM, using <a href=\"https://aws.amazon.com/marketplace/partners/private-offers\" target=\"_blank\">AWS Marketplace Private Offers</a>. This complements the existing options of <a href=\"https://aws.amazon.com/about-aws/whats-new/2024/05/amazon-rds-db2-hourly-licensing-ibm-aws-marketplace/\" target=\"_blank\">using the public hourly license price</a> to get started instantly, or using the Bring-Your-Own-License (BYOL) option.<br /> <br /> Customers can request a Private Offer from IBM and, if available, get individualized quotes on Db2 hourly licensing through AWS Marketplace.<br /> <br /> <a href=\"https://aws.amazon.com/rds/db2/\" target=\"_blank\">Amazon RDS for Db2</a> makes it easy to set up, operate, and scale Db2 databases in the cloud. See the <a href=\"https://aws.amazon.com/rds/db2/pricing/\" target=\"_blank\">Amazon RDS for Db2 Pricing page</a> for pricing and regional availability information. To learn more about the AWS Marketplace license option, visit the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/db2-licensing.html#db2-licensing-options-marketplace\" target=\"_blank\">AWS Documentation</a> to get started.<br /> &nbsp;</p>"}, "published": "Tue, 02 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 2, 17, 0, 0, 1, 184, 0], "tags": [{"term": "general:products/amazon-rds,marketing:marchitecture/databases", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/rds-db2-private-offers-licensing-aws-marketplace/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/rds-db2-private-offers-licensing-aws-marketplace/"}
{"id": "6126dd45a04ca378ae07465330c88f6f5feadf82", "guidislink": false, "title": "Elastic Fabric Adapter (EFA) now supports cross-subnet communication", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Elastic Fabric Adapter (EFA) now supports cross-subnet communication"}, "summary": "<p>We are excited to announce that AWS now supports cross-subnet communication between <a href=\"https://aws.amazon.com/hpc/efa/\" target=\"_blank\">Elastic Fabric Adapter (EFA)</a> interfaces for Amazon EC2 instances within the same Availability Zone (AZ). This enhancement makes it possible to communicate with EC2 instances across subnets while benefiting from the low latency and high throughput provided by EFA. EFA is a network device that you can attach to your Amazon EC2 instance to accelerate High Performance Computing (HPC) and Machine Learning (ML) applications.<br /> <br /> Previously, EFA traffic was limited to the same subnet, thus requiring all instances to be configured within a single subnet. With this update, you have the option to send traffic over EFA across subnets for both existing and new instances. To take advantage of this capability, you need to configure your security group rules to allow traffic to and from security groups of instances from other subnets. You will also need to ensure your application configuration and orchestration logic accounts for hosts from other subnets when provisioning and managing EFA-enabled instances to communicate across subnets over EFA.<br /> <br /> The cross-subnet communication support over EFA is available in all AWS commercial regions, the AWS GovCloud (US) regions, and the Amazon Web Services China (Beijing) region, operated by Sinnet, and the Amazon Web Services China (Ningxia) region, operated by NWCD. For more information about EFA, please visit <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/efa.html\" target=\"_blank\">EFA documentation page</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>We are excited to announce that AWS now supports cross-subnet communication between <a href=\"https://aws.amazon.com/hpc/efa/\" target=\"_blank\">Elastic Fabric Adapter (EFA)</a> interfaces for Amazon EC2 instances within the same Availability Zone (AZ). This enhancement makes it possible to communicate with EC2 instances across subnets while benefiting from the low latency and high throughput provided by EFA. EFA is a network device that you can attach to your Amazon EC2 instance to accelerate High Performance Computing (HPC) and Machine Learning (ML) applications.<br /> <br /> Previously, EFA traffic was limited to the same subnet, thus requiring all instances to be configured within a single subnet. With this update, you have the option to send traffic over EFA across subnets for both existing and new instances. To take advantage of this capability, you need to configure your security group rules to allow traffic to and from security groups of instances from other subnets. You will also need to ensure your application configuration and orchestration logic accounts for hosts from other subnets when provisioning and managing EFA-enabled instances to communicate across subnets over EFA.<br /> <br /> The cross-subnet communication support over EFA is available in all AWS commercial regions, the AWS GovCloud (US) regions, and the Amazon Web Services China (Beijing) region, operated by Sinnet, and the Amazon Web Services China (Ningxia) region, operated by NWCD. For more information about EFA, please visit <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/efa.html\" target=\"_blank\">EFA documentation page</a>.<br /> &nbsp;</p>"}, "published": "Tue, 02 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 2, 17, 0, 0, 1, 184, 0], "tags": [{"term": "general:products/elastic-fabric-adapter,general:products/aws-govcloud-us,marketing:marchitecture/networking-and-content-delivery", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/elastic-fabric-adapter-cross-subnet-communication/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/elastic-fabric-adapter-cross-subnet-communication/"}
{"id": "b500813c533d063af901508083ffbf877bbf527d", "guidislink": false, "title": "Amazon EKS natively supports EC2 capacity blocks for ML", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon EKS natively supports EC2 capacity blocks for ML"}, "summary": "<p>You can now use Amazon EC2 instances reserved using Capacity Blocks for ML natively in Amazon EKS clusters with managed node groups. EKS managed node groups make it easy to run highly-available and secure Kubernetes clusters by automating the provisioning and lifecycle of cluster worker nodes. EC2 Capacity Blocks provide you with assured and predictable access to GPU instances for your artificial intelligence / machine learning (AI/ML) workloads.<br /> <br /> Customers increasingly choose Kubernetes as the platform for their AI/ML workloads and Amazon EKS lets them combine the benefits of Kubernetes with the security, scalability, and availability of the AWS cloud. Native support for EC2 Capacity Blocks in Amazon EKS simplifies capacity planning for cutting-edge AI/ML workloads in Kubernetes clusters, helping to ensure that GPU capacity is available when and where it\u2019s needed. To get started, create an EKS managed node group with an EC2 Launch Template targeting a Capacity Block reservation so that the reserved GPU capacity will be accessible in the EKS cluster when the reservation becomes active. EC2 Capacity Blocks can be reserved up to eight weeks in advance and for just the amount of time that you require the instances.<br /> <br /> Native EKS support for EC2 Capacity Blocks via managed node groups is available in the US East (Ohio), US East (N. Virginia), and US West (Oregon) <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\" target=\"_blank\">AWS Regions</a>. Read more about Amazon EKS support for EC2 Capacity Blocks for ML in the <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html\" target=\"_blank\">Amazon EKS User Guide</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>You can now use Amazon EC2 instances reserved using Capacity Blocks for ML natively in Amazon EKS clusters with managed node groups. EKS managed node groups make it easy to run highly-available and secure Kubernetes clusters by automating the provisioning and lifecycle of cluster worker nodes. EC2 Capacity Blocks provide you with assured and predictable access to GPU instances for your artificial intelligence / machine learning (AI/ML) workloads.<br /> <br /> Customers increasingly choose Kubernetes as the platform for their AI/ML workloads and Amazon EKS lets them combine the benefits of Kubernetes with the security, scalability, and availability of the AWS cloud. Native support for EC2 Capacity Blocks in Amazon EKS simplifies capacity planning for cutting-edge AI/ML workloads in Kubernetes clusters, helping to ensure that GPU capacity is available when and where it\u2019s needed. To get started, create an EKS managed node group with an EC2 Launch Template targeting a Capacity Block reservation so that the reserved GPU capacity will be accessible in the EKS cluster when the reservation becomes active. EC2 Capacity Blocks can be reserved up to eight weeks in advance and for just the amount of time that you require the instances.<br /> <br /> Native EKS support for EC2 Capacity Blocks via managed node groups is available in the US East (Ohio), US East (N. Virginia), and US West (Oregon) <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regions_az/\" target=\"_blank\">AWS Regions</a>. Read more about Amazon EKS support for EC2 Capacity Blocks for ML in the <a href=\"https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html\" target=\"_blank\">Amazon EKS User Guide</a>.<br /> &nbsp;</p>"}, "published": "Tue, 02 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 2, 17, 0, 0, 1, 184, 0], "tags": [{"term": "marketing:marchitecture/compute,general:products/amazon-eks", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-eks-natively-ec2-capacity-blocks-for-ml/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-eks-natively-ec2-capacity-blocks-for-ml/"}
{"id": "ad40daeef61970f06e6bd86cc7784b25d46c1447", "guidislink": false, "title": "Amazon MQ now supports RabbitMQ version 3.13", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon MQ now supports RabbitMQ version 3.13"}, "summary": "<p>Amazon MQ now provides support for RabbitMQ version 3.13, which includes several fixes and performance improvements to the previous versions of RabbitMQ supported by Amazon MQ. Starting from RabbitMQ 3.13, Amazon MQ will manage patch version upgrades for your brokers. All brokers on version 3.13 will be automatically upgraded to the latest compatible and secure patch version in your scheduled maintenance window.<br /> <br /> If you are running earlier versions of RabbitMQ, such as 3.8, 3.9, 3.10, 3.11 or 3.12, we strongly encourage you to upgrade to RabbitMQ 3.13. This can be accomplished with just a few clicks in the <a href=\"https://console.aws.amazon.com/amazon-mq/home\" target=\"_blank\">AWS Management Console</a>. Amazon MQ for RabbitMQ will soon end support for RabbitMQ versions 3.8, 3.9 and 3.10. To learn more about upgrading, see <a href=\"https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/rabbitmq-version-management.html\" target=\"_blank\">Managing Amazon MQ for RabbitMQ engine versions</a> in the Amazon MQ Developer Guide. To learn more about the changes in RabbitMQ 3.13, see the <a href=\"https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/amazon-mq-release-notes.html\" target=\"_blank\">Amazon MQ release notes</a>. This version is available in all the regions Amazon MQ is available in. For a full list of available regions see the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Region Table</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon MQ now provides support for RabbitMQ version 3.13, which includes several fixes and performance improvements to the previous versions of RabbitMQ supported by Amazon MQ. Starting from RabbitMQ 3.13, Amazon MQ will manage patch version upgrades for your brokers. All brokers on version 3.13 will be automatically upgraded to the latest compatible and secure patch version in your scheduled maintenance window.<br /> <br /> If you are running earlier versions of RabbitMQ, such as 3.8, 3.9, 3.10, 3.11 or 3.12, we strongly encourage you to upgrade to RabbitMQ 3.13. This can be accomplished with just a few clicks in the <a href=\"https://console.aws.amazon.com/amazon-mq/home\" target=\"_blank\">AWS Management Console</a>. Amazon MQ for RabbitMQ will soon end support for RabbitMQ versions 3.8, 3.9 and 3.10. To learn more about upgrading, see <a href=\"https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/rabbitmq-version-management.html\" target=\"_blank\">Managing Amazon MQ for RabbitMQ engine versions</a> in the Amazon MQ Developer Guide. To learn more about the changes in RabbitMQ 3.13, see the <a href=\"https://docs.aws.amazon.com/amazon-mq/latest/developer-guide/amazon-mq-release-notes.html\" target=\"_blank\">Amazon MQ release notes</a>. This version is available in all the regions Amazon MQ is available in. For a full list of available regions see the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Region Table</a>.<br /> &nbsp;</p>"}, "published": "Tue, 02 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 2, 17, 0, 0, 1, 184, 0], "tags": [{"term": "general:products/amazon-mq,marketing:marchitecture/application-services", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-mq-rabbitmq-version-3-13/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-mq-rabbitmq-version-3-13/"}
{"id": "14b9c820a94bea6455a765b81b53223046ca2d35", "guidislink": false, "title": "AWS Direct Connect announces native 400 Gbps Dedicated Connections at select locations", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Direct Connect announces native 400 Gbps Dedicated Connections at select locations"}, "summary": "<p>AWS Direct Connect now offers native 400 Gbps Dedicated Connections to support your private connectivity needs to the cloud.<br /> <br /> AWS Direct Connect provides private, high-bandwidth connectivity between AWS and your data center, office, or colocation facility. Native 400 Gbps connections provide higher bandwidth, without the operational overhead of managing multiple 100 Gbps connections in a link aggregation group. The increased capacity delivered by 400 Gbps connections is particularly beneficial to applications that transfer large-scale datasets, such as for machine learning and large language model training or advanced driver assistance systems for autonomous vehicles.<br /> <br /> For production workloads, AWS recommends using connections in more than one AWS Direct Connect location to ensure resilience against device or colocation failure. To get started, follow our <a href=\"https://aws.amazon.com/directconnect/resiliency-recommendation/\" target=\"_blank\">Resiliency Recommendations</a> to determine the best resiliency model for your use case. After selecting a resiliency model, the <a href=\"https://docs.aws.amazon.com/directconnect/latest/UserGuide/resiliency_toolkit.html\" target=\"_blank\">AWS Direct Connect Resiliency Toolkit</a> can guide you through the process for ordering redundant connectivity through the AWS Direct Connect Console or CLI/APIs. AWS encourages you to use the Resiliency Toolkit failover test feature to test your configurations before going live and set up active health monitoring using Amazon <a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/what-is-network-monitor.html\" target=\"_blank\">CloudWatch Network Monitor</a>.<br /> <br /> Starting today, 400 Gbps Dedicated Connections are available at <a href=\"https://aws.amazon.com/directconnect/locations/\" target=\"_blank\">these locations</a>. This list will be updated as 400 Gbps Dedicated Connections are made available at additional locations. The AWS Direct Connect <a href=\"https://aws.amazon.com/directconnect/pricing/\" target=\"_blank\">pricing page</a> has pricing information for 400 Gbps Dedicated Connections and the Direct Connect User Guide provides setup instructions.<br /> <br /> Sign into the Direct Connect Console today to order your 400 Gbps Dedicated Connection!</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS Direct Connect now offers native 400 Gbps Dedicated Connections to support your private connectivity needs to the cloud.<br /> <br /> AWS Direct Connect provides private, high-bandwidth connectivity between AWS and your data center, office, or colocation facility. Native 400 Gbps connections provide higher bandwidth, without the operational overhead of managing multiple 100 Gbps connections in a link aggregation group. The increased capacity delivered by 400 Gbps connections is particularly beneficial to applications that transfer large-scale datasets, such as for machine learning and large language model training or advanced driver assistance systems for autonomous vehicles.<br /> <br /> For production workloads, AWS recommends using connections in more than one AWS Direct Connect location to ensure resilience against device or colocation failure. To get started, follow our <a href=\"https://aws.amazon.com/directconnect/resiliency-recommendation/\" target=\"_blank\">Resiliency Recommendations</a> to determine the best resiliency model for your use case. After selecting a resiliency model, the <a href=\"https://docs.aws.amazon.com/directconnect/latest/UserGuide/resiliency_toolkit.html\" target=\"_blank\">AWS Direct Connect Resiliency Toolkit</a> can guide you through the process for ordering redundant connectivity through the AWS Direct Connect Console or CLI/APIs. AWS encourages you to use the Resiliency Toolkit failover test feature to test your configurations before going live and set up active health monitoring using Amazon <a href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/what-is-network-monitor.html\" target=\"_blank\">CloudWatch Network Monitor</a>.<br /> <br /> Starting today, 400 Gbps Dedicated Connections are available at <a href=\"https://aws.amazon.com/directconnect/locations/\" target=\"_blank\">these locations</a>. This list will be updated as 400 Gbps Dedicated Connections are made available at additional locations. The AWS Direct Connect <a href=\"https://aws.amazon.com/directconnect/pricing/\" target=\"_blank\">pricing page</a> has pricing information for 400 Gbps Dedicated Connections and the Direct Connect User Guide provides setup instructions.<br /> <br /> Sign into the Direct Connect Console today to order your 400 Gbps Dedicated Connection!</p>"}, "published": "Mon, 01 Jul 2024 22:00:00 GMT", "published_parsed": [2024, 7, 1, 22, 0, 0, 0, 183, 0], "tags": [{"term": "marketing:marchitecture/networking,general:products/aws-direct-connect", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-direct-connect-native-400-gbps-dedicated-connections-select-locations"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-direct-connect-native-400-gbps-dedicated-connections-select-locations"}
{"id": "7554cf4420af5185c7d716eac270bd2d07c1cc5b", "guidislink": false, "title": "Amazon OpenSearch Ingestion adds support for ingesting data from self-managed sources", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon OpenSearch Ingestion adds support for ingesting data from self-managed sources"}, "summary": "<p>Amazon OpenSearch Ingestion now allows you to ingest data from self-managed OpenSearch, Elasticsearch and Apache Kafka clusters, eliminating the need to run and manage 3rd party tools like Logstash to migrate your data from self-managed sources into Amazon OpenSearch Service. Now you can seamlessly migrate or continuously replicate your data from all OpenSearch versions and Elasticsearch 7.x versions either on Amazon EC2 or on-premises environments into Amazon OpenSearch Service managed clusters or Serverless collections.<br /> <br /> You can now migrate data from all indices, or just specific indices, from one or more self-managed OpenSearch/Elasticsearch clusters to one or more Amazon OpenSearch Service managed clusters or Serverless collections. Amazon OpenSearch Ingestion will continually detect new indices in the self-managed source cluster that need to be processed and can even be scheduled to reprocess indices at a configurable interval to pick up on new documents. Similarly, Amazon OpenSearch Ingestion pipelines can consume data from one or more topics in your self-managed Kafka cluster and transform the data before writing it to Amazon OpenSearch Service or Amazon S3. You can check out the complete list of features in this blog <a href=\"https://aws.amazon.com/blogs/big-data/introducing-self-managed-data-sources-for-amazon-opensearch-ingestion/\" target=\"_blank\">post</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon OpenSearch Ingestion now allows you to ingest data from self-managed OpenSearch, Elasticsearch and Apache Kafka clusters, eliminating the need to run and manage 3rd party tools like Logstash to migrate your data from self-managed sources into Amazon OpenSearch Service. Now you can seamlessly migrate or continuously replicate your data from all OpenSearch versions and Elasticsearch 7.x versions either on Amazon EC2 or on-premises environments into Amazon OpenSearch Service managed clusters or Serverless collections.<br /> <br /> You can now migrate data from all indices, or just specific indices, from one or more self-managed OpenSearch/Elasticsearch clusters to one or more Amazon OpenSearch Service managed clusters or Serverless collections. Amazon OpenSearch Ingestion will continually detect new indices in the self-managed source cluster that need to be processed and can even be scheduled to reprocess indices at a configurable interval to pick up on new documents. Similarly, Amazon OpenSearch Ingestion pipelines can consume data from one or more topics in your self-managed Kafka cluster and transform the data before writing it to Amazon OpenSearch Service or Amazon S3. You can check out the complete list of features in this blog <a href=\"https://aws.amazon.com/blogs/big-data/introducing-self-managed-data-sources-for-amazon-opensearch-ingestion/\" target=\"_blank\">post</a>.</p>"}, "published": "Mon, 01 Jul 2024 19:55:00 GMT", "published_parsed": [2024, 7, 1, 19, 55, 0, 0, 183, 0], "tags": [{"term": "marketing:marchitecture/analytics,marketing:marchitecture/serverless,general:products/amazon-opensearch-service", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-opensearch-ingesting-data-self-managed-sources"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-opensearch-ingesting-data-self-managed-sources"}
{"id": "7cd78a08b3f79ad21b481bfdefeb2bcd02d5cd68", "guidislink": false, "title": "Announcing streamlined Migration Acceleration Program (MAP) funding and approval process in AWS Partner Central", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Announcing streamlined Migration Acceleration Program (MAP) funding and approval process in AWS Partner Central"}, "summary": "<p>Today, Amazon Web Services, Inc. (AWS) announces a new Migration Acceleration Program (MAP) template in AWS Partner Central with streamlined funding and approval processes to better support partner-led migrations. Eligible AWS Partners can leverage MAP to accelerate more customer migration opportunities, now scaling to support migrations up to $10M in annual recurring revenue, with a simple approval workflow and access to new Strategic Partner Incentives (SPIs).<br /> <br /> The new MAP template helps partners accelerate migration opportunities by providing better speed to market with fewer AWS approval stages. The simplified partner experience for submitting fund requests and cash claims in AWS Partner Funding Portal (APFP) automatically creates claim milestones and associates them with realized revenue outcomes for the MAP Mobilize phase. This improves overall partner productivity by avoiding the need to manually create individual claim milestones. The new MAP template also supports additional SPIs for new customer engagement and modernization opportunities. Partners can now easily get visibility to their funding investment status through Analytics tab in AWS Partner Central.<br /> <br /> The MAP template can be accessed by all partners at the Validated Stage in AWS Partner Central and AWS Migration Competency Partners. To learn more, review the<a href=\"https://partnercentral.awspartner.com/partnercentral2/s/resources?Id=0690h000008hPVmAAM\" target=\"_blank\"> 2024 MAP program guide.</a><br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, Amazon Web Services, Inc. (AWS) announces a new Migration Acceleration Program (MAP) template in AWS Partner Central with streamlined funding and approval processes to better support partner-led migrations. Eligible AWS Partners can leverage MAP to accelerate more customer migration opportunities, now scaling to support migrations up to $10M in annual recurring revenue, with a simple approval workflow and access to new Strategic Partner Incentives (SPIs).<br /> <br /> The new MAP template helps partners accelerate migration opportunities by providing better speed to market with fewer AWS approval stages. The simplified partner experience for submitting fund requests and cash claims in AWS Partner Funding Portal (APFP) automatically creates claim milestones and associates them with realized revenue outcomes for the MAP Mobilize phase. This improves overall partner productivity by avoiding the need to manually create individual claim milestones. The new MAP template also supports additional SPIs for new customer engagement and modernization opportunities. Partners can now easily get visibility to their funding investment status through Analytics tab in AWS Partner Central.<br /> <br /> The MAP template can be accessed by all partners at the Validated Stage in AWS Partner Central and AWS Migration Competency Partners. To learn more, review the<a href=\"https://partnercentral.awspartner.com/partnercentral2/s/resources?Id=0690h000008hPVmAAM\" target=\"_blank\"> 2024 MAP program guide.</a><br /> &nbsp;</p>"}, "published": "Mon, 01 Jul 2024 18:20:00 GMT", "published_parsed": [2024, 7, 1, 18, 20, 0, 0, 183, 0], "tags": [{"term": "marketing:marchitecture/partner-network,marketing:marchitecture/aws-marketplace-and-partners", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/streamlined-map-funding-approval-aws-partner-central"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/streamlined-map-funding-approval-aws-partner-central"}
{"id": "149e09eec7738f10f0f318b4c84d79286b99caf0", "guidislink": false, "title": "Amazon API Gateway WebSocket APIs now available in 7 additional AWS Regions", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon API Gateway WebSocket APIs now available in 7 additional AWS Regions"}, "summary": "<p>Today, <a href=\"https://aws.amazon.com/api-gateway/\">Amazon API Gateway</a> has expanded the availability of WebSocket APIs to 7 additional AWS Regions: Asia Pacific (Jakarta), Europe (Zurich), Europe (Spain), Asia Pacific (Hyderabad), Asia Pacific (Melbourne), Israel (Tel Aviv), and Canada West (Calgary). With this launch, customers can build APIs with real-time bi-directional communication across all commercial AWS Regions.<br /> <br /> Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. WebSocket APIs enable real-time bi-directional communication, resulting in richer client-server interactions where services can push data to clients without requiring clients to make an explicit request. They are often used in real-time applications such as chat applications, collaboration platforms, multiplayer games, and financial trading platforms. WebSocket APIs have routes that can be integrated with backend HTTP endpoints, Lambda functions, or other AWS services.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, <a href=\"https://aws.amazon.com/api-gateway/\">Amazon API Gateway</a> has expanded the availability of WebSocket APIs to 7 additional AWS Regions: Asia Pacific (Jakarta), Europe (Zurich), Europe (Spain), Asia Pacific (Hyderabad), Asia Pacific (Melbourne), Israel (Tel Aviv), and Canada West (Calgary). With this launch, customers can build APIs with real-time bi-directional communication across all commercial AWS Regions.<br /> <br /> Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. WebSocket APIs enable real-time bi-directional communication, resulting in richer client-server interactions where services can push data to clients without requiring clients to make an explicit request. They are often used in real-time applications such as chat applications, collaboration platforms, multiplayer games, and financial trading platforms. WebSocket APIs have routes that can be integrated with backend HTTP endpoints, Lambda functions, or other AWS services.</p>"}, "published": "Mon, 01 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 1, 17, 0, 0, 0, 183, 0], "tags": [{"term": "marketing:marchitecture/networking,marketing:marchitecture/serverless,general:products/amazon-api-gateway", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-api-gateway-websocket-apis-additional-aws-regions"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-api-gateway-websocket-apis-additional-aws-regions"}
{"id": "3a832757f7cb9dfd829f9cbbc85639f9bd55a7ec", "guidislink": false, "title": "AWS Application Migration Service supports Dynatrace post-launch action", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Application Migration Service supports Dynatrace post-launch action"}, "summary": "<p>Starting today, AWS Application Migration Service (AWS MGN) provides an action for installing the Dynatrace agent on your migrated instances. For each migrated server, you can choose to automatically install the Dynatrace agent to support your observability needs.<br /> <br /> Application Migration Service minimizes time-intensive, error-prone manual processes by automating the conversion of your source servers to run natively on AWS. It also helps simplify modernization of your migrated applications by allowing you to select preconfigured and custom optimization options during migration.<br /> <br /> This feature is now available in all of the Commercial regions where Application Migration Service is available. Access the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regional Services List</a> for the most up-to-date availability information.<br /> <br /> To start using Application Migration Service for free, sign in through the <a href=\"https://console.aws.amazon.com/mgn/home\" target=\"_blank\">AWS Management Console</a>. For more information, visit the <a href=\"https://aws.amazon.com/application-migration-service/\" target=\"_blank\">Application Migration Service product page</a>.<br /> <br /> For more information on Dynatrace and to create a trial account, visit the <a href=\"https://www.dynatrace.com/signup/\" target=\"_blank\">Dynatrace sign up page</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Starting today, AWS Application Migration Service (AWS MGN) provides an action for installing the Dynatrace agent on your migrated instances. For each migrated server, you can choose to automatically install the Dynatrace agent to support your observability needs.<br /> <br /> Application Migration Service minimizes time-intensive, error-prone manual processes by automating the conversion of your source servers to run natively on AWS. It also helps simplify modernization of your migrated applications by allowing you to select preconfigured and custom optimization options during migration.<br /> <br /> This feature is now available in all of the Commercial regions where Application Migration Service is available. Access the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regional Services List</a> for the most up-to-date availability information.<br /> <br /> To start using Application Migration Service for free, sign in through the <a href=\"https://console.aws.amazon.com/mgn/home\" target=\"_blank\">AWS Management Console</a>. For more information, visit the <a href=\"https://aws.amazon.com/application-migration-service/\" target=\"_blank\">Application Migration Service product page</a>.<br /> <br /> For more information on Dynatrace and to create a trial account, visit the <a href=\"https://www.dynatrace.com/signup/\" target=\"_blank\">Dynatrace sign up page</a>.</p>"}, "published": "Mon, 01 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 1, 17, 0, 0, 0, 183, 0], "tags": [{"term": "marketing:marchitecture/migration,general:products/aws-application-migration-service", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-application-migration-service-dynatrace-post-launch-action"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/aws-application-migration-service-dynatrace-post-launch-action"}
{"id": "044b8b0719716551e911cdaf7a9d570badb7c873", "guidislink": false, "title": "RDS for PostgreSQL supports PL/Rust crates serde, serde_json, regex, and url", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "RDS for PostgreSQL supports PL/Rust crates serde, serde_json, regex, and url"}, "summary": "<p><a href=\"https://aws.amazon.com/rds/postgresql/\" target=\"_blank\">Amazon RDS for PostgreSQL</a> now supports new PL/Rust crates such as serde and serde_json crates, allowing you to exchange information between server and client or between servers by serializing and deserializing data structures in your PL/Rust user-defined functions. The release also includes support for regex crate that allow you to search strings for matches of a regular expression and url crate that implements the URL standard to provide parsing and deparsing of URL strings. With support for additional crates, you can now build more types of extensions on RDS for PostgreSQL using <a href=\"https://www.amazonaws.cn/en/new/2023/announcing-trusted-language-extensions-for-postgresql-on-amazon-aurora-and-amazon-rds/\" target=\"_blank\">Trusted Language Extensions for PostgreSQL</a> (pg_tle).<br /> <br /> pg_tle is an open source development kit to help you build extensions written in a trusted language, such as PL/Rust, that run safely on PostgreSQL. Support for serde, serde_json, regex, and url crates is available on database instances in Amazon RDS running PostgreSQL 16.3-R2 and higher, 15.7-R2 and higher, 14.12-R2 and higher, and 13.15-R2 and higher in all applicable AWS Regions. To learn more about using pg_tle, see our <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/PostgreSQL_trusted_language_extension.html\" target=\"_blank\">documentation</a>.<br /> <br /> Amazon RDS for PostgreSQL makes it simple to set up, operate, and scale PostgreSQL deployments in the cloud. See <a href=\"https://aws.amazon.com/rds/postgresql/pricing/\" target=\"_blank\">Amazon RDS for PostgreSQL Pricing</a> for pricing details and regional availability. Create or update a fully managed Amazon RDS database in the <a href=\"https://console.aws.amazon.com/rds/home\" target=\"_blank\">Amazon RDS Management Console</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://aws.amazon.com/rds/postgresql/\" target=\"_blank\">Amazon RDS for PostgreSQL</a> now supports new PL/Rust crates such as serde and serde_json crates, allowing you to exchange information between server and client or between servers by serializing and deserializing data structures in your PL/Rust user-defined functions. The release also includes support for regex crate that allow you to search strings for matches of a regular expression and url crate that implements the URL standard to provide parsing and deparsing of URL strings. With support for additional crates, you can now build more types of extensions on RDS for PostgreSQL using <a href=\"https://www.amazonaws.cn/en/new/2023/announcing-trusted-language-extensions-for-postgresql-on-amazon-aurora-and-amazon-rds/\" target=\"_blank\">Trusted Language Extensions for PostgreSQL</a> (pg_tle).<br /> <br /> pg_tle is an open source development kit to help you build extensions written in a trusted language, such as PL/Rust, that run safely on PostgreSQL. Support for serde, serde_json, regex, and url crates is available on database instances in Amazon RDS running PostgreSQL 16.3-R2 and higher, 15.7-R2 and higher, 14.12-R2 and higher, and 13.15-R2 and higher in all applicable AWS Regions. To learn more about using pg_tle, see our <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/PostgreSQL_trusted_language_extension.html\" target=\"_blank\">documentation</a>.<br /> <br /> Amazon RDS for PostgreSQL makes it simple to set up, operate, and scale PostgreSQL deployments in the cloud. See <a href=\"https://aws.amazon.com/rds/postgresql/pricing/\" target=\"_blank\">Amazon RDS for PostgreSQL Pricing</a> for pricing details and regional availability. Create or update a fully managed Amazon RDS database in the <a href=\"https://console.aws.amazon.com/rds/home\" target=\"_blank\">Amazon RDS Management Console</a>.<br /> &nbsp;</p>"}, "published": "Mon, 01 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 1, 17, 0, 0, 0, 183, 0], "tags": [{"term": "marketing:marchitecture/databases,general:products/amazon-rds", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/rds-postgresql-pl-rust-crates-serde-json-regex-url/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/rds-postgresql-pl-rust-crates-serde-json-regex-url/"}
{"id": "f8130bc317fa93032ae36a9b5c1f401bac601785", "guidislink": false, "title": "Amazon S3 Access Grants now integrate with open source Python frameworks", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon S3 Access Grants now integrate with open source Python frameworks"}, "summary": "<p><a href=\"https://aws.amazon.com/s3/features/access-grants/\" target=\"_blank\">Amazon S3 Access Grants</a> now&nbsp;integrate with open source Python frameworks using the AWS SDK for Python (Boto3) plugin. S3 Access Grants help you to map identities in Identity Providers (IdPs) such as Active Directory, or AWS Identity and Access Management (IAM) principals, to your datasets in S3. Importing the Boto3 plugin to your client replaces any custom code required to manage data permissions, so you can use S3 Access Grants in open source Python frameworks such as Django, TensorFlow, NumPy, Pandas, and more.<br /> <br /> Get started with S3 Access Grants using the AWS SDK for Python by importing the Boto3 plugin as a module in your Python code. The Boto3 plugin now has the ability to automatically request, cache, and refresh temporary credentials issued by S3, based on an Access Grant. As a result, the permissions for your Python-based S3 clients will be determined based on user group membership in an IdP.<br /> <br /> Amazon S3 Access Grants are available in all AWS Regions where <a href=\"https://docs.aws.amazon.com/general/latest/gr/sso.html\" target=\"_blank\">AWS IAM Identity Center is available</a>. To learn more about the Boto3 plugin, visit the <a href=\"https://github.com/aws/boto3-s3-access-grants-plugin\" target=\"_blank\">GitHub repository</a>. For pricing details, visit <a href=\"https://aws.amazon.com/s3/pricing/\" target=\"_blank\">Amazon S3 pricing</a>. To learn more, refer to the <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-grants.html\" target=\"_blank\">documentation</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://aws.amazon.com/s3/features/access-grants/\" target=\"_blank\">Amazon S3 Access Grants</a> now&nbsp;integrate with open source Python frameworks using the AWS SDK for Python (Boto3) plugin. S3 Access Grants help you to map identities in Identity Providers (IdPs) such as Active Directory, or AWS Identity and Access Management (IAM) principals, to your datasets in S3. Importing the Boto3 plugin to your client replaces any custom code required to manage data permissions, so you can use S3 Access Grants in open source Python frameworks such as Django, TensorFlow, NumPy, Pandas, and more.<br /> <br /> Get started with S3 Access Grants using the AWS SDK for Python by importing the Boto3 plugin as a module in your Python code. The Boto3 plugin now has the ability to automatically request, cache, and refresh temporary credentials issued by S3, based on an Access Grant. As a result, the permissions for your Python-based S3 clients will be determined based on user group membership in an IdP.<br /> <br /> Amazon S3 Access Grants are available in all AWS Regions where <a href=\"https://docs.aws.amazon.com/general/latest/gr/sso.html\" target=\"_blank\">AWS IAM Identity Center is available</a>. To learn more about the Boto3 plugin, visit the <a href=\"https://github.com/aws/boto3-s3-access-grants-plugin\" target=\"_blank\">GitHub repository</a>. For pricing details, visit <a href=\"https://aws.amazon.com/s3/pricing/\" target=\"_blank\">Amazon S3 pricing</a>. To learn more, refer to the <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-grants.html\" target=\"_blank\">documentation</a>.</p>"}, "published": "Mon, 01 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 1, 17, 0, 0, 0, 183, 0], "tags": [{"term": "marketing:marchitecture/storage,general:products/amazon-s3", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-s3-access-grants-integrate-open-source-python/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-s3-access-grants-integrate-open-source-python/"}
{"id": "56a7d91581e441b588106d7e1ea1aaef9289550f", "guidislink": false, "title": "Amazon Connect launches the ability to preferentially route contacts to specific agents within a queue", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Connect launches the ability to preferentially route contacts to specific agents within a queue"}, "summary": "<p>Amazon Connect now supports the ability to preferentially route a contact within a queue to specific agents. Using this new feature, you can now set the preferred agent(s) for a given contact, and if that agent is unavailable, fall back to the next set of routing criteria. You can also use this feature to integrate Amazon Connect\u2019s routing with your own custom business logic or machine learning models to personalize matching each contact to the most suitable agent, resulting in better business outcomes and increased customer satisfaction. For example, you could route repeat contacts to the agent who previously handled the customer, and if that specific agent isn\u2019t available, offer the contact to another available agent within the same queue.<br /> <br /> This feature is available in all <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS regions</a> where Amazon Connect is offered. To learn more about routing criteria, see the <a href=\"https://docs.aws.amazon.com/connect/latest/adminguide/set-routing-criteria.html\" target=\"_blank\">Amazon Connect Administrator Guide</a>. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the <a href=\"https://aws.amazon.com/connect/\" target=\"_blank\">Amazon Connect website</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Connect now supports the ability to preferentially route a contact within a queue to specific agents. Using this new feature, you can now set the preferred agent(s) for a given contact, and if that agent is unavailable, fall back to the next set of routing criteria. You can also use this feature to integrate Amazon Connect\u2019s routing with your own custom business logic or machine learning models to personalize matching each contact to the most suitable agent, resulting in better business outcomes and increased customer satisfaction. For example, you could route repeat contacts to the agent who previously handled the customer, and if that specific agent isn\u2019t available, offer the contact to another available agent within the same queue.<br /> <br /> This feature is available in all <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS regions</a> where Amazon Connect is offered. To learn more about routing criteria, see the <a href=\"https://docs.aws.amazon.com/connect/latest/adminguide/set-routing-criteria.html\" target=\"_blank\">Amazon Connect Administrator Guide</a>. To learn more about Amazon Connect, the AWS cloud-based contact center, please visit the <a href=\"https://aws.amazon.com/connect/\" target=\"_blank\">Amazon Connect website</a>.</p>"}, "published": "Mon, 01 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 1, 17, 0, 0, 0, 183, 0], "tags": [{"term": "marketing:marchitecture/business-productivity,general:products/aws-govcloud-us,general:products/amazon-connect", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-connect-preferentially-route-contacts-agents-queue"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-connect-preferentially-route-contacts-agents-queue"}
{"id": "f20644027e60f734bec78e65b25236a7982dc198", "guidislink": false, "title": "Amazon S3 Access Grants now integrate with Amazon SageMaker Studio", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon S3 Access Grants now integrate with Amazon SageMaker Studio"}, "summary": "<p><a href=\"https://aws.amazon.com/s3/features/access-grants/\" target=\"_blank\">Amazon S3 Access Grants</a> now&nbsp;integrate with Amazon SageMaker Studio for machine learning (ML) model training. S3 Access Grants help you to map identities in Identity Provider (IdPs) such as Active Directory, or AWS Identity and Access Management (IAM) principals, to your ML datasets in S3. Using the AWS SDK for Python (Boto3) plugin within Amazon SageMaker Studio notebooks helps you easily use S3 Access Grants for ML training and inference.<br /> <br /> Get started with S3 Access Grants in SageMaker Studio by launching a JupyterLab notebook. Next, import the Amazon S3 Access Grants Boto3 plugin into your notebook to start accessing your ML datasets in S3. The Boto3 plugin automatically requests, caches, and refreshes temporary credential tokens for all S3 requests that you run in your notebook. S3 Access Grants automatically update S3 permissions based on end-user group membership as users are added and removed from groups in the IdP.<br /> <br /> Amazon S3 Access Grants with Amazon SageMaker Studio are available in all AWS Regions where <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/regions-quotas.html\" target=\"_blank\">SageMaker Studio is available</a>. For pricing details, visit <a href=\"https://aws.amazon.com/s3/pricing/\" target=\"_blank\">Amazon S3 pricing</a> and <a href=\"https://aws.amazon.com/sagemaker/pricing/\" target=\"_blank\">Amazon SageMaker pricing</a>. To learn more about S3 Access Grants, refer to the <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-grants.html\" target=\"_blank\">documentation</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://aws.amazon.com/s3/features/access-grants/\" target=\"_blank\">Amazon S3 Access Grants</a> now&nbsp;integrate with Amazon SageMaker Studio for machine learning (ML) model training. S3 Access Grants help you to map identities in Identity Provider (IdPs) such as Active Directory, or AWS Identity and Access Management (IAM) principals, to your ML datasets in S3. Using the AWS SDK for Python (Boto3) plugin within Amazon SageMaker Studio notebooks helps you easily use S3 Access Grants for ML training and inference.<br /> <br /> Get started with S3 Access Grants in SageMaker Studio by launching a JupyterLab notebook. Next, import the Amazon S3 Access Grants Boto3 plugin into your notebook to start accessing your ML datasets in S3. The Boto3 plugin automatically requests, caches, and refreshes temporary credential tokens for all S3 requests that you run in your notebook. S3 Access Grants automatically update S3 permissions based on end-user group membership as users are added and removed from groups in the IdP.<br /> <br /> Amazon S3 Access Grants with Amazon SageMaker Studio are available in all AWS Regions where <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/regions-quotas.html\" target=\"_blank\">SageMaker Studio is available</a>. For pricing details, visit <a href=\"https://aws.amazon.com/s3/pricing/\" target=\"_blank\">Amazon S3 pricing</a> and <a href=\"https://aws.amazon.com/sagemaker/pricing/\" target=\"_blank\">Amazon SageMaker pricing</a>. To learn more about S3 Access Grants, refer to the <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/userguide/access-grants.html\" target=\"_blank\">documentation</a>.</p>"}, "published": "Mon, 01 Jul 2024 17:00:00 GMT", "published_parsed": [2024, 7, 1, 17, 0, 0, 0, 183, 0], "tags": [{"term": "general:products/amazon-s3,marketing:marchitecture/storage", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-s3-access-grants-integrate-sagemaker-studio/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/07/amazon-s3-access-grants-integrate-sagemaker-studio/"}
{"id": "3a3ab9f71ef2e416c5c16a2e2d64b5944f7909d0", "guidislink": false, "title": "Amazon GuardDuty EC2 Runtime Monitoring now supports Ubuntu and Debian OS", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon GuardDuty EC2 Runtime Monitoring now supports Ubuntu and Debian OS"}, "summary": "<p>The Amazon GuardDuty EC2 Runtime Monitoring eBPF security agent now supports Amazon Elastic Compute Cloud (Amazon EC2) workloads that use the Ubuntu (Ubuntu 20.04, Ubuntu 22.04) and Debian (Debian 11 and Debian 12) operating system. If you use GuardDuty EC2 Runtime Monitoring with automated agent management then GuardDuty will automatically upgrade the security agent for your Amazon EC2 workloads. If you are not using automated agent management, you are responsible for <a href=\"https://docs.aws.amazon.com/guardduty/latest/ug/managing-gdu-agent-ec2-manually.html\" target=\"_blank\">upgrading the agent manually</a>. You can <a href=\"https://docs.aws.amazon.com/guardduty/latest/ug/gdu-assess-coverage-ec2.html\" target=\"_blank\">view the current agent version</a> running in your Amazon EC2 instances in the EC2 runtime coverage page of the GuardDuty console. If you are not yet using GuardDuty EC2 Runtime Monitoring, you can enable the feature for a 30-day free trial with a <a href=\"https://docs.aws.amazon.com/guardduty/latest/ug/eks-protection-configuration.html\" target=\"_blank\">few steps</a>.<br /> <br /> GuardDuty Runtime Monitoring helps you identify and respond to potential threats, including instances or self-managed containers in your AWS environment associated with suspicious network activity, such as querying IP addresses associated with cryptocurrency-related activity, or connections to a Tor network as a Tor relay. Threats to compute workloads often involve remote code execution that leads to the download and execution of malware. GuardDuty Runtime Monitoring provides visibility into suspicious commands that involve malicious file downloads and execution across each step, providing earlier discovery of threats during initial compromise\u2014before they become business-impacting events.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>The Amazon GuardDuty EC2 Runtime Monitoring eBPF security agent now supports Amazon Elastic Compute Cloud (Amazon EC2) workloads that use the Ubuntu (Ubuntu 20.04, Ubuntu 22.04) and Debian (Debian 11 and Debian 12) operating system. If you use GuardDuty EC2 Runtime Monitoring with automated agent management then GuardDuty will automatically upgrade the security agent for your Amazon EC2 workloads. If you are not using automated agent management, you are responsible for <a href=\"https://docs.aws.amazon.com/guardduty/latest/ug/managing-gdu-agent-ec2-manually.html\" target=\"_blank\">upgrading the agent manually</a>. You can <a href=\"https://docs.aws.amazon.com/guardduty/latest/ug/gdu-assess-coverage-ec2.html\" target=\"_blank\">view the current agent version</a> running in your Amazon EC2 instances in the EC2 runtime coverage page of the GuardDuty console. If you are not yet using GuardDuty EC2 Runtime Monitoring, you can enable the feature for a 30-day free trial with a <a href=\"https://docs.aws.amazon.com/guardduty/latest/ug/eks-protection-configuration.html\" target=\"_blank\">few steps</a>.<br /> <br /> GuardDuty Runtime Monitoring helps you identify and respond to potential threats, including instances or self-managed containers in your AWS environment associated with suspicious network activity, such as querying IP addresses associated with cryptocurrency-related activity, or connections to a Tor network as a Tor relay. Threats to compute workloads often involve remote code execution that leads to the download and execution of malware. GuardDuty Runtime Monitoring provides visibility into suspicious commands that involve malicious file downloads and execution across each step, providing earlier discovery of threats during initial compromise\u2014before they become business-impacting events.</p>"}, "published": "Fri, 28 Jun 2024 21:35:00 GMT", "published_parsed": [2024, 6, 28, 21, 35, 0, 4, 180, 0], "tags": [{"term": "general:products/amazon-guardduty,general:products/amazon-ec2,marketing:marchitecture/compute,marketing:marchitecture/security-identity-and-compliance", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-guardduty-ec2-runtime-monitoring-ubuntu-debian-os"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-guardduty-ec2-runtime-monitoring-ubuntu-debian-os"}
{"id": "58fb73d776c5135332180ccdddc4e4c1532448c5", "guidislink": false, "title": "EvolutionaryScale\u2019s ESM3, a frontier language model family for biology, now available on AWS", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "EvolutionaryScale\u2019s ESM3, a frontier language model family for biology, now available on AWS"}, "summary": "<p>EvolutionaryScale\u2019s ESM3 1.4B open source language model is now generally available on AWS through Amazon SageMaker JumpStart and AWS HealthOmics, with the full family coming soon. Amazon SageMaker JumpStart is a ML hub with foundation models, built-in algorithms, and prebuilt ML solutions that can be deployed with just a few clicks. AWS HealthOmics is a purpose-built service that helps healthcare and life science organizations analyze biological data.<br /> <br /> EvolutionaryScale, a frontier AI research lab and Public Benefit Corporation dedicated to developing AI for biology\u2019s most complex problems, has released the cutting-edge ESM3 family of models. ESM3 is a biological frontier model family capable of generating entirely new proteins that have never existed in nature. ESM3 can generate proteins based on sequence, structure, and/or functional constraints \u2013 a novel \"programmable biology\" approach. Trained on billions of protein sequences spanning 3.8 billion years of evolution, ESM3 is one of the largest and most advanced generative AI models ever applied to biology.<br /> <br /> EvolutionaryScale\u2019s ESM3 1.4B open source model is available in Amazon SageMaker JumpStart initially in US East (Ohio) and in all available AWS HealthOmics regions, except Asia Pacific (Singapore). To learn more, read the <a href=\"https://aws.amazon.com/blogs/industries/revolutionizing-generative-biology-with-aws-and-evolutionaryscale/?trk=9e93c9df-e00a-491d-8545-774932c535a4\" target=\"_blank\">blog</a> and <a href=\"https://press.aboutamazon.com/aws/2024/6/evolutionaryscale-launches-with-esm3-a-milestone-ai-model-for-biology\" target=\"_blank\">press release</a>. To get started with ESM3, visit <a href=\"https://aws.amazon.com/sagemaker/jumpstart/\" target=\"_blank\">SageMaker JumpStart website</a> and <a href=\"https://github.com/aws-samples/drug-discovery-workflows\" target=\"_blank\">AWS HealthOmics GitHub repository</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>EvolutionaryScale\u2019s ESM3 1.4B open source language model is now generally available on AWS through Amazon SageMaker JumpStart and AWS HealthOmics, with the full family coming soon. Amazon SageMaker JumpStart is a ML hub with foundation models, built-in algorithms, and prebuilt ML solutions that can be deployed with just a few clicks. AWS HealthOmics is a purpose-built service that helps healthcare and life science organizations analyze biological data.<br /> <br /> EvolutionaryScale, a frontier AI research lab and Public Benefit Corporation dedicated to developing AI for biology\u2019s most complex problems, has released the cutting-edge ESM3 family of models. ESM3 is a biological frontier model family capable of generating entirely new proteins that have never existed in nature. ESM3 can generate proteins based on sequence, structure, and/or functional constraints \u2013 a novel \"programmable biology\" approach. Trained on billions of protein sequences spanning 3.8 billion years of evolution, ESM3 is one of the largest and most advanced generative AI models ever applied to biology.<br /> <br /> EvolutionaryScale\u2019s ESM3 1.4B open source model is available in Amazon SageMaker JumpStart initially in US East (Ohio) and in all available AWS HealthOmics regions, except Asia Pacific (Singapore). To learn more, read the <a href=\"https://aws.amazon.com/blogs/industries/revolutionizing-generative-biology-with-aws-and-evolutionaryscale/?trk=9e93c9df-e00a-491d-8545-774932c535a4\" target=\"_blank\">blog</a> and <a href=\"https://press.aboutamazon.com/aws/2024/6/evolutionaryscale-launches-with-esm3-a-milestone-ai-model-for-biology\" target=\"_blank\">press release</a>. To get started with ESM3, visit <a href=\"https://aws.amazon.com/sagemaker/jumpstart/\" target=\"_blank\">SageMaker JumpStart website</a> and <a href=\"https://github.com/aws-samples/drug-discovery-workflows\" target=\"_blank\">AWS HealthOmics GitHub repository</a>.</p>"}, "published": "Fri, 28 Jun 2024 21:25:00 GMT", "published_parsed": [2024, 6, 28, 21, 25, 0, 4, 180, 0], "tags": [{"term": "general:products/aws-health,marketing:marchitecture/artificial-intelligence,general:products/amazon-sagemaker", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/evolutionaryscale-esm3-available-aws"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/evolutionaryscale-esm3-available-aws"}
{"id": "090048f1ccb4cd6ab1bf1ad57b853c368c586c42", "guidislink": false, "title": "Amazon EventBridge announces new console dashboard", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon EventBridge announces new console dashboard"}, "summary": "<p>Amazon EventBridge announces a new console dashboard providing you with a centralized view of your EventBridge resources, metrics, and quotas. The dashboard leverages CloudWatch metrics, allowing you to monitor account level metrics such as PutEvents, Matched Events, and Invocations for Buses, Concurrency and Throttles for Pipes, and Invocations and Errors for ScheduledGroups. Additionally, the dashboard allows you to view your default and applied quotas and navigate to the Service Quotas page to request increases, enabling you to respond quickly to changes in usage.<br /> <br /> The Amazon EventBridge Event Bus is a serverless event router that enables you to create scalable event-driven applications by routing events between your own applications, SaaS applications, and AWS services. EventBridge Pipes provides a consistent, and cost-effective way to create point-to-point integrations between event producers and consumers. The EventBridge Scheduler makes it simple for developers to create, execute, and manage scheduled tasks at scale.<br /> <br /> The new console dashboard surfaces account level metrics, providing deeper insight into your event-driven applications and allowing you to quickly identify and resolve issues as they arise. You can use the dashboard to answer basic questions such as \u201cHow many Buses and Pipes have I configured in my account?\u201d, \u201cWhat was my PutEvent traffic pattern for the last 3 hours?\u201d or \u201cWhat is the concurrency of my Pipe?\u201d. You can further analyze and customize these dashboards in CloudWatch.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon EventBridge announces a new console dashboard providing you with a centralized view of your EventBridge resources, metrics, and quotas. The dashboard leverages CloudWatch metrics, allowing you to monitor account level metrics such as PutEvents, Matched Events, and Invocations for Buses, Concurrency and Throttles for Pipes, and Invocations and Errors for ScheduledGroups. Additionally, the dashboard allows you to view your default and applied quotas and navigate to the Service Quotas page to request increases, enabling you to respond quickly to changes in usage.<br /> <br /> The Amazon EventBridge Event Bus is a serverless event router that enables you to create scalable event-driven applications by routing events between your own applications, SaaS applications, and AWS services. EventBridge Pipes provides a consistent, and cost-effective way to create point-to-point integrations between event producers and consumers. The EventBridge Scheduler makes it simple for developers to create, execute, and manage scheduled tasks at scale.<br /> <br /> The new console dashboard surfaces account level metrics, providing deeper insight into your event-driven applications and allowing you to quickly identify and resolve issues as they arise. You can use the dashboard to answer basic questions such as \u201cHow many Buses and Pipes have I configured in my account?\u201d, \u201cWhat was my PutEvent traffic pattern for the last 3 hours?\u201d or \u201cWhat is the concurrency of my Pipe?\u201d. You can further analyze and customize these dashboards in CloudWatch.</p>"}, "published": "Fri, 28 Jun 2024 17:30:00 GMT", "published_parsed": [2024, 6, 28, 17, 30, 0, 4, 180, 0], "tags": [{"term": "marketing:marchitecture/serverless,marketing:marchitecture/application-services,general:products/amazon-eventBridge", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-eventbridge-console-dashboard"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-eventbridge-console-dashboard"}
{"id": "2fb6018414cc56c1f0577b7ef1138b097a7c0370", "guidislink": false, "title": "Amazon EC2 High Memory instances now available in Asia Pacific (Hong Kong) Region", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon EC2 High Memory instances now available in Asia Pacific (Hong Kong) Region"}, "summary": "<p>Starting today, <a href=\"https://aws.amazon.com/ec2/instance-types/high-memory/\" target=\"_blank\">Amazon EC2 High Memory instances</a> with 3TiB of memory are now available in Asia Pacific (Hong Kong) region. Customers can start using these new High Memory instances with On Demand and Savings Plan purchase options.<br /> <br /> Amazon EC2 High Memory instances are certified by SAP for running Business Suite on HANA, SAP S/4HANA, Data Mart Solutions on HANA, Business Warehouse on HANA, and SAP BW/4HANA in production environments. For details, see the <a href=\"https://www.sap.com/dmc/exp/2014-09-02-hana-hardware/enEN/#/solutions?filters=v:deCertified;ve:23\" target=\"_blank\">Certified and Supported SAP HANA Hardware Directory</a>.<br /> <br /> For information on how to get started with your SAP HANA migration to EC2 High Memory instances, view the <a href=\"https://docs.aws.amazon.com/sap/latest/sap-hana/migrating-hana-to-hm.html\" target=\"_blank\">Migrating SAP HANA on AWS to an EC2 High Memory Instance</a> documentation. To hear from Steven Jones, GM for SAP on AWS on what this launch means for our SAP customers, you can read <a href=\"https://aws.amazon.com/blogs/awsforsap/amazon-ec2-high-memory-instances-now-available-for-on-demand-usage/\">his launch blog</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Starting today, <a href=\"https://aws.amazon.com/ec2/instance-types/high-memory/\" target=\"_blank\">Amazon EC2 High Memory instances</a> with 3TiB of memory are now available in Asia Pacific (Hong Kong) region. Customers can start using these new High Memory instances with On Demand and Savings Plan purchase options.<br /> <br /> Amazon EC2 High Memory instances are certified by SAP for running Business Suite on HANA, SAP S/4HANA, Data Mart Solutions on HANA, Business Warehouse on HANA, and SAP BW/4HANA in production environments. For details, see the <a href=\"https://www.sap.com/dmc/exp/2014-09-02-hana-hardware/enEN/#/solutions?filters=v:deCertified;ve:23\" target=\"_blank\">Certified and Supported SAP HANA Hardware Directory</a>.<br /> <br /> For information on how to get started with your SAP HANA migration to EC2 High Memory instances, view the <a href=\"https://docs.aws.amazon.com/sap/latest/sap-hana/migrating-hana-to-hm.html\" target=\"_blank\">Migrating SAP HANA on AWS to an EC2 High Memory Instance</a> documentation. To hear from Steven Jones, GM for SAP on AWS on what this launch means for our SAP customers, you can read <a href=\"https://aws.amazon.com/blogs/awsforsap/amazon-ec2-high-memory-instances-now-available-for-on-demand-usage/\">his launch blog</a>.<br /> &nbsp;</p>"}, "published": "Fri, 28 Jun 2024 17:30:00 GMT", "published_parsed": [2024, 6, 28, 17, 30, 0, 4, 180, 0], "tags": [{"term": "general:products/amazon-ec2,marketing:marchitecture/compute", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-ec2-high-memory-instances-hong-kong-region"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-ec2-high-memory-instances-hong-kong-region"}
{"id": "3edd30d39b0331067af9b1e8d17ff7703e27dca7", "guidislink": false, "title": "AWS ParallelCluster 3.10 with support for Amazon Linux 2023 and Terraform", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS ParallelCluster 3.10 with support for Amazon Linux 2023 and Terraform"}, "summary": "<p>AWS ParallelCluster 3.10 is now generally available. Key features of this release include support for Amazon Linux 2023 and Terraform. With Terrafrom support, customers can automate deployment and management of clusters similar to how they use Terraform to automate other parts of their AWS infrastructure. Other important features in this release include:</p> \n<ol> \n <li>Support for connecting clusters to an external Slurm database daemon (Slurmdbd) to follow best practices of enabling Slurm accounting in a multi-cluster environment.</li> \n <li>A new allocation strategy configuration to allocate EC2 Spot instances from the lowest-priced, highest-capacity availability pools to minimize job interruptions and save costs.</li> \n</ol> \n<p>For more details on the release, review the AWS ParallelCluster 3.10.0 <a href=\"https://github.com/aws/aws-parallelcluster/releases/tag/v3.10.0\" target=\"_blank\">release notes</a>.<br /> <br /> AWS ParallelCluster is a fully-supported and maintained open-source cluster management tool that enables R&amp;D customers and their IT administrators to operate high-performance computing (HPC) clusters on AWS. AWS ParallelCluster is designed to automatically and securely provision cloud resources into elastically-scaling HPC clusters capable of running scientific, engineering, and machine-learning (ML/AI) workloads at scale on AWS.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS ParallelCluster 3.10 is now generally available. Key features of this release include support for Amazon Linux 2023 and Terraform. With Terrafrom support, customers can automate deployment and management of clusters similar to how they use Terraform to automate other parts of their AWS infrastructure. Other important features in this release include:</p> \n<ol> \n <li>Support for connecting clusters to an external Slurm database daemon (Slurmdbd) to follow best practices of enabling Slurm accounting in a multi-cluster environment.</li> \n <li>A new allocation strategy configuration to allocate EC2 Spot instances from the lowest-priced, highest-capacity availability pools to minimize job interruptions and save costs.</li> \n</ol> \n<p>For more details on the release, review the AWS ParallelCluster 3.10.0 <a href=\"https://github.com/aws/aws-parallelcluster/releases/tag/v3.10.0\" target=\"_blank\">release notes</a>.<br /> <br /> AWS ParallelCluster is a fully-supported and maintained open-source cluster management tool that enables R&amp;D customers and their IT administrators to operate high-performance computing (HPC) clusters on AWS. AWS ParallelCluster is designed to automatically and securely provision cloud resources into elastically-scaling HPC clusters capable of running scientific, engineering, and machine-learning (ML/AI) workloads at scale on AWS.</p>"}, "published": "Fri, 28 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 28, 17, 0, 0, 4, 180, 0], "tags": [{"term": "marketing:marchitecture/compute,general:products/aws-parallelcluster,general:products/amazon-ec2", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-parallelcluster-3-10-amazon-linux-2023-terraform"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-parallelcluster-3-10-amazon-linux-2023-terraform"}
{"id": "e87721b0b3181aebb1c8dd001e05e783e89b3f9b", "guidislink": false, "title": "Amazon SageMaker Model Registry now supports cross-account machine learning (ML) model sharing", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon SageMaker Model Registry now supports cross-account machine learning (ML) model sharing"}, "summary": "<p>Today, we're excited to announce that Amazon SageMaker Model Registry now integrates with <a href=\"https://docs.aws.amazon.com/ram/latest/userguide/what-is.html\" target=\"_blank\">AWS Resource Access Manager</a> (AWS RAM), making it easier to securely share and discover machine learning (ML) models across your AWS accounts.<br /> <br /> Data scientists, ML engineers, and governance officers need access to ML models across different AWS accounts such as development, staging and production to make the relevant decisions. With this launch, customers can now seamlessly share and access ML models registered in SageMaker Model Registry between different AWS accounts. Customers can simply go to the AWS RAM console or CLI, specify the Amazon SageMaker Model Registry model that needs to be shared, and grant access to specific AWS accounts or to everyone in the organization. Authorized users can then instantly discover and use those shared models in their own AWS accounts . This streamlines the ML workflows, enables better visibility and governance, and accelerates the adoption of ML models across the organization.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, we're excited to announce that Amazon SageMaker Model Registry now integrates with <a href=\"https://docs.aws.amazon.com/ram/latest/userguide/what-is.html\" target=\"_blank\">AWS Resource Access Manager</a> (AWS RAM), making it easier to securely share and discover machine learning (ML) models across your AWS accounts.<br /> <br /> Data scientists, ML engineers, and governance officers need access to ML models across different AWS accounts such as development, staging and production to make the relevant decisions. With this launch, customers can now seamlessly share and access ML models registered in SageMaker Model Registry between different AWS accounts. Customers can simply go to the AWS RAM console or CLI, specify the Amazon SageMaker Model Registry model that needs to be shared, and grant access to specific AWS accounts or to everyone in the organization. Authorized users can then instantly discover and use those shared models in their own AWS accounts . This streamlines the ML workflows, enables better visibility and governance, and accelerates the adoption of ML models across the organization.</p>"}, "published": "Fri, 28 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 28, 17, 0, 0, 4, 180, 0], "tags": [{"term": "marketing:marchitecture/artificial-intelligence,general:products/amazon-sagemaker,general:products/aws-resource-access-manager", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-sagemaker-model-registry-cross-account-ml-model-sharing"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-sagemaker-model-registry-cross-account-ml-model-sharing"}
{"id": "ebf4e00235281f951aa71f077b8b04c104b42b95", "guidislink": false, "title": "Amazon EventBridge Pipes now supports AWS PrivateLink", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon EventBridge Pipes now supports AWS PrivateLink"}, "summary": "<p>Amazon EventBridge Pipes now supports <a href=\"https://aws.amazon.com/privatelink/\" target=\"_blank\">AWS PrivateLink</a>, allowing you to access Pipes from within your Amazon Virtual Private Cloud (VPC) without traversing the public internet. With today\u2019s launch, you can leverage EventBridge Pipes features from a private subnet without the need to deploy an internet gateway, configure firewall rules, or set up proxy servers.<br /> <br /> Amazon EventBridge lets you use events to connect application components, making it easier to build scalable event-driven applications. EventBridge Pipes provides a simple, consistent, and cost-effective way to create point-to-point integrations between event producers and consumers. Pipes enables you to send data from one of 7 different event sources to any of the 20+ targets supported by the EventBridge Event Bus, including HTTPS endpoints through EventBridge API Destinations and event buses themselves. Today\u2019s release of AWS PrivateLink support further reduces the amount of integration code you need to write and infrastructure you need to maintain when building event-driven applications.<br /> <br /> AWS PrivateLink support for EventBridge Pipes is available in all AWS Regions where EventBridge Pipes is available.<br /> <br /> To get started, follow the directions provided in the <a href=\"https://docs.aws.amazon.com/en_us/vpc/latest/privatelink/privatelink-access-aws-services.html\" target=\"_blank\">AWS PrivateLink documentation</a>. To learn more about Amazon EventBridge Pipes, visit the EventBridge <a href=\"https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html\" target=\"_blank\">documentation</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon EventBridge Pipes now supports <a href=\"https://aws.amazon.com/privatelink/\" target=\"_blank\">AWS PrivateLink</a>, allowing you to access Pipes from within your Amazon Virtual Private Cloud (VPC) without traversing the public internet. With today\u2019s launch, you can leverage EventBridge Pipes features from a private subnet without the need to deploy an internet gateway, configure firewall rules, or set up proxy servers.<br /> <br /> Amazon EventBridge lets you use events to connect application components, making it easier to build scalable event-driven applications. EventBridge Pipes provides a simple, consistent, and cost-effective way to create point-to-point integrations between event producers and consumers. Pipes enables you to send data from one of 7 different event sources to any of the 20+ targets supported by the EventBridge Event Bus, including HTTPS endpoints through EventBridge API Destinations and event buses themselves. Today\u2019s release of AWS PrivateLink support further reduces the amount of integration code you need to write and infrastructure you need to maintain when building event-driven applications.<br /> <br /> AWS PrivateLink support for EventBridge Pipes is available in all AWS Regions where EventBridge Pipes is available.<br /> <br /> To get started, follow the directions provided in the <a href=\"https://docs.aws.amazon.com/en_us/vpc/latest/privatelink/privatelink-access-aws-services.html\" target=\"_blank\">AWS PrivateLink documentation</a>. To learn more about Amazon EventBridge Pipes, visit the EventBridge <a href=\"https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-pipes.html\" target=\"_blank\">documentation</a>.<br /> &nbsp;</p>"}, "published": "Fri, 28 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 28, 17, 0, 0, 4, 180, 0], "tags": [{"term": "marketing:marchitecture/application-services,general:products/amazon-eventBridge", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-eventbridge-pipes-aws-privatelink/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-eventbridge-pipes-aws-privatelink/"}
{"id": "0e587d523789a2e1f9339cf3b8e9d3ff58ae7ce3", "guidislink": false, "title": "Amazon SageMaker now supports SageMaker Studio Personalization", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon SageMaker now supports SageMaker Studio Personalization"}, "summary": "<p>We are excited to announce that Amazon SageMaker now allows admins to personalize the <a href=\"https://aws.amazon.com/sagemaker/studio/\" target=\"_blank\">SageMaker Studio</a> experience for their end-users. Admins can choose to hide applications and ML Tools from SageMaker Studio based on the end user preferences.<br /> <br /> Starting today, admins can use the new personalization capability while setting up domains and user-profiles on SageMaker Console or using APIs, and tailor the SageMaker Studio interface. They can curate experiences by selectively showing or hiding specific ML tools, applications and IDEs for specific personas to align closely with how users interact with the platform. This improves SageMaker Studio usability and provides a more intuitive and user-friendly experience. Data scientists and ML engineers can now easily discover and select ML features required to complete their workflows, leading to a better developer productivity.<br /> <br /> You can get started by creating or editing a domain, or a user profile in<a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-ui-customize.html\" target=\"_blank\"> SageMaker Console</a> or by using <a href=\"https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_StudioWebPortalSettings.html\" target=\"_blank\">SageMaker APIs</a>. This feature is available in all Amazon Web Services regions where SageMaker Studio is currently available. To learn more, visit <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-ui-customize.html\" target=\"_blank\">documentation.</a><br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>We are excited to announce that Amazon SageMaker now allows admins to personalize the <a href=\"https://aws.amazon.com/sagemaker/studio/\" target=\"_blank\">SageMaker Studio</a> experience for their end-users. Admins can choose to hide applications and ML Tools from SageMaker Studio based on the end user preferences.<br /> <br /> Starting today, admins can use the new personalization capability while setting up domains and user-profiles on SageMaker Console or using APIs, and tailor the SageMaker Studio interface. They can curate experiences by selectively showing or hiding specific ML tools, applications and IDEs for specific personas to align closely with how users interact with the platform. This improves SageMaker Studio usability and provides a more intuitive and user-friendly experience. Data scientists and ML engineers can now easily discover and select ML features required to complete their workflows, leading to a better developer productivity.<br /> <br /> You can get started by creating or editing a domain, or a user profile in<a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-ui-customize.html\" target=\"_blank\"> SageMaker Console</a> or by using <a href=\"https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_StudioWebPortalSettings.html\" target=\"_blank\">SageMaker APIs</a>. This feature is available in all Amazon Web Services regions where SageMaker Studio is currently available. To learn more, visit <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-ui-customize.html\" target=\"_blank\">documentation.</a><br /> &nbsp;</p>"}, "published": "Fri, 28 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 28, 17, 0, 0, 4, 180, 0], "tags": [{"term": "general:products/amazon-sagemaker,marketing:marchitecture/artificial-intelligence,general:products/amazon-machine-learning", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-sagemaker-sagemaker-studio-personalization/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-sagemaker-sagemaker-studio-personalization/"}
{"id": "54619fa37ff8e21c83c941e2f64fccbe454052dc", "guidislink": false, "title": "Amazon Q in Connect now recommends step-by-step guides", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Q in Connect now recommends step-by-step guides"}, "summary": "<p>Amazon Q in Connect, a generative-AI powered assistant for contact center agents, now recommends step-by-step guides in real-time, which agents use to quickly take action to resolve customers' issues. Amazon Q in Connect uses the real-time conversation with a customer to detect the customer's intent and provides a guided workflow that leads an agent through each step needed to solve the issue, reducing handle time and increasing first contact resolution rates and customer satisfaction. For example, when a customer contacts a financial services company, Amazon Q in Connect analyzes the conversation and detects the customer wants to open a retirement plan. Amazon Q in Connect then provides the agent with a guide that enables the agent to collect the necessary information, deliver the required disclosures, and automatically open the account. To learn more about Amazon Q in Connect, please visit the <a href=\"https://aws.amazon.com/connect/q/\" target=\"_blank\"><u>websit</u></a><a href=\"https://aws.amazon.com/connect/q\"><u>e</u></a> or see the <a href=\"https://docs.aws.amazon.com/connect/latest/adminguide/amazon-q-connect.html\" target=\"_blank\"><u>help documentation</u></a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Q in Connect, a generative-AI powered assistant for contact center agents, now recommends step-by-step guides in real-time, which agents use to quickly take action to resolve customers' issues. Amazon Q in Connect uses the real-time conversation with a customer to detect the customer's intent and provides a guided workflow that leads an agent through each step needed to solve the issue, reducing handle time and increasing first contact resolution rates and customer satisfaction. For example, when a customer contacts a financial services company, Amazon Q in Connect analyzes the conversation and detects the customer wants to open a retirement plan. Amazon Q in Connect then provides the agent with a guide that enables the agent to collect the necessary information, deliver the required disclosures, and automatically open the account. To learn more about Amazon Q in Connect, please visit the <a href=\"https://aws.amazon.com/connect/q/\" target=\"_blank\"><u>websit</u></a><a href=\"https://aws.amazon.com/connect/q\"><u>e</u></a> or see the <a href=\"https://docs.aws.amazon.com/connect/latest/adminguide/amazon-q-connect.html\" target=\"_blank\"><u>help documentation</u></a>.</p>"}, "published": "Fri, 28 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 28, 17, 0, 0, 4, 180, 0], "tags": [{"term": "general:products/amazon-connect,marketing:marchitecture/business-productivity", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-q-connect-step-by-step-guides"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-q-connect-step-by-step-guides"}
{"id": "dc6d262de4717c9ce29c7700fe2250cad6f860c9", "guidislink": false, "title": "Announcing Data Quality Definition Language (DQDL) enhancements for AWS Glue Data Quality", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Announcing Data Quality Definition Language (DQDL) enhancements for AWS Glue Data Quality"}, "summary": "<p>Customers use AWS Glue Data Quality, a feature of AWS Glue, to measure and monitor quality of their data. They author data quality rules using DQDL to ensure their data is accurate . Customers need the ability to author rules for complex business scenarios that include filter conditions, exclusion conditions, validations for empty values, and composite rules . Previously customers authored SQL to perform these data quality validations in the CustomSQL rule type. Today, AWS Glue announces new set of new enhancements to DQDL that allows data engineers easily author complex data quality rules using native rule types. DQDL now supports</p> \n<ul> \n <li><a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html#dqdl-syntax-rule-expressions\" target=\"_blank\">NOT operator</a> allowing customers to exclude certain values in their rule.</li> \n <li>New keywords such as <a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html#dqdl-keywords-null-empty-whitespaces_only\" target=\"_blank\">NULL, EMPTY, and WHITESPACES_ONLY</a> to author rules that capture missing values without complex regular expressions.</li> \n <li><a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html#dqdl-syntax-composite-rules\" target=\"_blank\">Composite rules</a><a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html#dqdl-syntax-composite-rules\"> </a>for customers to author sophisticated business rules. They can now specify options to manage the evaluation order of these rules.</li> \n <li><a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html#dqdl-filtering-data-in-dqdl\" target=\"_blank\">WHERE</a> clause in DQDL to filter data before applying rules.</li> \n</ul> \n<p>Refer to <a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html\" target=\"_blank\">DQDL</a> guide for more information.<br /> <br /> AWS Glue Data Quality is available in all commercial regions where AWS Glue is available. To learn more, visit the <a href=\"https://aws.amazon.com/glue/\" target=\"_blank\">AWS Glue</a> product page and our documentation.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Customers use AWS Glue Data Quality, a feature of AWS Glue, to measure and monitor quality of their data. They author data quality rules using DQDL to ensure their data is accurate . Customers need the ability to author rules for complex business scenarios that include filter conditions, exclusion conditions, validations for empty values, and composite rules . Previously customers authored SQL to perform these data quality validations in the CustomSQL rule type. Today, AWS Glue announces new set of new enhancements to DQDL that allows data engineers easily author complex data quality rules using native rule types. DQDL now supports</p> \n<ul> \n <li><a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html#dqdl-syntax-rule-expressions\" target=\"_blank\">NOT operator</a> allowing customers to exclude certain values in their rule.</li> \n <li>New keywords such as <a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html#dqdl-keywords-null-empty-whitespaces_only\" target=\"_blank\">NULL, EMPTY, and WHITESPACES_ONLY</a> to author rules that capture missing values without complex regular expressions.</li> \n <li><a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html#dqdl-syntax-composite-rules\" target=\"_blank\">Composite rules</a><a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html#dqdl-syntax-composite-rules\"> </a>for customers to author sophisticated business rules. They can now specify options to manage the evaluation order of these rules.</li> \n <li><a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html#dqdl-filtering-data-in-dqdl\" target=\"_blank\">WHERE</a> clause in DQDL to filter data before applying rules.</li> \n</ul> \n<p>Refer to <a href=\"https://docs.aws.amazon.com/glue/latest/dg/dqdl.html\" target=\"_blank\">DQDL</a> guide for more information.<br /> <br /> AWS Glue Data Quality is available in all commercial regions where AWS Glue is available. To learn more, visit the <a href=\"https://aws.amazon.com/glue/\" target=\"_blank\">AWS Glue</a> product page and our documentation.</p>"}, "published": "Fri, 28 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 28, 17, 0, 0, 4, 180, 0], "tags": [{"term": "marketing:marchitecture/analytics,general:products/aws-glue", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/data-quality-language-enhancements-glue-data-quality/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/data-quality-language-enhancements-glue-data-quality/"}
{"id": "26ca8bf47776ee66f83e30bcdcb0f0ba2a91d034", "guidislink": false, "title": "AWS Elemental MediaTailor now supports CMAF for dynamic ad transcoding", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Elemental MediaTailor now supports CMAF for dynamic ad transcoding"}, "summary": "<p>AWS Elemental MediaTailor now supports Common Media Application Format (CMAF) segments for personalized HLS streams and will automatically transcode ad creatives to match.<br /> <br /> Previously, if you wanted to serve CMAF ad segments, you had to create a custom transcode profile configuration. MediaTailor will now detect when the content source is CMAF or ISOBMFF in a DASH or HLS stream and dynamically transcode the ad creatives to match the program source with no additional user configuration required. There is no additional cost for CMAF ad transcoding.<br /> <br /> AWS Elemental MediaTailor is a channel assembly and personalized ad-insertion service for video providers to create linear over-the-top (OTT) channels using existing video content. The service then lets you monetize those channels\u2014or other live streams\u2014with personalized advertising across the broadest range of devices with a seamless viewer experience. MediaTailor functions independently or as part of <a href=\"https://aws.amazon.com/media-services/\" target=\"_blank\">AWS Media Services</a>, a family of services that form the foundation of cloud-based workflows.<br /> <br /> Visit the AWS region table for a full list of <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regions</a> where AWS Elemental MediaTailor is available. To learn more about MediaTailor, please visit the <a href=\"https://aws.amazon.com/mediatailor/\" target=\"_blank\">product page</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS Elemental MediaTailor now supports Common Media Application Format (CMAF) segments for personalized HLS streams and will automatically transcode ad creatives to match.<br /> <br /> Previously, if you wanted to serve CMAF ad segments, you had to create a custom transcode profile configuration. MediaTailor will now detect when the content source is CMAF or ISOBMFF in a DASH or HLS stream and dynamically transcode the ad creatives to match the program source with no additional user configuration required. There is no additional cost for CMAF ad transcoding.<br /> <br /> AWS Elemental MediaTailor is a channel assembly and personalized ad-insertion service for video providers to create linear over-the-top (OTT) channels using existing video content. The service then lets you monetize those channels\u2014or other live streams\u2014with personalized advertising across the broadest range of devices with a seamless viewer experience. MediaTailor functions independently or as part of <a href=\"https://aws.amazon.com/media-services/\" target=\"_blank\">AWS Media Services</a>, a family of services that form the foundation of cloud-based workflows.<br /> <br /> Visit the AWS region table for a full list of <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regions</a> where AWS Elemental MediaTailor is available. To learn more about MediaTailor, please visit the <a href=\"https://aws.amazon.com/mediatailor/\" target=\"_blank\">product page</a>.<br /> &nbsp;</p>"}, "published": "Fri, 28 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 28, 17, 0, 0, 4, 180, 0], "tags": [{"term": "general:products/aws-elemental-mediatailor,marketing:marchitecture/media-services", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-elemental-mediatailor-cmaf-dynamic-ad-transcoding/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-elemental-mediatailor-cmaf-dynamic-ad-transcoding/"}
{"id": "b1e02adcb4d0ea564bb5abd6bc8c2eb9cf042159", "guidislink": false, "title": "Amazon CodeCatalyst now allows conversion of source repositories to custom blueprints", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon CodeCatalyst now allows conversion of source repositories to custom blueprints"}, "summary": "<p>Today, AWS announces a new capability that enables customers to convert an existing source repository into a custom blueprint in Amazon CodeCatalyst. Custom blueprints give teams the ability to define and propagate best practices for application code, workflows, and infrastructure. However, many customers have already defined these best practices in one or more existing source repositories. Previously, they needed to create a custom blueprint, and manually copy relevant artifacts from their existing source repository into the blueprint project. Now customers have a one-click option to convert an existing repository to a custom blueprint. For more information, see <a href=\"https://docs.aws.amazon.com/codecatalyst/latest/userguide/convert-bp.html\" target=\"_blank\">Converting source repositories to custom blueprints</a>.<br /> <br /> Teams can use these custom blueprints to create CodeCatalyst projects or add functionality to existing projects. As the blueprint gets updated with the latest best practices or new options, it can regenerate the relevant parts of your codebase in projects containing that blueprint. For more information, see the <a href=\"https://codecatalyst.aws/explore/blueprints\" target=\"_blank\">CodeCatalyst Blueprints webpage</a> and <a href=\"https://docs.aws.amazon.com/codecatalyst/latest/userguide/blueprints.html\" target=\"_blank\">blueprints documentation</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, AWS announces a new capability that enables customers to convert an existing source repository into a custom blueprint in Amazon CodeCatalyst. Custom blueprints give teams the ability to define and propagate best practices for application code, workflows, and infrastructure. However, many customers have already defined these best practices in one or more existing source repositories. Previously, they needed to create a custom blueprint, and manually copy relevant artifacts from their existing source repository into the blueprint project. Now customers have a one-click option to convert an existing repository to a custom blueprint. For more information, see <a href=\"https://docs.aws.amazon.com/codecatalyst/latest/userguide/convert-bp.html\" target=\"_blank\">Converting source repositories to custom blueprints</a>.<br /> <br /> Teams can use these custom blueprints to create CodeCatalyst projects or add functionality to existing projects. As the blueprint gets updated with the latest best practices or new options, it can regenerate the relevant parts of your codebase in projects containing that blueprint. For more information, see the <a href=\"https://codecatalyst.aws/explore/blueprints\" target=\"_blank\">CodeCatalyst Blueprints webpage</a> and <a href=\"https://docs.aws.amazon.com/codecatalyst/latest/userguide/blueprints.html\" target=\"_blank\">blueprints documentation</a>.</p>"}, "published": "Fri, 28 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 28, 17, 0, 0, 4, 180, 0], "tags": [{"term": "marketing:marchitecture/developer-tools,general:products/amazon-codecatalyst", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-codecatalyst-conversion-source-repositories-custom-blueprints"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-codecatalyst-conversion-source-repositories-custom-blueprints"}
{"id": "09f7044a8f984f9ca83dfef8f99e6cf8563904e6", "guidislink": false, "title": "AWS CodeBuild build timeout limit increased to 36 hours", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS CodeBuild build timeout limit increased to 36 hours"}, "summary": "<p>AWS CodeBuild now enables customers to increase their build timeout up to 36 hours compared to the prior limit of 8 hours. AWS CodeBuild is a fully managed continuous integration service that compiles source code, runs tests, and produces software packages ready for deployment.<br /> <br /> This setting represents the maximum amount of time before CodeBuild stops a build request if it is not complete. With this launch, customers with workloads requiring longer timeouts, such as large automated test suites or embedded machine builds, can leverage CodeBuild.<br /> <br /> The increased timeout limit is available in all regions where CodeBuild is offered. For more information about the AWS Regions where CodeBuild is available, see the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regions page</a>.<br /> <br /> To learn more about CodeBuild configurations, please visit our <a href=\"https://docs.aws.amazon.com/codebuild/latest/userguide/create-project-console.html#create-project-console-environment\" target=\"_blank\">documentation</a>. To learn more about how to get started with CodeBuild, visit the <a href=\"https://aws.amazon.com/codebuild/\" target=\"_blank\">AWS CodeBuild product page</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS CodeBuild now enables customers to increase their build timeout up to 36 hours compared to the prior limit of 8 hours. AWS CodeBuild is a fully managed continuous integration service that compiles source code, runs tests, and produces software packages ready for deployment.<br /> <br /> This setting represents the maximum amount of time before CodeBuild stops a build request if it is not complete. With this launch, customers with workloads requiring longer timeouts, such as large automated test suites or embedded machine builds, can leverage CodeBuild.<br /> <br /> The increased timeout limit is available in all regions where CodeBuild is offered. For more information about the AWS Regions where CodeBuild is available, see the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regions page</a>.<br /> <br /> To learn more about CodeBuild configurations, please visit our <a href=\"https://docs.aws.amazon.com/codebuild/latest/userguide/create-project-console.html#create-project-console-environment\" target=\"_blank\">documentation</a>. To learn more about how to get started with CodeBuild, visit the <a href=\"https://aws.amazon.com/codebuild/\" target=\"_blank\">AWS CodeBuild product page</a>.</p>"}, "published": "Fri, 28 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 28, 17, 0, 0, 4, 180, 0], "tags": [{"term": "marketing:marchitecture/developer-tools,general:products/aws-codebuild", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-codebuild-build-timeout-limit-increased-36-hours"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-codebuild-build-timeout-limit-increased-36-hours"}
{"id": "60cc3593e16d815fefb1bd596dd1d99233fcf281", "guidislink": false, "title": "Amazon WorkSpaces introduces support for Red Hat Enterprise Linux", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon WorkSpaces introduces support for Red Hat Enterprise Linux"}, "summary": "<p>AWS today announced support for Red Hat Enterprise Linux on Amazon WorkSpaces Personal. This operating system includes built-in security features that help organizations to run virtual desktops securely, while increasing agility and reducing cost. With this launch, WorkSpaces Personal customers have the flexibility to choose from a wider range of operating systems including Red Hat Enterprise Linux, Ubuntu Desktop, Amazon Linux 2, and Microsoft Windows.<br /> <br /> With Red Hat Enterprise Linux on WorkSpaces Personal, IT organizations can enable developers to work in an environment that is consistent with their production environment, and provide power users like engineers and data scientists with on-demand access to Red Hat Enterprise Linux environments whenever necessary\u2014quickly spinning up and tearing down instances and managing the entire fleet through the AWS Console, without the burden of capacity planning or license management. WorkSpaces Personal offers a wide range of high-performance, license-included, fully-managed virtual desktop bundles\u2014enabling organizations to only pay for the resources they use.<br /> <br /> Red Hat Enterprise Linux on WorkSpaces Personal is available in all AWS <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">Regions</a> where WorkSpaces Personal is available, except for AWS China Regions. Depending on the WorkSpaces Personal <a href=\"https://docs.aws.amazon.com/workspaces/latest/adminguide/running-mode.html\" target=\"_blank\">running mode</a>, you will be charged hourly or monthly for your virtual desktops. For more details on pricing, refer to <a href=\"https://aws.amazon.com/workspaces/pricing/\" target=\"_blank\">Amazon WorkSpaces Pricing</a>.<br /> <br /> To get started with Red Hat Enterprise Linux on WorkSpace Personal log on to <a href=\"https://console.aws.amazon.com/workspaces\" target=\"_blank\">AWS Management Console</a>, navigate to the WorkSpaces service and follow the <a href=\"https://docs.aws.amazon.com/workspaces/latest/adminguide/amazon-workspaces.html\" target=\"_blank\">Amazon WorkSpaces administration guide</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS today announced support for Red Hat Enterprise Linux on Amazon WorkSpaces Personal. This operating system includes built-in security features that help organizations to run virtual desktops securely, while increasing agility and reducing cost. With this launch, WorkSpaces Personal customers have the flexibility to choose from a wider range of operating systems including Red Hat Enterprise Linux, Ubuntu Desktop, Amazon Linux 2, and Microsoft Windows.<br /> <br /> With Red Hat Enterprise Linux on WorkSpaces Personal, IT organizations can enable developers to work in an environment that is consistent with their production environment, and provide power users like engineers and data scientists with on-demand access to Red Hat Enterprise Linux environments whenever necessary\u2014quickly spinning up and tearing down instances and managing the entire fleet through the AWS Console, without the burden of capacity planning or license management. WorkSpaces Personal offers a wide range of high-performance, license-included, fully-managed virtual desktop bundles\u2014enabling organizations to only pay for the resources they use.<br /> <br /> Red Hat Enterprise Linux on WorkSpaces Personal is available in all AWS <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">Regions</a> where WorkSpaces Personal is available, except for AWS China Regions. Depending on the WorkSpaces Personal <a href=\"https://docs.aws.amazon.com/workspaces/latest/adminguide/running-mode.html\" target=\"_blank\">running mode</a>, you will be charged hourly or monthly for your virtual desktops. For more details on pricing, refer to <a href=\"https://aws.amazon.com/workspaces/pricing/\" target=\"_blank\">Amazon WorkSpaces Pricing</a>.<br /> <br /> To get started with Red Hat Enterprise Linux on WorkSpace Personal log on to <a href=\"https://console.aws.amazon.com/workspaces\" target=\"_blank\">AWS Management Console</a>, navigate to the WorkSpaces service and follow the <a href=\"https://docs.aws.amazon.com/workspaces/latest/adminguide/amazon-workspaces.html\" target=\"_blank\">Amazon WorkSpaces administration guide</a>.<br /> &nbsp;</p>"}, "published": "Fri, 28 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 28, 17, 0, 0, 4, 180, 0], "tags": [{"term": "marketing:marchitecture/desktop-and-app-streaming,general:products/amazon-workspaces,general:products/aws-govcloud-us", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-workspaces-red-hat-enterprise-linux/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-workspaces-red-hat-enterprise-linux/"}
{"id": "74d4630e1afecd4ddd86feb980079f64254a941a", "guidislink": false, "title": "Amazon SageMaker Canvas announces new capabilities for time series forecasting models", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon SageMaker Canvas announces new capabilities for time series forecasting models"}, "summary": "<p><a href=\"https://aws.amazon.com/sagemaker/canvas/\" target=\"_blank\">Amazon SageMaker Canvas</a> announces new capabilities to build, evaluate, and deploy time series forecasting models, providing greater flexibility and ease of use to build forecasting applications. Amazon SageMaker Canvas is a no-code workspace that empowers analysts and citizen data scientists to build, customize, and deploy machine learning (ML) models to generate accurate predictions.<br /> <br /> To build time series forecasting models, SageMaker Canvas uses up to six built-in algorithms to create a custom ensemble of models for each item in your time series, resulting in highly accurate models. Starting today, SageMaker Canvas provides visibility into these algorithms and the flexibility to choose any combination of these algorithms to build your time series forecasting model. Once the model is built, SageMaker Canvas provides a leaderboard with a ranked list of model candidates including a recommendation for the best model based on your dataset and the problem to be solved. You can review key performance metrics for each model on the leaderboard and select a model of your choice. The selected model can then be deployed into production on an Amazon SageMaker real-time inference endpoint for use in applications outside SageMaker Canvas.<br /> <br /> To access the algorithm selection, model leaderboard, and direct deployment to real-time endpoint capabilities for time series forecasting, log out and log back in to SageMaker Canvas. The new capabilities are now available in all AWS regions where SageMaker Canvas is supported. To learn more, refer to the&nbsp;<a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/canvas-time-series.html\" target=\"_blank\">SageMaker Canvas product documentation</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://aws.amazon.com/sagemaker/canvas/\" target=\"_blank\">Amazon SageMaker Canvas</a> announces new capabilities to build, evaluate, and deploy time series forecasting models, providing greater flexibility and ease of use to build forecasting applications. Amazon SageMaker Canvas is a no-code workspace that empowers analysts and citizen data scientists to build, customize, and deploy machine learning (ML) models to generate accurate predictions.<br /> <br /> To build time series forecasting models, SageMaker Canvas uses up to six built-in algorithms to create a custom ensemble of models for each item in your time series, resulting in highly accurate models. Starting today, SageMaker Canvas provides visibility into these algorithms and the flexibility to choose any combination of these algorithms to build your time series forecasting model. Once the model is built, SageMaker Canvas provides a leaderboard with a ranked list of model candidates including a recommendation for the best model based on your dataset and the problem to be solved. You can review key performance metrics for each model on the leaderboard and select a model of your choice. The selected model can then be deployed into production on an Amazon SageMaker real-time inference endpoint for use in applications outside SageMaker Canvas.<br /> <br /> To access the algorithm selection, model leaderboard, and direct deployment to real-time endpoint capabilities for time series forecasting, log out and log back in to SageMaker Canvas. The new capabilities are now available in all AWS regions where SageMaker Canvas is supported. To learn more, refer to the&nbsp;<a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/canvas-time-series.html\" target=\"_blank\">SageMaker Canvas product documentation</a>.</p>"}, "published": "Fri, 28 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 28, 17, 0, 0, 4, 180, 0], "tags": [{"term": "marketing:marchitecture/artificial-intelligence,general:products/amazon-machine-learning,general:products/amazon-sagemaker-canvas", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-sagemaker-canvas-capabilities-time-forecasting-models/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-sagemaker-canvas-capabilities-time-forecasting-models/"}
{"id": "9f2dbaeffab024abac0641983254e7a1f427262b", "guidislink": false, "title": "AWS Backup support for Amazon S3 is now available in AWS Canada West (Calgary) Region", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Backup support for Amazon S3 is now available in AWS Canada West (Calgary) Region"}, "summary": "<p>Today, we are announcing the availability of AWS Backup support for Amazon S3 in Canada West (Calgary) Region. AWS Backup is a policy-based, fully managed and cost-effective solution that enables you to centralize and automate data protection of Amazon S3 along with other AWS services (spanning compute, storage, and databases) and third-party applications. Together with AWS Organizations, AWS Backup enables you to centrally deploy policies to configure, manage, and govern your data protection activity.<br /> <br /> With this launch, AWS Backup support for Amazon S3 is available in all AWS commercial, AWS China, and AWS GovCloud (US) Regions where AWS Backup is available. For more information on regional availability and pricing, see <a href=\"https://aws.amazon.com/backup/pricing/\" target=\"_blank\">AWS Backup pricing page</a>.<br /> <br /> To learn more about AWS Backup support for Amazon S3, visit the <a href=\"https://aws.amazon.com/backup/faqs/\" target=\"_blank\">product page</a> and <a href=\"https://docs.aws.amazon.com/aws-backup/latest/devguide/s3-backups.html\" target=\"_blank\">technical documentation</a>. To get started, visit the <a href=\"https://console.aws.amazon.com/backup\" target=\"_blank\">AWS Backup console</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, we are announcing the availability of AWS Backup support for Amazon S3 in Canada West (Calgary) Region. AWS Backup is a policy-based, fully managed and cost-effective solution that enables you to centralize and automate data protection of Amazon S3 along with other AWS services (spanning compute, storage, and databases) and third-party applications. Together with AWS Organizations, AWS Backup enables you to centrally deploy policies to configure, manage, and govern your data protection activity.<br /> <br /> With this launch, AWS Backup support for Amazon S3 is available in all AWS commercial, AWS China, and AWS GovCloud (US) Regions where AWS Backup is available. For more information on regional availability and pricing, see <a href=\"https://aws.amazon.com/backup/pricing/\" target=\"_blank\">AWS Backup pricing page</a>.<br /> <br /> To learn more about AWS Backup support for Amazon S3, visit the <a href=\"https://aws.amazon.com/backup/faqs/\" target=\"_blank\">product page</a> and <a href=\"https://docs.aws.amazon.com/aws-backup/latest/devguide/s3-backups.html\" target=\"_blank\">technical documentation</a>. To get started, visit the <a href=\"https://console.aws.amazon.com/backup\" target=\"_blank\">AWS Backup console</a>.</p>"}, "published": "Thu, 27 Jun 2024 21:50:00 GMT", "published_parsed": [2024, 6, 27, 21, 50, 0, 3, 179, 0], "tags": [{"term": "general:products/aws-backup,marketing:marchitecture/storage,general:products/amazon-s3", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-backup-amazon-s3-calgary-region"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-backup-amazon-s3-calgary-region"}
{"id": "d5c8f0740e578deb3f16196a1d15443e0761767d", "guidislink": false, "title": "Amazon QuickSight simplifies building pixel-perfect reports with Repeating Sections", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon QuickSight simplifies building pixel-perfect reports with Repeating Sections"}, "summary": "<p>Today, Amazon QuickSight announces the addition of Repeating Sections capability within Pixel-perfect reports. The new feature gives QuickSight Authors the ability to configure report sections to automatically repeat based on the values of one or more dimensions in their data.<br /> <br /> When defining a repeating section, QuickSight users can select which dimension(s) the section should repeat for, such as state, country, or product category. The section will then dynamically generate a copy for each unique value in the selected dimension(s). For example, a section could repeat once for each state so that separate charts and text are generated specifically for California, Texas, New York, and other states. Repeating sections make it easy to automatically generate customized views of data across different groups or categories with minimal effort.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, Amazon QuickSight announces the addition of Repeating Sections capability within Pixel-perfect reports. The new feature gives QuickSight Authors the ability to configure report sections to automatically repeat based on the values of one or more dimensions in their data.<br /> <br /> When defining a repeating section, QuickSight users can select which dimension(s) the section should repeat for, such as state, country, or product category. The section will then dynamically generate a copy for each unique value in the selected dimension(s). For example, a section could repeat once for each state so that separate charts and text are generated specifically for California, Texas, New York, and other states. Repeating sections make it easy to automatically generate customized views of data across different groups or categories with minimal effort.</p>"}, "published": "Thu, 27 Jun 2024 21:00:00 GMT", "published_parsed": [2024, 6, 27, 21, 0, 0, 3, 179, 0], "tags": [{"term": "general:products/amazon-quicksight,marketing:marchitecture/analytics", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-quicksight-building-pixel-perfect-reports-repeating-sections"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-quicksight-building-pixel-perfect-reports-repeating-sections"}
{"id": "288707f2772a8d7b1a5ac1f90668cfb47f124f63", "guidislink": false, "title": "Amazon DataZone introduces API-driven, OpenLineage-compatible data lineage visualization in preview", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon DataZone introduces API-driven, OpenLineage-compatible data lineage visualization in preview"}, "summary": "<p>Amazon DataZone introduces data lineage in preview, helping customers visualize lineage events from OpenLineage-enabled systems or through API and trace data movement from source to consumption. Amazon DataZone is a data management service for customers to catalog, discover, share, and govern data at scale across organizational boundaries with governance and access controls.<br /> <br /> Amazon DataZone's data lineage feature captures and visualizes the transformations of data assets and columns, providing a view into the data movement from source to consumption. Using Amazon DataZone's OpenLineage-compatible API, domain administrators and data producers can capture and store lineage events beyond what is available in Amazon DataZone, including transformations in Amazon S3, AWS Glue, and other services. Data consumers in Amazon DataZone can gain confidence in an asset's origin from the comprehensive view of its lineage while data producers can assess the impact of changes to an asset by understanding its consumption. Additionally, Amazon DataZone versions lineage with each event, enabling users to visualize lineage at any point in time or compare transformations across an asset's or job's history. This historical lineage provides a deeper understanding of how data has evolved, essential for troubleshooting, auditing, and validating the integrity of data assets.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon DataZone introduces data lineage in preview, helping customers visualize lineage events from OpenLineage-enabled systems or through API and trace data movement from source to consumption. Amazon DataZone is a data management service for customers to catalog, discover, share, and govern data at scale across organizational boundaries with governance and access controls.<br /> <br /> Amazon DataZone's data lineage feature captures and visualizes the transformations of data assets and columns, providing a view into the data movement from source to consumption. Using Amazon DataZone's OpenLineage-compatible API, domain administrators and data producers can capture and store lineage events beyond what is available in Amazon DataZone, including transformations in Amazon S3, AWS Glue, and other services. Data consumers in Amazon DataZone can gain confidence in an asset's origin from the comprehensive view of its lineage while data producers can assess the impact of changes to an asset by understanding its consumption. Additionally, Amazon DataZone versions lineage with each event, enabling users to visualize lineage at any point in time or compare transformations across an asset's or job's history. This historical lineage provides a deeper understanding of how data has evolved, essential for troubleshooting, auditing, and validating the integrity of data assets.</p>"}, "published": "Thu, 27 Jun 2024 20:20:00 GMT", "published_parsed": [2024, 6, 27, 20, 20, 0, 3, 179, 0], "tags": [{"term": "marketing:marchitecture/analytics,general:products/amazon-datazone", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-datazone-openlineage-compatible-data-lineage-visualization-preview"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-datazone-openlineage-compatible-data-lineage-visualization-preview"}
{"id": "dee8ed44392bd0e0ef30b04d46d63c4c0b879e4d", "guidislink": false, "title": "Amazon Managed Service for Apache Flink now supports Apache Flink 1.19", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Managed Service for Apache Flink now supports Apache Flink 1.19"}, "summary": "<p>Amazon Managed Service for Apache Flink now supports Apache Flink 1.19. This version includes new capabilities in the SQL API such as state TTL configuration and session window support. Flink 1.19 also includes Python 3.11 support, trace reporters for job restarts and checkpointing, and more. You can use<a href=\"https://docs.aws.amazon.com/managed-flink/latest/java/how-in-place-version-upgrades.html\" target=\"_blank\"> in-place version upgrades for Apache Flink </a>to adopt the Apache Flink 1.19 runtime for a simple and faster upgrade to your existing application.<br /> <br /> Amazon Managed Service for Apache Flink makes it easier to transform and analyze streaming data in real time with Apache Flink. Apache Flink is an open source framework and engine for processing data streams. Amazon Managed Service for Apache Flink reduces the complexity of building and managing Apache Flink applications and integrates with Amazon Managed Streaming for Apache Kafka (Amazon MSK), Amazon Kinesis Data Streams, Amazon OpenSearch Service, Amazon DynamoDB streams, Amazon S3, custom integrations, and more using built-in connectors. Create or update an Amazon Managed Service for Apache Flink application in the <a href=\"https://console.aws.amazon.com/flink/home\" target=\"_blank\">Amazon Managed Service for Apache Flink console</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Managed Service for Apache Flink now supports Apache Flink 1.19. This version includes new capabilities in the SQL API such as state TTL configuration and session window support. Flink 1.19 also includes Python 3.11 support, trace reporters for job restarts and checkpointing, and more. You can use<a href=\"https://docs.aws.amazon.com/managed-flink/latest/java/how-in-place-version-upgrades.html\" target=\"_blank\"> in-place version upgrades for Apache Flink </a>to adopt the Apache Flink 1.19 runtime for a simple and faster upgrade to your existing application.<br /> <br /> Amazon Managed Service for Apache Flink makes it easier to transform and analyze streaming data in real time with Apache Flink. Apache Flink is an open source framework and engine for processing data streams. Amazon Managed Service for Apache Flink reduces the complexity of building and managing Apache Flink applications and integrates with Amazon Managed Streaming for Apache Kafka (Amazon MSK), Amazon Kinesis Data Streams, Amazon OpenSearch Service, Amazon DynamoDB streams, Amazon S3, custom integrations, and more using built-in connectors. Create or update an Amazon Managed Service for Apache Flink application in the <a href=\"https://console.aws.amazon.com/flink/home\" target=\"_blank\">Amazon Managed Service for Apache Flink console</a>.</p>"}, "published": "Thu, 27 Jun 2024 20:10:00 GMT", "published_parsed": [2024, 6, 27, 20, 10, 0, 3, 179, 0], "tags": [{"term": "general:products/amazon-managed-service-for-apache-flink,marketing:marchitecture/analytics,general:products/aws-govcloud-us", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-managed-service-apache-flink-1-19"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-managed-service-apache-flink-1-19"}
{"id": "82d9fa2be7a837d207f0e86ce71804b69bc72874", "guidislink": false, "title": "Amazon IVS Real-Time Streaming now supports up to 25,000 viewers", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon IVS Real-Time Streaming now supports up to 25,000 viewers"}, "summary": "<p>The Amazon IVS Real-Time Streaming capability subscriber limit can now be raised beyond the default of 10,000 per stage in an AWS Region. You can request an increase for up to 25,000 subscribers per stage. With this enhancement, you can now reach an audience that is more than double the previous size, all engaging in the same Real-Time Stream.<br /> <br /> The increased limit for subscribers per stage is supported in all AWS Regions where Amazon IVS is available. You can request a quota increase by using the Service Quotas console. To learn more about Amazon IVS Real-Time Streaming quotas, please refer to the service <a href=\"https://docs.aws.amazon.com/ivs/latest/RealTimeUserGuide/service-quotas.html\" target=\"_blank\">documentation</a>.<br /> <br /> <a href=\"https://aws.amazon.com/ivs/\" target=\"_blank\">Amazon IVS</a> is a managed live streaming solution that is designed to be quick and easy to set up, and ideal for creating interactive video experiences. Video ingest and delivery are available around the world over a managed network of infrastructure optimized for live video. Visit the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS region table</a> for a full list of AWS Regions where the Amazon IVS console and APIs for control and creation of video streams are available.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>The Amazon IVS Real-Time Streaming capability subscriber limit can now be raised beyond the default of 10,000 per stage in an AWS Region. You can request an increase for up to 25,000 subscribers per stage. With this enhancement, you can now reach an audience that is more than double the previous size, all engaging in the same Real-Time Stream.<br /> <br /> The increased limit for subscribers per stage is supported in all AWS Regions where Amazon IVS is available. You can request a quota increase by using the Service Quotas console. To learn more about Amazon IVS Real-Time Streaming quotas, please refer to the service <a href=\"https://docs.aws.amazon.com/ivs/latest/RealTimeUserGuide/service-quotas.html\" target=\"_blank\">documentation</a>.<br /> <br /> <a href=\"https://aws.amazon.com/ivs/\" target=\"_blank\">Amazon IVS</a> is a managed live streaming solution that is designed to be quick and easy to set up, and ideal for creating interactive video experiences. Video ingest and delivery are available around the world over a managed network of infrastructure optimized for live video. Visit the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS region table</a> for a full list of AWS Regions where the Amazon IVS console and APIs for control and creation of video streams are available.</p>"}, "published": "Thu, 27 Jun 2024 17:30:00 GMT", "published_parsed": [2024, 6, 27, 17, 30, 0, 3, 179, 0], "tags": [{"term": "general:products/amazon-ivs,marketing:marchitecture/media-services", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-ivs-real-time-streaming-25000-viewers"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-ivs-real-time-streaming-25000-viewers"}
{"id": "61cf9316cf41a3cc3c8f40624704567e2c7e8839", "guidislink": false, "title": "AWS Blu Insights accelerates migrations with new AI capabilities", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Blu Insights accelerates migrations with new AI capabilities"}, "summary": "<p>We are excited to announce new capabilities for accelerating AWS Mainframe Modernization with machine learning and generative AI assistance. Using the latest generative AI models in Amazon Bedrock and AWS Machine Learning services like Amazon Translate, AWS Blu Insights makes it simple to automatically generate code and file descriptions, transform code from mainframe languages, and query projects using natural language.<br /> <br /> Customers can now automatically generate summaries of source code files and snips, making it much easier to understand legacy mainframe applications. If a codebase has comments in languages other than English, with a click on the console, customers can view a translation of the comments into the English language. Blu Insights also makes it much faster to find information within files. Now, customers can filter data in projects using natural language that Blu Insights automatically converts to specific Blu Age queries. Using GenAI, Blu Insights also speeds up common tasks by classifying codebase files that don\u2019t have an extension, converting source files written in languages like Rexx and C, and creating previews of mainframe BMS screens.<br /> <br /> Finally, new project management features driven by GenAI simplify project management by taking natural language text like \u201cschedule a meeting\u201d and automating the creation of scheduled events to save time and improve collaboration. Customers can now take advantage of automatically generated Activity Summaries and Activity Audits, which includes the actions taken by AI in a Blu Age project for auditing and compliance purposes.<br /> <br /> To learn more, visit AWS Mainframe Modernization <a href=\"https://aws.amazon.com/mainframe-modernization/\" target=\"_blank\">service</a> and <a href=\"https://bluinsights.aws/docs/\" target=\"_blank\">documentation</a> pages.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>We are excited to announce new capabilities for accelerating AWS Mainframe Modernization with machine learning and generative AI assistance. Using the latest generative AI models in Amazon Bedrock and AWS Machine Learning services like Amazon Translate, AWS Blu Insights makes it simple to automatically generate code and file descriptions, transform code from mainframe languages, and query projects using natural language.<br /> <br /> Customers can now automatically generate summaries of source code files and snips, making it much easier to understand legacy mainframe applications. If a codebase has comments in languages other than English, with a click on the console, customers can view a translation of the comments into the English language. Blu Insights also makes it much faster to find information within files. Now, customers can filter data in projects using natural language that Blu Insights automatically converts to specific Blu Age queries. Using GenAI, Blu Insights also speeds up common tasks by classifying codebase files that don\u2019t have an extension, converting source files written in languages like Rexx and C, and creating previews of mainframe BMS screens.<br /> <br /> Finally, new project management features driven by GenAI simplify project management by taking natural language text like \u201cschedule a meeting\u201d and automating the creation of scheduled events to save time and improve collaboration. Customers can now take advantage of automatically generated Activity Summaries and Activity Audits, which includes the actions taken by AI in a Blu Age project for auditing and compliance purposes.<br /> <br /> To learn more, visit AWS Mainframe Modernization <a href=\"https://aws.amazon.com/mainframe-modernization/\" target=\"_blank\">service</a> and <a href=\"https://bluinsights.aws/docs/\" target=\"_blank\">documentation</a> pages.</p>"}, "published": "Thu, 27 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 27, 17, 0, 0, 3, 179, 0], "tags": [{"term": "marketing:marchitecture/migration,general:products/aws-mainframe-modernization", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-blu-insights-accelerates-migrations-ai-capabilities"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-blu-insights-accelerates-migrations-ai-capabilities"}
{"id": "4244adfec637914755d02898eda796eb2d39cdf1", "guidislink": false, "title": "Amazon EKS introduces cluster creation flexibility for networking add-ons", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon EKS introduces cluster creation flexibility for networking add-ons"}, "summary": "<p>Starting today, Amazon Elastic Kubernetes Service (EKS) provides the flexibility to create Kubernetes clusters without the default networking add-ons, enabling you to easily install open source or third party alternative add-ons or self-manage default networking add-ons using any Kubernetes lifecycle management tool.<br /> <br /> Every EKS cluster automatically comes with default networking add-ons including Amazon VPC CNI, CoreDNS, and kube-proxy providing critical functionality that enables pod and service operations for EKS clusters. EKS also allows you to bring open source or third party add-ons and tools that manage their lifecycle. With today\u2019s launch, you can skip the installation of default networking add-ons when creating the cluster, making it easier to install alternative add-ons. This also simplifies self-managing default networking add-ons using any lifecycle management tool like Helm or Kustomize, without needing to first remove the Kubernetes manifests of the add-ons from the cluster.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Starting today, Amazon Elastic Kubernetes Service (EKS) provides the flexibility to create Kubernetes clusters without the default networking add-ons, enabling you to easily install open source or third party alternative add-ons or self-manage default networking add-ons using any Kubernetes lifecycle management tool.<br /> <br /> Every EKS cluster automatically comes with default networking add-ons including Amazon VPC CNI, CoreDNS, and kube-proxy providing critical functionality that enables pod and service operations for EKS clusters. EKS also allows you to bring open source or third party add-ons and tools that manage their lifecycle. With today\u2019s launch, you can skip the installation of default networking add-ons when creating the cluster, making it easier to install alternative add-ons. This also simplifies self-managing default networking add-ons using any lifecycle management tool like Helm or Kustomize, without needing to first remove the Kubernetes manifests of the add-ons from the cluster.</p>"}, "published": "Thu, 27 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 27, 17, 0, 0, 3, 179, 0], "tags": [{"term": "marketing:marchitecture/containers,general:products/amazon-eks", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-eks-cluster-creation-flexibility-networking-add-ons"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-eks-cluster-creation-flexibility-networking-add-ons"}
{"id": "6508fb024d683632ad6d59038cf257a70d65eaca", "guidislink": false, "title": "Amazon ECR supports Open Container Initiative Image and Distribution specification version 1.1", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon ECR supports Open Container Initiative Image and Distribution specification version 1.1"}, "summary": "<p>Today, Amazon Elastic Container Registry (ECR) announced that it supports Open Container Initiative (OCI) Image and Distribution specification version 1.1, which includes support for Reference Types, simplifying the storage, discovery, and retrieval of artifacts related to a container image. AWS Container Services customers can now easily store, discover, and retrieve artifacts such as image signatures and Software bill of materials (SBOMs) as defined by OCI 1.1 for a variety of supply chain security use cases such as image signing and vulnerability auditing. Through ECR\u2019s support of Reference types, customers now have a simple user experience for distributing and managing artifacts related to these use cases, consistent with how they manage container images today.<br /> <br /> OCI Reference Types support in ECR allows customers to distribute artifacts in their repositories alongside their respective images. Artifacts for a specific image are discovered through their reference relationship, and can be pulled the same way images are pulled. In addition, ECR\u2019s replication feature supports referrers, copying artifacts to destination regions and accounts so they are ready to use alongside replicated images. ECR Lifecycle Policies also supports referring artifacts by deleting references when a subject image is deleted as a result of a lifecycle policy rule expire action, making management of referring artifacts simple with no additional configuration.<br /> <br /> OCI 1.1 is now supported in ECR in all AWS commercial regions and the AWS GovCloud (US) Regions. OCI 1.1 is also supported in Amazon ECR Public registry. To learn more, please visit our <a href=\"https://docs.aws.amazon.com/AmazonECR/latest/userguide/images.html\" target=\"_blank\">documentation</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, Amazon Elastic Container Registry (ECR) announced that it supports Open Container Initiative (OCI) Image and Distribution specification version 1.1, which includes support for Reference Types, simplifying the storage, discovery, and retrieval of artifacts related to a container image. AWS Container Services customers can now easily store, discover, and retrieve artifacts such as image signatures and Software bill of materials (SBOMs) as defined by OCI 1.1 for a variety of supply chain security use cases such as image signing and vulnerability auditing. Through ECR\u2019s support of Reference types, customers now have a simple user experience for distributing and managing artifacts related to these use cases, consistent with how they manage container images today.<br /> <br /> OCI Reference Types support in ECR allows customers to distribute artifacts in their repositories alongside their respective images. Artifacts for a specific image are discovered through their reference relationship, and can be pulled the same way images are pulled. In addition, ECR\u2019s replication feature supports referrers, copying artifacts to destination regions and accounts so they are ready to use alongside replicated images. ECR Lifecycle Policies also supports referring artifacts by deleting references when a subject image is deleted as a result of a lifecycle policy rule expire action, making management of referring artifacts simple with no additional configuration.<br /> <br /> OCI 1.1 is now supported in ECR in all AWS commercial regions and the AWS GovCloud (US) Regions. OCI 1.1 is also supported in Amazon ECR Public registry. To learn more, please visit our <a href=\"https://docs.aws.amazon.com/AmazonECR/latest/userguide/images.html\" target=\"_blank\">documentation</a>.</p>"}, "published": "Thu, 27 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 27, 17, 0, 0, 3, 179, 0], "tags": [{"term": "marketing:marchitecture/containers,general:products/amazon-ecr,general:products/aws-govcloud-us", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-ecr-oci-image-distribution-version-1-1/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-ecr-oci-image-distribution-version-1-1/"}
{"id": "c5ee1adcde700d5b66da324759bd8ba464bbc7e7", "guidislink": false, "title": "Announcing Amazon WorkSpaces Pools, a new feature of Amazon WorkSpaces", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Announcing Amazon WorkSpaces Pools, a new feature of Amazon WorkSpaces"}, "summary": "<p>Amazon Web Services (AWS) announces a new feature of Amazon WorkSpaces, called Amazon WorkSpaces Pools, that helps customers save costs by sharing a pool of virtual desktops across a group of users who get a fresh desktop every time they log in. This new feature provides customers the flexibility and choice to support a wide range of use cases, including training labs, contact centers, and other shared-environments. Some user settings like bookmarks and files stored in a central storage repository like Amazon S3 or Amazon FSx can be saved for improved personalization.</p> \n<p>WorkSpaces Pools also simplifies management across a customer\u2019s WorkSpaces environment by providing a single console and set of clients to manage the various desktop hardware configurations, storage, and applications for the user, including the ability to manage their existing Microsoft 365 Apps for enterprise. Customers use <a href=\"https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html\" target=\"_blank\">AWS Application AutoScaling</a> to automatically scale a pool of virtual desktops based on real-time usage metrics or predefined schedules. WorkSpaces Pools offers pay-as-you-go hourly pricing, providing significant savings.</p> \n<p>With the launch of WorkSpaces Pools, customers now have the option to choose between WorkSpaces Personal, and WorkSpaces Pools. Customer can even opt for a blend of both, with the ease of managing from a single AWS Management Console. WorkSpaces Pools is now available with the usual WorkSpaces bundles including Value, Standard, Performance, Power, and PowerPro. For Region availability details, see <a href=\"https://docs.aws.amazon.com/workspaces/latest/adminguide/wsp-pools-regions.html\" target=\"_blank\">AWS Regions and Availability Zones for WorkSpaces Pools</a>. Learn more <a href=\"https://aws.amazon.com/blogs/aws/amazon-workspaces-pools-cost-effective-non-persistent-virtual-desktops/?trk=48f49f35-2ffe-4152-9ceb-47d990c28f5e&amp;sc_channel=sm\" target=\"_blank\">here</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Web Services (AWS) announces a new feature of Amazon WorkSpaces, called Amazon WorkSpaces Pools, that helps customers save costs by sharing a pool of virtual desktops across a group of users who get a fresh desktop every time they log in. This new feature provides customers the flexibility and choice to support a wide range of use cases, including training labs, contact centers, and other shared-environments. Some user settings like bookmarks and files stored in a central storage repository like Amazon S3 or Amazon FSx can be saved for improved personalization.</p> \n<p>WorkSpaces Pools also simplifies management across a customer\u2019s WorkSpaces environment by providing a single console and set of clients to manage the various desktop hardware configurations, storage, and applications for the user, including the ability to manage their existing Microsoft 365 Apps for enterprise. Customers use <a href=\"https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html\" target=\"_blank\">AWS Application AutoScaling</a> to automatically scale a pool of virtual desktops based on real-time usage metrics or predefined schedules. WorkSpaces Pools offers pay-as-you-go hourly pricing, providing significant savings.</p> \n<p>With the launch of WorkSpaces Pools, customers now have the option to choose between WorkSpaces Personal, and WorkSpaces Pools. Customer can even opt for a blend of both, with the ease of managing from a single AWS Management Console. WorkSpaces Pools is now available with the usual WorkSpaces bundles including Value, Standard, Performance, Power, and PowerPro. For Region availability details, see <a href=\"https://docs.aws.amazon.com/workspaces/latest/adminguide/wsp-pools-regions.html\" target=\"_blank\">AWS Regions and Availability Zones for WorkSpaces Pools</a>. Learn more <a href=\"https://aws.amazon.com/blogs/aws/amazon-workspaces-pools-cost-effective-non-persistent-virtual-desktops/?trk=48f49f35-2ffe-4152-9ceb-47d990c28f5e&amp;sc_channel=sm\" target=\"_blank\">here</a>.</p>"}, "published": "Thu, 27 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 27, 17, 0, 0, 3, 179, 0], "tags": [{"term": "marketing:marchitecture/desktop-and-app-streaming,general:products/amazon-workspaces", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-workspaces-pools-amazon-workspaces/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-workspaces-pools-amazon-workspaces/"}
{"id": "ec69f3646dd1744a955f8ef2970f0831c9ea116f", "guidislink": false, "title": "Updates and Expansion to the AWS Well-Architected Framework and Lens Catalog", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Updates and Expansion to the AWS Well-Architected Framework and Lens Catalog"}, "summary": "<p>AWS is excited to announce updates to the Well-Architected Framework and Lens Catalog. This latest update brings a comprehensive expansion to customers with expanded guidance on architectural best practices, empowering them to build and maintain optimized, secure, and resilient workloads in the cloud.<br /> <br /> The Framework updates provide more recommendations for AWS services, observability, generative AI, and operating models. We also refreshed the lists of resources and overall Framework structure. This update reduces redundancies, enhances consistency, and empowers customers to more accurately identify and address risks.<br /> <br /> We also expanded the Lens Catalog in the Well-Architected Tool to include additional industry-specific best practices. The Lens Catalog now includes the new <a href=\"https://aws.amazon.com/blogs/industries/announcing-the-aws-well-architected-financial-service-industry-lens/\" target=\"_blank\">Financial Services Industry Lens</a> and updates to the <a href=\"https://aws-blogs-prod.amazon.com/mt/announcing-the-aws-well-architected-mergers-and-acquisitions-lens/\" target=\"_blank\">Mergers and Acquisitions Lens.</a> Additionally, we made significant updates to the <a href=\"https://docs.aws.amazon.com/wellarchitected/latest/change-enablement-in-the-cloud/change-enablement-in-the-cloud.html\" target=\"_blank\">Change Enablement in the Cloud whitepaper</a>. With these updates to lenses and guidance, customers can optimize, secure, and align their cloud architectures based on their unique requirements.<br /> <br /> By leveraging the updated Well-Architected Framework and Lens Catalog, customers can follow the most current and comprehensive architectural best practices to confidently design, deploy, and operate their workloads in the cloud. To learn more about the AWS Well-Architected Framework and Lens Catalog updates, visit the <a href=\"https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html\" target=\"_blank\">AWS Well-Architected Framework documentation </a>and explore the updated lenses in the <a href=\"https://console.aws.amazon.com/wellarchitected\" target=\"_blank\">Well-Architected Tool</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS is excited to announce updates to the Well-Architected Framework and Lens Catalog. This latest update brings a comprehensive expansion to customers with expanded guidance on architectural best practices, empowering them to build and maintain optimized, secure, and resilient workloads in the cloud.<br /> <br /> The Framework updates provide more recommendations for AWS services, observability, generative AI, and operating models. We also refreshed the lists of resources and overall Framework structure. This update reduces redundancies, enhances consistency, and empowers customers to more accurately identify and address risks.<br /> <br /> We also expanded the Lens Catalog in the Well-Architected Tool to include additional industry-specific best practices. The Lens Catalog now includes the new <a href=\"https://aws.amazon.com/blogs/industries/announcing-the-aws-well-architected-financial-service-industry-lens/\" target=\"_blank\">Financial Services Industry Lens</a> and updates to the <a href=\"https://aws-blogs-prod.amazon.com/mt/announcing-the-aws-well-architected-mergers-and-acquisitions-lens/\" target=\"_blank\">Mergers and Acquisitions Lens.</a> Additionally, we made significant updates to the <a href=\"https://docs.aws.amazon.com/wellarchitected/latest/change-enablement-in-the-cloud/change-enablement-in-the-cloud.html\" target=\"_blank\">Change Enablement in the Cloud whitepaper</a>. With these updates to lenses and guidance, customers can optimize, secure, and align their cloud architectures based on their unique requirements.<br /> <br /> By leveraging the updated Well-Architected Framework and Lens Catalog, customers can follow the most current and comprehensive architectural best practices to confidently design, deploy, and operate their workloads in the cloud. To learn more about the AWS Well-Architected Framework and Lens Catalog updates, visit the <a href=\"https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html\" target=\"_blank\">AWS Well-Architected Framework documentation </a>and explore the updated lenses in the <a href=\"https://console.aws.amazon.com/wellarchitected\" target=\"_blank\">Well-Architected Tool</a>.<br /> &nbsp;</p>"}, "published": "Thu, 27 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 27, 17, 0, 0, 3, 179, 0], "tags": [{"term": "general:products/aws-well-architected-tool,marketing:marchitecture/management-and-governance", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/updates-expansion-aws-well-architected-lens-catalog/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/updates-expansion-aws-well-architected-lens-catalog/"}
{"id": "2a74aba844c642cb90e0c7e912848b58a644a178", "guidislink": false, "title": "PostgreSQL 17 Beta 2 is now available in Amazon RDS Database Preview Environment", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "PostgreSQL 17 Beta 2 is now available in Amazon RDS Database Preview Environment"}, "summary": "<p><a href=\"https://aws.amazon.com/rds/postgresql/\" target=\"_blank\">Amazon RDS for PostgreSQL</a> 17 Beta 2 is now available in the <a href=\"https://aws.amazon.com/rds/databasepreview/\" target=\"_blank\">Amazon RDS Database Preview Environment</a>, allowing you to evaluate the pre-release of PostgreSQL 17 on Amazon RDS for PostgreSQL. You can deploy PostgreSQL 17 Beta 2 in the Amazon RDS Database Preview Environment that has the benefits of a fully managed database.<br /> <br /> PostgreSQL 17 includes updates to vacuuming that reduces memory usage, improves time to finish vacuuming, and shows progress of vacuuming indexes. With PostgreSQL 17, you no longer need to drop logical replication slots when performing a major version upgrade. PostgreSQL 17 continues to build on the SQL/JSON standard, adding support for `JSON_TABLE` features that can convert JSON to a standard PostgreSQL table. The `MERGE` command now supports the `RETURNING` clause, letting you further work with modified rows. PostgreSQL 17 also includes general improvements to query performance and adds more flexibility to partition management with the ability to SPLIT/MERGE partitions. Please refer to the <a href=\"https://www.postgresql.org/about/news/postgresql-17-beta-1-released-2865/\" target=\"_blank\">PostgreSQL community announcement</a> for more details.<br /> <br /> Amazon RDS Database Preview Environment database instances are retained for a maximum period of 60 days and are automatically deleted after the retention period. Amazon RDS database snapshots that are created in the preview environment can only be used to create or restore database instances within the Preview Environment. You can use the PostgreSQL dump and load functionality to import or export your databases from the preview environment.<br /> <br /> Amazon RDS Database Preview Environment database instances are priced as per the <a href=\"https://aws.amazon.com/rds/postgresql/pricing/\" target=\"_blank\">pricing</a> in the US East (Ohio) Region.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://aws.amazon.com/rds/postgresql/\" target=\"_blank\">Amazon RDS for PostgreSQL</a> 17 Beta 2 is now available in the <a href=\"https://aws.amazon.com/rds/databasepreview/\" target=\"_blank\">Amazon RDS Database Preview Environment</a>, allowing you to evaluate the pre-release of PostgreSQL 17 on Amazon RDS for PostgreSQL. You can deploy PostgreSQL 17 Beta 2 in the Amazon RDS Database Preview Environment that has the benefits of a fully managed database.<br /> <br /> PostgreSQL 17 includes updates to vacuuming that reduces memory usage, improves time to finish vacuuming, and shows progress of vacuuming indexes. With PostgreSQL 17, you no longer need to drop logical replication slots when performing a major version upgrade. PostgreSQL 17 continues to build on the SQL/JSON standard, adding support for `JSON_TABLE` features that can convert JSON to a standard PostgreSQL table. The `MERGE` command now supports the `RETURNING` clause, letting you further work with modified rows. PostgreSQL 17 also includes general improvements to query performance and adds more flexibility to partition management with the ability to SPLIT/MERGE partitions. Please refer to the <a href=\"https://www.postgresql.org/about/news/postgresql-17-beta-1-released-2865/\" target=\"_blank\">PostgreSQL community announcement</a> for more details.<br /> <br /> Amazon RDS Database Preview Environment database instances are retained for a maximum period of 60 days and are automatically deleted after the retention period. Amazon RDS database snapshots that are created in the preview environment can only be used to create or restore database instances within the Preview Environment. You can use the PostgreSQL dump and load functionality to import or export your databases from the preview environment.<br /> <br /> Amazon RDS Database Preview Environment database instances are priced as per the <a href=\"https://aws.amazon.com/rds/postgresql/pricing/\" target=\"_blank\">pricing</a> in the US East (Ohio) Region.<br /> &nbsp;</p>"}, "published": "Thu, 27 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 27, 17, 0, 0, 3, 179, 0], "tags": [{"term": "general:products/amazon-rds,marketing:marchitecture/databases", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/postgresql-17-beta-2-rds-database-preview-environment/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/postgresql-17-beta-2-rds-database-preview-environment/"}
{"id": "15188eaa888b1a038d1a70a8494be352c7866f40", "guidislink": false, "title": "Amazon RDS Multi-AZ deployment with two readable standbys now supports snapshot export to S3", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon RDS Multi-AZ deployment with two readable standbys now supports snapshot export to S3"}, "summary": "<p><a href=\"https://aws.amazon.com/about-aws/whats-new/2022/03/amazon-rds-multi-az-transaction-commit-latency/\" target=\"_blank\">Amazon Relational Database Service (Amazon RDS) Multi-AZ deployments with two readable standbys </a>now supports export of snapshot data to an Amazon S3 bucket. Amazon RDS Multi-AZ deployments with two readable standbys is ideal when your workloads require lower write latency and more read capacity. In addition, this deployment option supports minor version upgrades and system maintenance updates with typically less than one second of downtime when using Amazon RDS Proxy or open source tools such as AWS Advanced JDBC Driver, PgBouncer, or ProxySQL.<br /> <br /> You can now export Amazon RDS Multi-AZ deployments with two readable standbys snapshot data to an Amazon S3 bucket. The export process runs in the background and doesn't affect the performance of your cluster. When you export a DB snapshot, Amazon RDS extracts data from the snapshot and stores it in an Amazon S3 bucket. The data is stored in an Apache Parquet format that is compressed and consistent. After the data is exported, you can analyze the exported data directly through tools like Amazon Athena or Amazon Redshift Spectrum.<br /> <br /> See the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RDS_Fea_Regions_DB-eng.Feature.MultiAZDBClusters.html\" target=\"_blank\">Amazon RDS User Guide</a> for a full list of supported Regions and engine versions.<br /> <br /> Learn more about Amazon RDS Multi-AZ deployments in the<a href=\"https://aws.amazon.com/blogs/aws/amazon-rds-multi-az-db-cluster/\" target=\"_blank\"> AWS News Blog</a>. Create or update fully managed Amazon RDS Multi-AZ databases with two readable standby instances in the <a href=\"https://console.aws.amazon.com/rds/home\" target=\"_blank\">Amazon RDS Management Console</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://aws.amazon.com/about-aws/whats-new/2022/03/amazon-rds-multi-az-transaction-commit-latency/\" target=\"_blank\">Amazon Relational Database Service (Amazon RDS) Multi-AZ deployments with two readable standbys </a>now supports export of snapshot data to an Amazon S3 bucket. Amazon RDS Multi-AZ deployments with two readable standbys is ideal when your workloads require lower write latency and more read capacity. In addition, this deployment option supports minor version upgrades and system maintenance updates with typically less than one second of downtime when using Amazon RDS Proxy or open source tools such as AWS Advanced JDBC Driver, PgBouncer, or ProxySQL.<br /> <br /> You can now export Amazon RDS Multi-AZ deployments with two readable standbys snapshot data to an Amazon S3 bucket. The export process runs in the background and doesn't affect the performance of your cluster. When you export a DB snapshot, Amazon RDS extracts data from the snapshot and stores it in an Amazon S3 bucket. The data is stored in an Apache Parquet format that is compressed and consistent. After the data is exported, you can analyze the exported data directly through tools like Amazon Athena or Amazon Redshift Spectrum.<br /> <br /> See the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.RDS_Fea_Regions_DB-eng.Feature.MultiAZDBClusters.html\" target=\"_blank\">Amazon RDS User Guide</a> for a full list of supported Regions and engine versions.<br /> <br /> Learn more about Amazon RDS Multi-AZ deployments in the<a href=\"https://aws.amazon.com/blogs/aws/amazon-rds-multi-az-db-cluster/\" target=\"_blank\"> AWS News Blog</a>. Create or update fully managed Amazon RDS Multi-AZ databases with two readable standby instances in the <a href=\"https://console.aws.amazon.com/rds/home\" target=\"_blank\">Amazon RDS Management Console</a>.<br /> &nbsp;</p>"}, "published": "Thu, 27 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 27, 17, 0, 0, 3, 179, 0], "tags": [{"term": "general:products/amazon-rds,marketing:marchitecture/databases", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-rds-multi-az-two-standbys-snapshot-export-s3/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-rds-multi-az-two-standbys-snapshot-export-s3/"}
{"id": "c8ade6889595d39d5119755b0e7b5ab1a2039c7e", "guidislink": false, "title": "Amazon Managed Service for Apache Flink introduces two new APIs to query operations on Flink applications", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Managed Service for Apache Flink introduces two new APIs to query operations on Flink applications"}, "summary": "<p>Amazon Managed Service for Apache Flink introduces the ListApplicationOperations and DescribeApplicationOperation APIs for visibility into operations that were performed on your application. These APIs provide details about when an operation was initiated, its current status, success or failure, if your operation triggered a rollback, and more so that you can take follow-up action.<br /> <br /> Amazon Managed Service for Apache Flink makes it easier to transform and analyze streaming data in real time with Apache Flink. Apache Flink is an open source framework and engine for processing data streams. Amazon Managed Service for Apache Flink reduces the complexity of building and managing Apache Flink applications and integrates with Amazon Managed Streaming for Apache Kafka (Amazon MSK), Amazon Kinesis Data Streams, Amazon OpenSearch Service, Amazon DynamoDB streams, Amazon Simple Storage Service (Amazon S3), custom integrations, and more using built-in connectors.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Managed Service for Apache Flink introduces the ListApplicationOperations and DescribeApplicationOperation APIs for visibility into operations that were performed on your application. These APIs provide details about when an operation was initiated, its current status, success or failure, if your operation triggered a rollback, and more so that you can take follow-up action.<br /> <br /> Amazon Managed Service for Apache Flink makes it easier to transform and analyze streaming data in real time with Apache Flink. Apache Flink is an open source framework and engine for processing data streams. Amazon Managed Service for Apache Flink reduces the complexity of building and managing Apache Flink applications and integrates with Amazon Managed Streaming for Apache Kafka (Amazon MSK), Amazon Kinesis Data Streams, Amazon OpenSearch Service, Amazon DynamoDB streams, Amazon Simple Storage Service (Amazon S3), custom integrations, and more using built-in connectors.</p>"}, "published": "Wed, 26 Jun 2024 21:05:00 GMT", "published_parsed": [2024, 6, 26, 21, 5, 0, 2, 178, 0], "tags": [{"term": "general:products/aws-govcloud-us,general:products/amazon-managed-service-for-apache-flink", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-managed-service-apache-flink-new-apis-query-operations-applications"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-managed-service-apache-flink-new-apis-query-operations-applications"}
{"id": "f8d483515128a100ce3035bc63f9dac228f6cbb1", "guidislink": false, "title": "Amazon Managed Service for Apache Flink now supports system-rollback", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Managed Service for Apache Flink now supports system-rollback"}, "summary": "<p>Amazon Managed Service for Apache Flink introduces the system-rollback feature to automatically revert your application to the previous running application version during Flink job submission if there are code or configuration errors. You can now opt-in to this feature for improved application uptime. You may encounter errors such as insufficient permissions, incompatible savepoints, and other errors when you perform application updates, Flink version upgrades, or scaling actions. System-rollback identifies these errors during job submission and prevents a bad update to your application. This gives you higher confidence in rolling out changes to your application faster.<br /> <br /> Amazon Managed Service for Apache Flink makes it easier to transform and analyze streaming data in real time with Apache Flink. Apache Flink is an open source framework and engine for processing data streams. Amazon Managed Service for Apache Flink reduces the complexity of building and managing Apache Flink applications and integrates with Amazon Managed Streaming for Apache Kafka (Amazon MSK), Amazon Kinesis Data Streams, Amazon OpenSearch Service, Amazon DynamoDB streams, Amazon Simple Storage Service (Amazon S3), custom integrations, and more using built-in connectors.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Managed Service for Apache Flink introduces the system-rollback feature to automatically revert your application to the previous running application version during Flink job submission if there are code or configuration errors. You can now opt-in to this feature for improved application uptime. You may encounter errors such as insufficient permissions, incompatible savepoints, and other errors when you perform application updates, Flink version upgrades, or scaling actions. System-rollback identifies these errors during job submission and prevents a bad update to your application. This gives you higher confidence in rolling out changes to your application faster.<br /> <br /> Amazon Managed Service for Apache Flink makes it easier to transform and analyze streaming data in real time with Apache Flink. Apache Flink is an open source framework and engine for processing data streams. Amazon Managed Service for Apache Flink reduces the complexity of building and managing Apache Flink applications and integrates with Amazon Managed Streaming for Apache Kafka (Amazon MSK), Amazon Kinesis Data Streams, Amazon OpenSearch Service, Amazon DynamoDB streams, Amazon Simple Storage Service (Amazon S3), custom integrations, and more using built-in connectors.</p>"}, "published": "Wed, 26 Jun 2024 21:00:00 GMT", "published_parsed": [2024, 6, 26, 21, 0, 0, 2, 178, 0], "tags": [{"term": "general:products/amazon-managed-service-for-apache-flink,marketing:marchitecture/analytics,general:products/aws-govcloud-us", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-managed-service-apache-flink-system-rollback"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-managed-service-apache-flink-system-rollback"}
{"id": "23f0f2069394cde61188be7c534cf8b4d4c0317c", "guidislink": false, "title": "Amazon Route 53 Application Recovery Controller zonal autoshift available in AWS GovCloud (US) Regions", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Route 53 Application Recovery Controller zonal autoshift available in AWS GovCloud (US) Regions"}, "summary": "<p>Amazon Route 53 Application Recovery Controller (Route 53 ARC) zonal autoshift is now generally available in the AWS GovCloud (US-East and US-West) Regions. AWS customers and AWS Partners who operate in the AWS GovCloud (US) Regions can now use zonal autoshift, a feature you can enable to safely and automatically shift an application\u2019s traffic away from an Availability Zone (AZ) when AWS identifies a potential failure affecting that AZ. For failures such as power and networking outages, zonal autoshift improves the availability of your application by shifting your application traffic away from an affected AZ to healthy AZs.<br /> <br /> To get started, you can enable zonal autoshift for Application Load Balancer and Network Load Balancer, with cross-zone configuration disabled, using the console, SDK or CLI, or an Amazon CloudFormation template. Once enabled, Amazon will automatically shift application traffic away from an affected AZ, and shift it back after the failure is resolved. Zonal autoshift includes practice runs, a feature that proactively tests if your application has sufficient capacity in each AZ to operate normally even after shifting away from an affected AZ. You configure practice runs to automatically apply zonal shifts, which regularly check if your application can tolerate losing capacity in an AZ.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Route 53 Application Recovery Controller (Route 53 ARC) zonal autoshift is now generally available in the AWS GovCloud (US-East and US-West) Regions. AWS customers and AWS Partners who operate in the AWS GovCloud (US) Regions can now use zonal autoshift, a feature you can enable to safely and automatically shift an application\u2019s traffic away from an Availability Zone (AZ) when AWS identifies a potential failure affecting that AZ. For failures such as power and networking outages, zonal autoshift improves the availability of your application by shifting your application traffic away from an affected AZ to healthy AZs.<br /> <br /> To get started, you can enable zonal autoshift for Application Load Balancer and Network Load Balancer, with cross-zone configuration disabled, using the console, SDK or CLI, or an Amazon CloudFormation template. Once enabled, Amazon will automatically shift application traffic away from an affected AZ, and shift it back after the failure is resolved. Zonal autoshift includes practice runs, a feature that proactively tests if your application has sufficient capacity in each AZ to operate normally even after shifting away from an affected AZ. You configure practice runs to automatically apply zonal shifts, which regularly check if your application can tolerate losing capacity in an AZ.</p>"}, "published": "Wed, 26 Jun 2024 20:15:00 GMT", "published_parsed": [2024, 6, 26, 20, 15, 0, 2, 178, 0], "tags": [{"term": "general:products/amazon-route-53,general:products/aws-govcloud-us,marketing:marchitecture/networking", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-route-53-application-recovery-controller-zonal-autoshift-govcloud-regions"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-route-53-application-recovery-controller-zonal-autoshift-govcloud-regions"}
{"id": "1ce696cd57b91e8e5233f43b07ea9e6fd4a9df27", "guidislink": false, "title": "Amazon OpenSearch Ingestion adds supports to ingest streaming data from Confluent Cloud", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon OpenSearch Ingestion adds supports to ingest streaming data from Confluent Cloud"}, "summary": "<p>Amazon OpenSearch Ingestion now allows you to seamlessly ingest streaming data from Confluent Cloud Kafka clusters into your Amazon OpenSearch Service managed clusters or Serverless collections without the need for any third-party data connectors. With this integration, you can now use Amazon OpenSearch Ingestion to perform near-real-time aggregations, sampling and anomaly detection on data ingested from Confluent Cloud, helping you to build efficient data pipelines to power your complex observability use cases.</p> \n<p>Amazon OpenSearch Ingestion pipelines can consume data from one or more topics in a Confluent Kafka cluster and transform the data before writing it to Amazon OpenSearch Service or Amazon S3. While reading data from Confluent Kafka clusters via Amazon OpenSearch Ingestion, you can configure the number of consumers per topic and tune different fetch parameters for high and low priority data. You can also optionally use Confluent Schema Registry to specify your data schema to dynamically read data at ingest time. You can also check out this blog <a href=\"https://www.confluent.io/blog/amazon-opensearch-ingestion-adds-support-for-confluent-cloud\" target=\"_blank\">post</a> by Confluent to learn more about this feature.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon OpenSearch Ingestion now allows you to seamlessly ingest streaming data from Confluent Cloud Kafka clusters into your Amazon OpenSearch Service managed clusters or Serverless collections without the need for any third-party data connectors. With this integration, you can now use Amazon OpenSearch Ingestion to perform near-real-time aggregations, sampling and anomaly detection on data ingested from Confluent Cloud, helping you to build efficient data pipelines to power your complex observability use cases.</p> \n<p>Amazon OpenSearch Ingestion pipelines can consume data from one or more topics in a Confluent Kafka cluster and transform the data before writing it to Amazon OpenSearch Service or Amazon S3. While reading data from Confluent Kafka clusters via Amazon OpenSearch Ingestion, you can configure the number of consumers per topic and tune different fetch parameters for high and low priority data. You can also optionally use Confluent Schema Registry to specify your data schema to dynamically read data at ingest time. You can also check out this blog <a href=\"https://www.confluent.io/blog/amazon-opensearch-ingestion-adds-support-for-confluent-cloud\" target=\"_blank\">post</a> by Confluent to learn more about this feature.</p>"}, "published": "Wed, 26 Jun 2024 19:30:00 GMT", "published_parsed": [2024, 6, 26, 19, 30, 0, 2, 178, 0], "tags": [{"term": "marketing:marchitecture/analytics,general:products/amazon-opensearch-service,marketing:marchitecture/serverless", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-opensearch-ingestion-support-ingest-streaming-data-confluent-cloud"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-opensearch-ingestion-support-ingest-streaming-data-confluent-cloud"}
{"id": "d63ca5c53568c636d30bc010bc8b266efd9ae507", "guidislink": false, "title": "Amazon CloudWatch Logs now supports account level subscription filter in 4 additional regions", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon CloudWatch Logs now supports account level subscription filter in 4 additional regions"}, "summary": "<p>Amazon CloudWatch Logs is excited to announce support for creating account-level subscription filters using the put-account-policy API in 4 additional regions. This new capability enables you to deliver real-time log events that are ingested into Amazon CloudWatch Logs to an Amazon Kinesis Data Stream, Amazon Kinesis Data Firehose, or AWS Lambda for custom processing, analysis, or delivery to other destinations using a single account level subscription filter.<br /> <br /> Customers often need to forward all or a subset of logs to AWS services such as Amazon OpenSearch for various analytical use cases or Amazon Kinesis Data Firehose for further streaming to other systems. Currently, customers have to set up a subscription filter for each log group. However, with account-level subscription filters, customers can egress logs ingested into multiple or all log groups by setting up a single subscription filter policy for the entire account. This saves time and reduces management overhead. The account-level subscription filter applies to both existing log groups and any future log groups that match the configuration. Each account can create one account-level subscription filter.<br /> <br /> CloudWatch Logs Account-level Subscription Filter is now available in the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS GovCloud (US-East) and (US-West) Regions, Israel (Tel Aviv), Canada West (Calgary).</a> To learn more, please refer to the documentation on <a href=\"http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SubscriptionFilters-AccountLevel.html\" target=\"_blank\">CloudWatch Logs Account Level Subscription Filters</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon CloudWatch Logs is excited to announce support for creating account-level subscription filters using the put-account-policy API in 4 additional regions. This new capability enables you to deliver real-time log events that are ingested into Amazon CloudWatch Logs to an Amazon Kinesis Data Stream, Amazon Kinesis Data Firehose, or AWS Lambda for custom processing, analysis, or delivery to other destinations using a single account level subscription filter.<br /> <br /> Customers often need to forward all or a subset of logs to AWS services such as Amazon OpenSearch for various analytical use cases or Amazon Kinesis Data Firehose for further streaming to other systems. Currently, customers have to set up a subscription filter for each log group. However, with account-level subscription filters, customers can egress logs ingested into multiple or all log groups by setting up a single subscription filter policy for the entire account. This saves time and reduces management overhead. The account-level subscription filter applies to both existing log groups and any future log groups that match the configuration. Each account can create one account-level subscription filter.<br /> <br /> CloudWatch Logs Account-level Subscription Filter is now available in the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS GovCloud (US-East) and (US-West) Regions, Israel (Tel Aviv), Canada West (Calgary).</a> To learn more, please refer to the documentation on <a href=\"http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/SubscriptionFilters-AccountLevel.html\" target=\"_blank\">CloudWatch Logs Account Level Subscription Filters</a>.<br /> &nbsp;</p>"}, "published": "Wed, 26 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 26, 17, 0, 0, 2, 178, 0], "tags": [{"term": "marketing:marchitecture/management-and-governance,general:products/amazon-cloudwatch-logs,general:products/aws-govcloud-us", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-cloudwatch-logs-subscription-filter-4-regions/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-cloudwatch-logs-subscription-filter-4-regions/"}
{"id": "8e7011e0e6cb955f90392fe81b39bcd3ef304449", "guidislink": false, "title": "AWS CloudShell now supports Amazon Virtual Private Cloud (VPC)", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS CloudShell now supports Amazon Virtual Private Cloud (VPC)"}, "summary": "<p>Today, AWS announces the general availability of Amazon Virtual Private Cloud (VPC) support for AWS CloudShell. This allows you to create CloudShell environments in a VPC, which enables you to use CloudShell securely within the same subnet as other resources in your VPC without the need for additional network configuration.<br /> <br /> Prior to this release, there was no mechanism to use CloudShell for controlling the network flow to the internet. This release allows you to securely and conveniently launch CloudShell in your VPC and access the resources within it.<br /> <br /> AWS CloudShell is a browser-based shell that makes it easy to securely manage, explore, and interact with your AWS resources. CloudShell is pre-authenticated with your console credentials. Common development tools are pre-installed so no local installation or configuration is required. With CloudShell you can run scripts with the AWS Command Line Interface (AWS CLI), define infrastructure with the AWS Cloud Development Kit (AWS CDK), experiment with AWS service APIs using the AWS SDKs, or use a range of other tools to increase your productivity.</p> \n<p>To learn more about VPC connectivity in AWS CloudShell see our <a href=\"https://docs.aws.amazon.com/cloudshell/latest/userguide/using-cshell-in-vpc.html\" target=\"_blank\">documentation</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, AWS announces the general availability of Amazon Virtual Private Cloud (VPC) support for AWS CloudShell. This allows you to create CloudShell environments in a VPC, which enables you to use CloudShell securely within the same subnet as other resources in your VPC without the need for additional network configuration.<br /> <br /> Prior to this release, there was no mechanism to use CloudShell for controlling the network flow to the internet. This release allows you to securely and conveniently launch CloudShell in your VPC and access the resources within it.<br /> <br /> AWS CloudShell is a browser-based shell that makes it easy to securely manage, explore, and interact with your AWS resources. CloudShell is pre-authenticated with your console credentials. Common development tools are pre-installed so no local installation or configuration is required. With CloudShell you can run scripts with the AWS Command Line Interface (AWS CLI), define infrastructure with the AWS Cloud Development Kit (AWS CDK), experiment with AWS service APIs using the AWS SDKs, or use a range of other tools to increase your productivity.</p> \n<p>To learn more about VPC connectivity in AWS CloudShell see our <a href=\"https://docs.aws.amazon.com/cloudshell/latest/userguide/using-cshell-in-vpc.html\" target=\"_blank\">documentation</a>.</p>"}, "published": "Wed, 26 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 26, 17, 0, 0, 2, 178, 0], "tags": [{"term": "general:products/aws-cloudshell,general:products/amazon-vpc,marketing:marchitecture/compute,marketing:marchitecture/developer-tools", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-cloudshell-amazon-virtual-private-cloud/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-cloudshell-amazon-virtual-private-cloud/"}
{"id": "f37123a75a6f430ae2491d2ede6ee54cc230119d", "guidislink": false, "title": "Amazon Athena Provisioned Capacity now available in South America (S\u00e3o Paulo) and Europe (Spain)", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Athena Provisioned Capacity now available in South America (S\u00e3o Paulo) and Europe (Spain)"}, "summary": "<p>Today, <a href=\"https://aws.amazon.com/athena/\" target=\"_blank\">Amazon Athena</a> made Provisioned Capacity available in the South America (S\u00e3o Paulo) and Europe (Spain) regions. Provisioned Capacity is a feature of Athena that allows you to run SQL queries on fully-managed, dedicated serverless resources for a fixed price and no long-term commitments. Using Provisioned Capacity, you can selectively assign processing capacity to queries and control workload performance characteristics such as query concurrency and cost. You can scale capacity at any time, and pay only for the amount of capacity you need and time it is active in your account.<br /> <br /> Athena is a serverless, interactive query service that makes it possible to analyze petabyte-scale data with ease and flexibility. Provisioned Capacity provides workload management capabilities that help you prioritize, isolate, and scale your interactive query workloads. For example, use Provisioned Capacity if you want to scale capacity to run many queries at the same time or to isolate important queries from others running in your account. To get started, use the Athena console, AWS SDK, or CLI to request capacity for your account and select the workgroups whose queries you want to use the capacity.<br /> <br /> Provisioned Capacity is also available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Tokyo), Asia Pacific (Sydney), Asia Pacific (Singapore), Europe (Ireland), Europe (Stockholm).<br /> <br /> To learn more, see <a href=\"https://docs.aws.amazon.com/athena/latest/ug/capacity-management.html\" target=\"_blank\">Managing query processing capacity</a> in the Amazon Athena User Guide. To learn more about pricing, visit the Athena <a href=\"https://aws.amazon.com/athena/pricing/\" target=\"_blank\">pricing page</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today, <a href=\"https://aws.amazon.com/athena/\" target=\"_blank\">Amazon Athena</a> made Provisioned Capacity available in the South America (S\u00e3o Paulo) and Europe (Spain) regions. Provisioned Capacity is a feature of Athena that allows you to run SQL queries on fully-managed, dedicated serverless resources for a fixed price and no long-term commitments. Using Provisioned Capacity, you can selectively assign processing capacity to queries and control workload performance characteristics such as query concurrency and cost. You can scale capacity at any time, and pay only for the amount of capacity you need and time it is active in your account.<br /> <br /> Athena is a serverless, interactive query service that makes it possible to analyze petabyte-scale data with ease and flexibility. Provisioned Capacity provides workload management capabilities that help you prioritize, isolate, and scale your interactive query workloads. For example, use Provisioned Capacity if you want to scale capacity to run many queries at the same time or to isolate important queries from others running in your account. To get started, use the Athena console, AWS SDK, or CLI to request capacity for your account and select the workgroups whose queries you want to use the capacity.<br /> <br /> Provisioned Capacity is also available in the following AWS Regions: US East (N. Virginia), US East (Ohio), US West (Oregon), Asia Pacific (Tokyo), Asia Pacific (Sydney), Asia Pacific (Singapore), Europe (Ireland), Europe (Stockholm).<br /> <br /> To learn more, see <a href=\"https://docs.aws.amazon.com/athena/latest/ug/capacity-management.html\" target=\"_blank\">Managing query processing capacity</a> in the Amazon Athena User Guide. To learn more about pricing, visit the Athena <a href=\"https://aws.amazon.com/athena/pricing/\" target=\"_blank\">pricing page</a>.<br /> &nbsp;</p>"}, "published": "Wed, 26 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 26, 17, 0, 0, 2, 178, 0], "tags": [{"term": "general:products/amazon-athena,marketing:marchitecture/analytics", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-athena-provisioned-capacity-south-america-europe/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-athena-provisioned-capacity-south-america-europe/"}
{"id": "bbce2afe82c273a349a86edd468a19143d75499c", "guidislink": false, "title": "Amazon Linux announces availability of AL2023.5 with new versions of PHP and Microsoft .NET", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Linux announces availability of AL2023.5 with new versions of PHP and Microsoft .NET"}, "summary": "<p>Today are announcing the availability of the latest quarterly update to AL2023 containing the latest version of PHP and .NET, along with IPA Client and mod-php.<br /> <br /> Customers can take advantage of newer versions of PHP and .NET to ensure their applications are secure and efficient. Additionally, AL2023.5 includes packages like mod-php and IPA client that can improve web server performance and simplify identity management integration, respectively, further streamlining development workflows and enhancing overall system efficiency.<br /> <br /> To learn more about other features and capabilities in AL2023.5, see <a href=\"https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes.html\" target=\"_blank\">release notes</a>.<br /> <br /> Amazon Linux 2023 is generally available in all <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regions</a>, including the AWS GovCloud (US) Regions and the China Regions. To learn more about Amazon Linux 2023, see the <a href=\"https://docs.aws.amazon.com/linux/al2022/ug/\" target=\"_blank\">AWS documentation</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Today are announcing the availability of the latest quarterly update to AL2023 containing the latest version of PHP and .NET, along with IPA Client and mod-php.<br /> <br /> Customers can take advantage of newer versions of PHP and .NET to ensure their applications are secure and efficient. Additionally, AL2023.5 includes packages like mod-php and IPA client that can improve web server performance and simplify identity management integration, respectively, further streamlining development workflows and enhancing overall system efficiency.<br /> <br /> To learn more about other features and capabilities in AL2023.5, see <a href=\"https://docs.aws.amazon.com/linux/al2023/release-notes/relnotes.html\" target=\"_blank\">release notes</a>.<br /> <br /> Amazon Linux 2023 is generally available in all <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Regions</a>, including the AWS GovCloud (US) Regions and the China Regions. To learn more about Amazon Linux 2023, see the <a href=\"https://docs.aws.amazon.com/linux/al2022/ug/\" target=\"_blank\">AWS documentation</a>.<br /> &nbsp;</p>"}, "published": "Wed, 26 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 26, 17, 0, 0, 2, 178, 0], "tags": [{"term": "marketing:marchitecture/compute,general:products/aws-govcloud-us,general:products/amazon-linux-2023", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-linux-al2023-5-versions-php-microsoft-net/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-linux-al2023-5-versions-php-microsoft-net/"}
{"id": "4787c613f927bbf19e74cc780ad34eeafe4240d9", "guidislink": false, "title": "EventBridge Scheduler adds more universal targets including Amazon Bedrock", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "EventBridge Scheduler adds more universal targets including Amazon Bedrock"}, "summary": "<p>EventBridge Scheduler adds additional universal targets with 650+ more AWS API actions bringing the total to 7000+, including Amazon Bedrock.</p> \n<p>EventBridge Scheduler allows you to create and run millions of scheduled events and tasks across AWS services without provisioning or managing the underlying infrastructure. EventBridge Scheduler supports one time and recurring schedules that can be created using common scheduling expressions such as cron, rate, and specific time with support for time zones and daylight savings. Our support for additional targets allows you to automate more use cases such as scheduling your Bedrock model to run inference for text models, image models, and embedding models at a specific point in time.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>EventBridge Scheduler adds additional universal targets with 650+ more AWS API actions bringing the total to 7000+, including Amazon Bedrock.</p> \n<p>EventBridge Scheduler allows you to create and run millions of scheduled events and tasks across AWS services without provisioning or managing the underlying infrastructure. EventBridge Scheduler supports one time and recurring schedules that can be created using common scheduling expressions such as cron, rate, and specific time with support for time zones and daylight savings. Our support for additional targets allows you to automate more use cases such as scheduling your Bedrock model to run inference for text models, image models, and embedding models at a specific point in time.</p>"}, "published": "Wed, 26 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 26, 17, 0, 0, 2, 178, 0], "tags": [{"term": "marketing:marchitecture/application-services,general:products/amazon-eventBridge", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/eventbridge-scheduler-universal-targets-amazon-bedrock"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/eventbridge-scheduler-universal-targets-amazon-bedrock"}
{"id": "e5c4072eb3e8f58a2535dc0f21202de071ae7045", "guidislink": false, "title": "Amazon Redshift Serverless with lower base capacity available in additional regions", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Redshift Serverless with lower base capacity available in additional regions"}, "summary": "<p>Amazon Redshift now allows you to get started with Amazon Redshift Serverless with a lower data warehouse <a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/serverless-capacity.html\" target=\"_blank\">base capacity configuration</a> of 8 Redshift Processing Units (RPUs) in the AWS Europe (Stockholm) and US West (Northern California) regions. Amazon Redshift Serverless measures data warehouse capacity in RPUs, and you pay only for the duration of workloads you run in RPU-hours on a per-second basis. Previously, the minimum base capacity required to run Amazon Redshift Serverless was 32 RPUs. With the new lower base capacity minimum of 8 RPUs, you now have even more flexibility to a support diverse set of workloads of small to large complexity based on your price performance requirements. You can increment or decrement the RPU in units of 8 RPUs.<br /> <br /> Amazon Redshift Serverless allows you to run and scale analytics without having to provision and manage data warehouse clusters. With Amazon Redshift Serverless, all users, including data analysts, developers, and data scientists, can use Amazon Redshift to get insights from data in seconds. With the new lower capacity configuration, you can use Amazon Redshift Serverless for production environments, test and development environments at an optimal price point when a workload needs a small amount of compute.<br /> <br /> To get started, see the Amazon Redshift Serverless <a href=\"https://aws.amazon.com/redshift/redshift-serverless/\" target=\"_blank\">feature page</a>, <a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-serverless.html\" target=\"_blank\">user documentation</a>, and <a href=\"https://docs.aws.amazon.com/redshift-serverless/latest/APIReference/Welcome.html\" target=\"_blank\">API Reference</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Redshift now allows you to get started with Amazon Redshift Serverless with a lower data warehouse <a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/serverless-capacity.html\" target=\"_blank\">base capacity configuration</a> of 8 Redshift Processing Units (RPUs) in the AWS Europe (Stockholm) and US West (Northern California) regions. Amazon Redshift Serverless measures data warehouse capacity in RPUs, and you pay only for the duration of workloads you run in RPU-hours on a per-second basis. Previously, the minimum base capacity required to run Amazon Redshift Serverless was 32 RPUs. With the new lower base capacity minimum of 8 RPUs, you now have even more flexibility to a support diverse set of workloads of small to large complexity based on your price performance requirements. You can increment or decrement the RPU in units of 8 RPUs.<br /> <br /> Amazon Redshift Serverless allows you to run and scale analytics without having to provision and manage data warehouse clusters. With Amazon Redshift Serverless, all users, including data analysts, developers, and data scientists, can use Amazon Redshift to get insights from data in seconds. With the new lower capacity configuration, you can use Amazon Redshift Serverless for production environments, test and development environments at an optimal price point when a workload needs a small amount of compute.<br /> <br /> To get started, see the Amazon Redshift Serverless <a href=\"https://aws.amazon.com/redshift/redshift-serverless/\" target=\"_blank\">feature page</a>, <a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-serverless.html\" target=\"_blank\">user documentation</a>, and <a href=\"https://docs.aws.amazon.com/redshift-serverless/latest/APIReference/Welcome.html\" target=\"_blank\">API Reference</a>.<br /> &nbsp;</p>"}, "published": "Wed, 26 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 26, 17, 0, 0, 2, 178, 0], "tags": [{"term": "marketing:marchitecture/analytics,general:products/amazon-redshift", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-redshift-serverless-lower-base-capacity-regions/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-redshift-serverless-lower-base-capacity-regions/"}
{"id": "47b554bc6125f0e08dabea1679ee5655f4db3bab", "guidislink": false, "title": "AWS Control Tower introduces an API to discover landing zone operations", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS Control Tower introduces an API to discover landing zone operations"}, "summary": "<p>AWS Control Tower customers can now programmatically retrieve a list of all landing zone operations that have completed in the past 90 days including create, update, reset, and delete. The output contains summary information like the operation identifier, operation type, and status to help identify initiated operations.<br /> <br /> Until today, customers could only retrieve landing zone operations if they requested it by operation identifier or examined all operations. API users on the same team could not view operations performed by others in the same landing zone, resulting in lost context and reduced visibility into all operations. Now customers can easily view, audit and troubleshoot operations for their entire landing zone to avoid duplicate operations and improve overall operational efficiency.<br /> <br /> To learn more about these APIs, review <a href=\"https://docs.aws.amazon.com/controltower/latest/userguide/getting-started-expectations-api.html\" target=\"_blank\">configurations for landing zone APIs</a> and <a href=\"https://docs.aws.amazon.com/controltower/latest/APIReference/Welcome.html\" target=\"_blank\">API References</a> in the AWS Control Tower User Guide. The new APIs are available in AWS Regions where AWS Control Tower is available. For a list of AWS Regions where AWS Control Tower is available, see the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Region Table</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS Control Tower customers can now programmatically retrieve a list of all landing zone operations that have completed in the past 90 days including create, update, reset, and delete. The output contains summary information like the operation identifier, operation type, and status to help identify initiated operations.<br /> <br /> Until today, customers could only retrieve landing zone operations if they requested it by operation identifier or examined all operations. API users on the same team could not view operations performed by others in the same landing zone, resulting in lost context and reduced visibility into all operations. Now customers can easily view, audit and troubleshoot operations for their entire landing zone to avoid duplicate operations and improve overall operational efficiency.<br /> <br /> To learn more about these APIs, review <a href=\"https://docs.aws.amazon.com/controltower/latest/userguide/getting-started-expectations-api.html\" target=\"_blank\">configurations for landing zone APIs</a> and <a href=\"https://docs.aws.amazon.com/controltower/latest/APIReference/Welcome.html\" target=\"_blank\">API References</a> in the AWS Control Tower User Guide. The new APIs are available in AWS Regions where AWS Control Tower is available. For a list of AWS Regions where AWS Control Tower is available, see the <a href=\"https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/\" target=\"_blank\">AWS Region Table</a>.<br /> &nbsp;</p>"}, "published": "Wed, 26 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 26, 17, 0, 0, 2, 178, 0], "tags": [{"term": "general:products/aws-control-tower,general:products/aws-govcloud-us,marketing:marchitecture/management-and-governance", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-control-tower-api-landing-zone-operations/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-control-tower-api-landing-zone-operations/"}
{"id": "8e9a1f5fb5a524318b923ad2c0ab0a74e589e66c", "guidislink": false, "title": "AI21 Labs' Jamba-Instruct model now available in Amazon Bedrock", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AI21 Labs' Jamba-Instruct model now available in Amazon Bedrock"}, "summary": "<p>AI21 Labs\u2019 Jamba-Instruct, a powerful instruction-following large language model, is now available in Amazon Bedrock. Fine-tuned for instruction following and built for reliable commercial use, Jamba-Instruct can engage in open-ended dialogue, understand context and subtext, and complete a wide variety of tasks based on natural language instructions.<br /> <br /> With its 256K context window, Jamba-Instruct has the capability to ingest the equivalent of a 800-page novel or an entire company's financial filings for a given fiscal year. This large context window allows Jamba-Instruct to answer questions and produce summaries that are grounded in the provided inputs, eliminating the need for manual segmentation of documents in order to fit smaller context windows.<br /> <br /> With its strong reasoning and analysis capabilities, Jamba-Instruct can break down complex problems, gather relevant information, and provide structured outputs. The model is ideal for common enterprise use cases such as enabling Q&amp;A on call transcripts, summarizing key points from documents, building chatbots, and more. Whether you need assistance with coding, writing, research, analysis, creative tasks, or general task assistance, Jamba-Instruct is a powerful model that can streamline your workflow and accelerate time to production for your gen AI enterprise applications.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AI21 Labs\u2019 Jamba-Instruct, a powerful instruction-following large language model, is now available in Amazon Bedrock. Fine-tuned for instruction following and built for reliable commercial use, Jamba-Instruct can engage in open-ended dialogue, understand context and subtext, and complete a wide variety of tasks based on natural language instructions.<br /> <br /> With its 256K context window, Jamba-Instruct has the capability to ingest the equivalent of a 800-page novel or an entire company's financial filings for a given fiscal year. This large context window allows Jamba-Instruct to answer questions and produce summaries that are grounded in the provided inputs, eliminating the need for manual segmentation of documents in order to fit smaller context windows.<br /> <br /> With its strong reasoning and analysis capabilities, Jamba-Instruct can break down complex problems, gather relevant information, and provide structured outputs. The model is ideal for common enterprise use cases such as enabling Q&amp;A on call transcripts, summarizing key points from documents, building chatbots, and more. Whether you need assistance with coding, writing, research, analysis, creative tasks, or general task assistance, Jamba-Instruct is a powerful model that can streamline your workflow and accelerate time to production for your gen AI enterprise applications.<br /> &nbsp;</p>"}, "published": "Tue, 25 Jun 2024 21:30:00 GMT", "published_parsed": [2024, 6, 25, 21, 30, 0, 1, 177, 0], "tags": [{"term": "marketing:marchitecture/artificial-intelligence,general:products/amazon-bedrock", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/ai21-labs-jamba-instruct-model-amazon-bedrock"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/ai21-labs-jamba-instruct-model-amazon-bedrock"}
{"id": "6e38d13a0cf1fa4edd03af74c47cf7f7333fd72f", "guidislink": false, "title": "Amazon CodeCatalyst now supports GitLab.com source code repositories", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon CodeCatalyst now supports GitLab.com source code repositories"}, "summary": "<p>Amazon CodeCatalyst now supports the use of source code repositories hosted in GitLab.com in CodeCatalyst projects. This allows customers to use GitLab.com repositories with CodeCatalyst\u2019s features such as its cloud IDE (Development Environments), Amazon Q feature development, and custom and public blueprints. Customers can also trigger CodeCatalyst workflows based on events in GitLab.com, view the status of CodeCatalyst workflows back in GitLab.com, and even block GitLab.com pull request merges based on the status of CodeCatalyst workflows.<br /> <br /> Customers want the flexibility to use source code repositories hosted in GitLab.com, without the need to migrate to CodeCatalyst to use it functionality. Migration is a long process and customers want to evaluate CodeCatalyst and its capabilities using their own code repositories before they decide to migrate. Support for popular source code providers such as GitLab.com is the top customer ask for CodeCatalyst. Now customers can use the capabilities of CodeCatalyst without the need for migration of source code from GitLab.com.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon CodeCatalyst now supports the use of source code repositories hosted in GitLab.com in CodeCatalyst projects. This allows customers to use GitLab.com repositories with CodeCatalyst\u2019s features such as its cloud IDE (Development Environments), Amazon Q feature development, and custom and public blueprints. Customers can also trigger CodeCatalyst workflows based on events in GitLab.com, view the status of CodeCatalyst workflows back in GitLab.com, and even block GitLab.com pull request merges based on the status of CodeCatalyst workflows.<br /> <br /> Customers want the flexibility to use source code repositories hosted in GitLab.com, without the need to migrate to CodeCatalyst to use it functionality. Migration is a long process and customers want to evaluate CodeCatalyst and its capabilities using their own code repositories before they decide to migrate. Support for popular source code providers such as GitLab.com is the top customer ask for CodeCatalyst. Now customers can use the capabilities of CodeCatalyst without the need for migration of source code from GitLab.com.</p>"}, "published": "Tue, 25 Jun 2024 21:00:00 GMT", "published_parsed": [2024, 6, 25, 21, 0, 0, 1, 177, 0], "tags": [{"term": "general:products/amazon-codecatalyst,marketing:marchitecture/developer-tools", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-codecatalyst-gitlab-com-source-code-repositories"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-codecatalyst-gitlab-com-source-code-repositories"}
{"id": "8279809aadace2673a2fe4cfad50aa698b3ea98f", "guidislink": false, "title": "Amazon MSK supports in-place upgrades from M5, T3 instance types to Graviton3 based M7G", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon MSK supports in-place upgrades from M5, T3 instance types to Graviton3 based M7G"}, "summary": "<p>You can now upgrade your <a href=\"https://aws.amazon.com/msk/\" target=\"_blank\">Amazon Managed Streaming for Apache Kafka (Amazon MSK)</a> provisioned clusters running on X-86 based M5 or T3 instances and replace them with AWS Graviton3-based M7G instances with a single click of a button. In-place upgrades allows you to seamlessly switch over your existing provisioned clusters to M7G instance type for better price performance, while continuing to serve reads and writes for your connecting client applications.<br /> <br /> Switching to <a href=\"https://aws.amazon.com/ec2/graviton/\" target=\"_blank\">AWS Graviton3 processor</a> based M7G instances on Amazon MSK provisioned clusters allows you to achieve up to 24% compute cost savings and up to 29% higher write and read throughput over comparable MSK clusters running on M5 instances. Additionally, these instances lower energy consumption by up to 60% than comparable instances, making your Kafka clusters more environmentally sustainable.<br /> <br /> In-place upgrades to M7G instances are now available in all AWS regions where MSK supports M7G. Please refer to our <a href=\"https://aws.amazon.com/blogs/big-data/amazon-msk-now-provides-up-to-29-more-throughput-and-up-to-24-lower-costs-with-aws-graviton3-support/\" target=\"_blank\">blog</a> for more information on the price/ performance improvements of M7g instances and the <a href=\"https://aws.amazon.com/msk/pricing/\" target=\"_blank\">Amazon MSK pricing page</a> for information on pricing. To get started, you can update your existing clusters to M7G brokers using the <a href=\"https://us-east-1.console.aws.amazon.com/msk/home?region=us-east-1#/cluster/create?isCustomCreate=false&amp;isProvisionedCreate=false\" target=\"_blank\">AWS Management Console</a>, and read our <a href=\"https://docs.aws.amazon.com/msk/latest/developerguide/what-is-msk.html\" target=\"_blank\">developer guide</a> for more information.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>You can now upgrade your <a href=\"https://aws.amazon.com/msk/\" target=\"_blank\">Amazon Managed Streaming for Apache Kafka (Amazon MSK)</a> provisioned clusters running on X-86 based M5 or T3 instances and replace them with AWS Graviton3-based M7G instances with a single click of a button. In-place upgrades allows you to seamlessly switch over your existing provisioned clusters to M7G instance type for better price performance, while continuing to serve reads and writes for your connecting client applications.<br /> <br /> Switching to <a href=\"https://aws.amazon.com/ec2/graviton/\" target=\"_blank\">AWS Graviton3 processor</a> based M7G instances on Amazon MSK provisioned clusters allows you to achieve up to 24% compute cost savings and up to 29% higher write and read throughput over comparable MSK clusters running on M5 instances. Additionally, these instances lower energy consumption by up to 60% than comparable instances, making your Kafka clusters more environmentally sustainable.<br /> <br /> In-place upgrades to M7G instances are now available in all AWS regions where MSK supports M7G. Please refer to our <a href=\"https://aws.amazon.com/blogs/big-data/amazon-msk-now-provides-up-to-29-more-throughput-and-up-to-24-lower-costs-with-aws-graviton3-support/\" target=\"_blank\">blog</a> for more information on the price/ performance improvements of M7g instances and the <a href=\"https://aws.amazon.com/msk/pricing/\" target=\"_blank\">Amazon MSK pricing page</a> for information on pricing. To get started, you can update your existing clusters to M7G brokers using the <a href=\"https://us-east-1.console.aws.amazon.com/msk/home?region=us-east-1#/cluster/create?isCustomCreate=false&amp;isProvisionedCreate=false\" target=\"_blank\">AWS Management Console</a>, and read our <a href=\"https://docs.aws.amazon.com/msk/latest/developerguide/what-is-msk.html\" target=\"_blank\">developer guide</a> for more information.<br /> &nbsp;</p>"}, "published": "Tue, 25 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 25, 17, 0, 0, 1, 177, 0], "tags": [{"term": "marketing:marchitecture/analytics,general:products/amazon-msk", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-msk-upgrades-m5-t3-instance-graviton3-m7g/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-msk-upgrades-m5-t3-instance-graviton3-m7g/"}
{"id": "881d06e0b91a4c69b796e2949cab429bcad21093", "guidislink": false, "title": "Amazon DocumentDB announces IAM database authentication", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon DocumentDB announces IAM database authentication"}, "summary": "<p>Amazon DocumentDB (with MongoDB compatibility) now supports cluster authentication with AWS Identity and Access Management (IAM) users and roles ARNs. Users and applications connecting to an Amazon DocumentDB cluster to read, write, update, or delete data can now use an AWS IAM identity to authenticate connection requests. These users and applications can use the same AWS IAM user or role when connecting to different DocumentDB clusters and to other AWS services.<br /> <br /> Applications running on AWS EC2, AWS Lambda, AWS ECS, or AWS EKS do not need to manage passwords in application when authenticating to Amazon DocumentDB using an AWS IAM role. These applications get their connection credentials through environment variables of an AWS IAM role, thus making it a passwordless mechanism.<br /> <br /> New and existing DocumentDB clusters can use AWS IAM to authenticate cluster connections without modifying the cluster configuration. You can also choose both password-based authentication and authentication with AWS IAM ARN to authenticate different users and applications to a DocumentDB cluster. Amazon DocumentDB cluster authentication with AWS IAM ARNs is supported by drivers which are compatible with MongoDB 5.0+.<br /> <br /> Authentication with AWS IAM ARNs is available in Amazon DocumentDB instance-based 5.0 clusters across all <a href=\"https://docs.aws.amazon.com/documentdb/latest/developerguide/regions-and-azs.html#regions-and-azs-availability\" target=\"_blank\">supported regions</a>. To learn more, please refer to the <a href=\"https://docs.aws.amazon.com/documentdb/latest/developerguide/iam-identity-auth.html\" target=\"_blank\">Amazon DocumentDB documentation</a>, and see the Region Support for complete regional availability. To learn more about IAM, refer to the <a href=\"https://aws.amazon.com/iam/\" target=\"_blank\">product detail page</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon DocumentDB (with MongoDB compatibility) now supports cluster authentication with AWS Identity and Access Management (IAM) users and roles ARNs. Users and applications connecting to an Amazon DocumentDB cluster to read, write, update, or delete data can now use an AWS IAM identity to authenticate connection requests. These users and applications can use the same AWS IAM user or role when connecting to different DocumentDB clusters and to other AWS services.<br /> <br /> Applications running on AWS EC2, AWS Lambda, AWS ECS, or AWS EKS do not need to manage passwords in application when authenticating to Amazon DocumentDB using an AWS IAM role. These applications get their connection credentials through environment variables of an AWS IAM role, thus making it a passwordless mechanism.<br /> <br /> New and existing DocumentDB clusters can use AWS IAM to authenticate cluster connections without modifying the cluster configuration. You can also choose both password-based authentication and authentication with AWS IAM ARN to authenticate different users and applications to a DocumentDB cluster. Amazon DocumentDB cluster authentication with AWS IAM ARNs is supported by drivers which are compatible with MongoDB 5.0+.<br /> <br /> Authentication with AWS IAM ARNs is available in Amazon DocumentDB instance-based 5.0 clusters across all <a href=\"https://docs.aws.amazon.com/documentdb/latest/developerguide/regions-and-azs.html#regions-and-azs-availability\" target=\"_blank\">supported regions</a>. To learn more, please refer to the <a href=\"https://docs.aws.amazon.com/documentdb/latest/developerguide/iam-identity-auth.html\" target=\"_blank\">Amazon DocumentDB documentation</a>, and see the Region Support for complete regional availability. To learn more about IAM, refer to the <a href=\"https://aws.amazon.com/iam/\" target=\"_blank\">product detail page</a>.</p>"}, "published": "Tue, 25 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 25, 17, 0, 0, 1, 177, 0], "tags": [{"term": "marketing:marchitecture/databases,general:products/aws-govcloud-us,general:products/amazon-documentdb", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-documentdb-iam-database-authentication/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-documentdb-iam-database-authentication/"}
{"id": "bccfac44a6a11c60ea20d91f9d45ba9426a91a75", "guidislink": false, "title": "Amazon Redshift Serverless with lower base capacity available in the Asia Pacific (Mumbai) Region", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Redshift Serverless with lower base capacity available in the Asia Pacific (Mumbai) Region"}, "summary": "<p>Amazon Redshift now allows you to get started with Amazon Redshift Serverless with a lower data warehouse <a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/serverless-capacity.html\" target=\"_blank\">base capacity configuration</a> of 8 Redshift Processing Units (RPUs) in the AWS Asia Pacific (Mumbai) region. Amazon Redshift Serverless measures data warehouse capacity in RPUs, and you pay only for the duration of workloads you run in RPU-hours on a per-second basis. Previously, the minimum base capacity required to run Amazon Redshift Serverless was 32 RPUs. With the new lower base capacity minimum of 8 RPUs, you now have even more flexibility to a support diverse set of workloads of small to large complexity based on your price performance requirements. You can increment or decrement the RPU in units of 8 RPUs.<br /> <br /> Amazon Redshift Serverless allows you to run and scale analytics without having to provision and manage data warehouse clusters. With Amazon Redshift Serverless, all users, including data analysts, developers, and data scientists, can use Amazon Redshift to get insights from data in seconds. With the new lower capacity configuration, you can use Amazon Redshift Serverless for production environments, test and development environments at an optimal price point when a workload needs a small amount of compute.<br /> <br /> To get started, see the Amazon Redshift Serverless <a href=\"https://aws.amazon.com/redshift/redshift-serverless/\" target=\"_blank\">feature page</a>, <a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-serverless.html\" target=\"_blank\">user documentation</a>, and <a href=\"https://docs.aws.amazon.com/redshift-serverless/latest/APIReference/Welcome.html\" target=\"_blank\">API Reference</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Redshift now allows you to get started with Amazon Redshift Serverless with a lower data warehouse <a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/serverless-capacity.html\" target=\"_blank\">base capacity configuration</a> of 8 Redshift Processing Units (RPUs) in the AWS Asia Pacific (Mumbai) region. Amazon Redshift Serverless measures data warehouse capacity in RPUs, and you pay only for the duration of workloads you run in RPU-hours on a per-second basis. Previously, the minimum base capacity required to run Amazon Redshift Serverless was 32 RPUs. With the new lower base capacity minimum of 8 RPUs, you now have even more flexibility to a support diverse set of workloads of small to large complexity based on your price performance requirements. You can increment or decrement the RPU in units of 8 RPUs.<br /> <br /> Amazon Redshift Serverless allows you to run and scale analytics without having to provision and manage data warehouse clusters. With Amazon Redshift Serverless, all users, including data analysts, developers, and data scientists, can use Amazon Redshift to get insights from data in seconds. With the new lower capacity configuration, you can use Amazon Redshift Serverless for production environments, test and development environments at an optimal price point when a workload needs a small amount of compute.<br /> <br /> To get started, see the Amazon Redshift Serverless <a href=\"https://aws.amazon.com/redshift/redshift-serverless/\" target=\"_blank\">feature page</a>, <a href=\"https://docs.aws.amazon.com/redshift/latest/mgmt/working-with-serverless.html\" target=\"_blank\">user documentation</a>, and <a href=\"https://docs.aws.amazon.com/redshift-serverless/latest/APIReference/Welcome.html\" target=\"_blank\">API Reference</a>.<br /> &nbsp;</p>"}, "published": "Tue, 25 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 25, 17, 0, 0, 1, 177, 0], "tags": [{"term": "marketing:marchitecture/analytics,general:products/amazon-redshift", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-redshift-serverless-lower-base-capacity-mumbai/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-redshift-serverless-lower-base-capacity-mumbai/"}
{"id": "e8f3910ad766d03bbfc5b9d3208646cc53e7c643", "guidislink": false, "title": "Amazon Aurora now provides additional monitoring information during upgrades", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Aurora now provides additional monitoring information during upgrades"}, "summary": "<p>Amazon Aurora now provides additional granular monitoring information during upgrades for enhanced observability. Customers can use the additional granularity shared in Amazon Aurora Events to stay informed and better manage their database upgrades.<br /> <br /> Customers upgrade their database version, operating system, and/or other components containing security, compliance, and functional enhancements. When applying upgrades, Aurora will now emit additional messages in Aurora Events and indicate when the database cluster is online and when it is not. For database minor version and patch upgrades, customers can use the messages to get additional granular insights about the exact downtime incurred for their database including the number of connections preserved during the upgrade. To learn more about how to monitor your upgrade process, you can view the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_Monitor_Logs_Events.html\" target=\"_blank\">technical documentation</a>.<br /> <br /> Amazon Aurora is designed for unparalleled high performance and availability at global scale with full MySQL and PostgreSQL compatibility. It provides built-in security, continuous backups, serverless compute, up to 15 read replicas, automated multi-Region replication, and integrations with other AWS services. You can get started by launching a new Amazon Aurora DB instance directly from the <a href=\"https://console.aws.amazon.com/rds/home\" target=\"_blank\">AWS Console</a> or the <a href=\"https://docs.aws.amazon.com/cli/latest/reference/rds/create-db-instance.html\" target=\"_blank\">AWS CLI</a>. To get started with Amazon Aurora, take a look at our <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_GettingStartedAurora.html\" target=\"_blank\">getting started page</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Aurora now provides additional granular monitoring information during upgrades for enhanced observability. Customers can use the additional granularity shared in Amazon Aurora Events to stay informed and better manage their database upgrades.<br /> <br /> Customers upgrade their database version, operating system, and/or other components containing security, compliance, and functional enhancements. When applying upgrades, Aurora will now emit additional messages in Aurora Events and indicate when the database cluster is online and when it is not. For database minor version and patch upgrades, customers can use the messages to get additional granular insights about the exact downtime incurred for their database including the number of connections preserved during the upgrade. To learn more about how to monitor your upgrade process, you can view the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_Monitor_Logs_Events.html\" target=\"_blank\">technical documentation</a>.<br /> <br /> Amazon Aurora is designed for unparalleled high performance and availability at global scale with full MySQL and PostgreSQL compatibility. It provides built-in security, continuous backups, serverless compute, up to 15 read replicas, automated multi-Region replication, and integrations with other AWS services. You can get started by launching a new Amazon Aurora DB instance directly from the <a href=\"https://console.aws.amazon.com/rds/home\" target=\"_blank\">AWS Console</a> or the <a href=\"https://docs.aws.amazon.com/cli/latest/reference/rds/create-db-instance.html\" target=\"_blank\">AWS CLI</a>. To get started with Amazon Aurora, take a look at our <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/CHAP_GettingStartedAurora.html\" target=\"_blank\">getting started page</a>.</p>"}, "published": "Tue, 25 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 25, 17, 0, 0, 1, 177, 0], "tags": [{"term": "marketing:marchitecture/databases,general:products/aws-govcloud-us,general:products/amazon-aurora", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-aurora-monitoring-information-upgrades"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-aurora-monitoring-information-upgrades"}
{"id": "543b937c454d7044d315a6e38d7182b9c7976b4b", "guidislink": false, "title": "Amazon EC2 C6a instances now available in additional regions", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon EC2 C6a instances now available in additional regions"}, "summary": "<p>Starting today, the general-purpose Amazon EC2 C6a instances are now available in Asia Pacific (Hong Kong) region. C6a instances are powered by third-generation AMD EPYC processors with a maximum frequency of 3.6 GHz. C6a instances deliver up to 15% better price performance than comparable C5a instances. C6a instances offer 10% lower cost than comparable x86-based EC2 instances. These instances are built on the <a href=\"https://aws.amazon.com/ec2/nitro/\" target=\"_blank\">AWS Nitro System</a>, a combination of dedicated hardware and lightweight hypervisor that delivers practically all of the compute and memory resources of the host hardware to your instances for better overall performance and security.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Starting today, the general-purpose Amazon EC2 C6a instances are now available in Asia Pacific (Hong Kong) region. C6a instances are powered by third-generation AMD EPYC processors with a maximum frequency of 3.6 GHz. C6a instances deliver up to 15% better price performance than comparable C5a instances. C6a instances offer 10% lower cost than comparable x86-based EC2 instances. These instances are built on the <a href=\"https://aws.amazon.com/ec2/nitro/\" target=\"_blank\">AWS Nitro System</a>, a combination of dedicated hardware and lightweight hypervisor that delivers practically all of the compute and memory resources of the host hardware to your instances for better overall performance and security.</p>"}, "published": "Tue, 25 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 25, 17, 0, 0, 1, 177, 0], "tags": [{"term": "marketing:marchitecture/compute,general:products/amazon-ec2", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-ec2-c6a-instances-in-additional-regions"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-ec2-c6a-instances-in-additional-regions"}
{"id": "201acb4f22d24a8fb399fd993e92e6f12143f3bf", "guidislink": false, "title": "AWS CodeBuild supports Arm-based workloads using AWS Graviton3", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "AWS CodeBuild supports Arm-based workloads using AWS Graviton3"}, "summary": "<p>AWS CodeBuild\u2019s support for Arm-based workloads now run on AWS Graviton3 without any additional configuration.<br /> <br /> In February 2021, CodeBuild launched support for native Arm builds on the second generation of AWS Graviton processors. Support for this platform allows customers to build and test on Arm without the need to emulate or cross-compile. Now, CodeBuild customers targeting Arm benefit from the enhanced capabilities of AWS Graviton3 processors. The upgrade delivers up to <a href=\"https://aws.amazon.com/blogs/aws/new-amazon-ec2-c7g-instances-powered-by-aws-graviton3-processors/\" target=\"_blank\">25% higher performance over Graviton2 processors</a>. Graviton3 also uses up to 60% less energy for the same performance as comparable EC2 instances, enabling customers to reduce their carbon footprint in the cloud.<br /> <br /> CodeBuild\u2019s support for Arm using Graviton3 is now available in: US East (N. Virginia), US East (Ohio), US West (Oregon), US West (N. California), Europe (Ireland), Europe (Frankfurt), Europe (London), Europe (Stockholm), Europe (Spain), Asia Pacific (Tokyo), Asia Pacific (Mumbai), Asia Pacific (Hyderabad), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Canada (Central).<br /> <br /> To learn more about CodeBuild\u2019s support for Arm, please visit our <a href=\"https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-compute-types.html\" target=\"_blank\">documentation</a>. To learn more about how to get started, visit the <a href=\"https://aws.amazon.com/codebuild/\" target=\"_blank\">AWS CodeBuild</a> product page.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>AWS CodeBuild\u2019s support for Arm-based workloads now run on AWS Graviton3 without any additional configuration.<br /> <br /> In February 2021, CodeBuild launched support for native Arm builds on the second generation of AWS Graviton processors. Support for this platform allows customers to build and test on Arm without the need to emulate or cross-compile. Now, CodeBuild customers targeting Arm benefit from the enhanced capabilities of AWS Graviton3 processors. The upgrade delivers up to <a href=\"https://aws.amazon.com/blogs/aws/new-amazon-ec2-c7g-instances-powered-by-aws-graviton3-processors/\" target=\"_blank\">25% higher performance over Graviton2 processors</a>. Graviton3 also uses up to 60% less energy for the same performance as comparable EC2 instances, enabling customers to reduce their carbon footprint in the cloud.<br /> <br /> CodeBuild\u2019s support for Arm using Graviton3 is now available in: US East (N. Virginia), US East (Ohio), US West (Oregon), US West (N. California), Europe (Ireland), Europe (Frankfurt), Europe (London), Europe (Stockholm), Europe (Spain), Asia Pacific (Tokyo), Asia Pacific (Mumbai), Asia Pacific (Hyderabad), Asia Pacific (Seoul), Asia Pacific (Singapore), Asia Pacific (Sydney), Canada (Central).<br /> <br /> To learn more about CodeBuild\u2019s support for Arm, please visit our <a href=\"https://docs.aws.amazon.com/codebuild/latest/userguide/build-env-ref-compute-types.html\" target=\"_blank\">documentation</a>. To learn more about how to get started, visit the <a href=\"https://aws.amazon.com/codebuild/\" target=\"_blank\">AWS CodeBuild</a> product page.<br /> &nbsp;</p>"}, "published": "Tue, 25 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 25, 17, 0, 0, 1, 177, 0], "tags": [{"term": "marketing:marchitecture/developer-tools,general:products/aws-codebuild", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-codebuild-arm-based-workloads-graviton3/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/aws-codebuild-arm-based-workloads-graviton3/"}
{"id": "60f0aa9d02f3198ee92cb6e15c119b123d935cea", "guidislink": false, "title": "Amazon ElastiCache supports M7g and R7g Graviton3-based nodes in additional AWS regions", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon ElastiCache supports M7g and R7g Graviton3-based nodes in additional AWS regions"}, "summary": "<p>Amazon ElastiCache now supports Graviton3-based M7g and R7g node families. ElastiCache Graviton3 nodes deliver improved price-performance compared to Graviton2. As an example, when running ElastiCache for Redis on an R7g.4xlarge node, you can achieve up to 28% increased throughput (read and write operations per second) and up to 21% improved P99 latency, compared to running on R6g.4xlarge. In addition, these nodes deliver up to 25% higher networking bandwidth.<br /> <br /> The M7g and R7g nodes are now available for Amazon ElastiCache in the following AWS regions: US East (N. Virginia and Ohio), US West (Oregon and N. California), Canada (Central), South America (Sao Paolo), Europe (Ireland, Frankfurt, London, Stockholm, Spain and Paris (m7g only)), Asia Pacific (Tokyo, Sydney, Mumbai, Hyderabad, Seoul and Singapore) regions. For complete information on pricing and regional availability, please refer to the <a href=\"https://aws.amazon.com/elasticache/pricing/\" target=\"_blank\">Amazon ElastiCache pricing page</a>. To get started, create a new cluster or upgrade to Graviton3 using the <a href=\"https://console.aws.amazon.com/elasticache/\" target=\"_blank\">AWS Management Console</a>, and get more <a href=\"https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheNodes.SupportedTypes.html\" target=\"_blank\">information</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon ElastiCache now supports Graviton3-based M7g and R7g node families. ElastiCache Graviton3 nodes deliver improved price-performance compared to Graviton2. As an example, when running ElastiCache for Redis on an R7g.4xlarge node, you can achieve up to 28% increased throughput (read and write operations per second) and up to 21% improved P99 latency, compared to running on R6g.4xlarge. In addition, these nodes deliver up to 25% higher networking bandwidth.<br /> <br /> The M7g and R7g nodes are now available for Amazon ElastiCache in the following AWS regions: US East (N. Virginia and Ohio), US West (Oregon and N. California), Canada (Central), South America (Sao Paolo), Europe (Ireland, Frankfurt, London, Stockholm, Spain and Paris (m7g only)), Asia Pacific (Tokyo, Sydney, Mumbai, Hyderabad, Seoul and Singapore) regions. For complete information on pricing and regional availability, please refer to the <a href=\"https://aws.amazon.com/elasticache/pricing/\" target=\"_blank\">Amazon ElastiCache pricing page</a>. To get started, create a new cluster or upgrade to Graviton3 using the <a href=\"https://console.aws.amazon.com/elasticache/\" target=\"_blank\">AWS Management Console</a>, and get more <a href=\"https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/CacheNodes.SupportedTypes.html\" target=\"_blank\">information</a>.<br /> &nbsp;</p>"}, "published": "Tue, 25 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 25, 17, 0, 0, 1, 177, 0], "tags": [{"term": "marketing:marchitecture/databases,general:products/amazon-elasticache", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-elasticache-m7g-r7g-graviton3-nodes-aws-regions/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-elasticache-m7g-r7g-graviton3-nodes-aws-regions/"}
{"id": "f6faea1695d01933a5eb4f8cd012250c09370e93", "guidislink": false, "title": "Amazon Time Sync Service expands microsecond-accurate time to 27 EC2 instance types", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Time Sync Service expands microsecond-accurate time to 27 EC2 instance types"}, "summary": "<p>The Amazon Time Sync Service now supports clock synchronization within microseconds of UTC on 27 additional Amazon Elastic Compute Cloud (Amazon EC2) instance types in supported regions, including all C7gd, M7gd, and R7gd instances.<br /> <br /> Built on Amazon's proven network infrastructure and the <a href=\"https://aws.amazon.com/ec2/nitro/\" target=\"_blank\">AWS Nitro System</a>, customers can now access local, GPS-disciplined reference clocks on additional EC2 instance types. These clocks can be used to more easily order application events, measure 1-way network latency, increase distributed application transaction speed, and incorporate in-region and cross-region scalability features while also simultaneously simplifying technical designs. Additionally, you can audit your clock accuracy from your instance to monitor the expected microsecond-range accuracy. Customers already using the Amazon Time Sync Service on these newly supported instance types will see improved clock accuracy automatically, without needing to adjust their AMI or NTP client settings. Customers can also use standard PTP clients and configure a PTP Hardware Clock (PHC) to get the best accuracy possible. Both NTP and PTP can be used without needing any updates to VPC configurations.<br /> <br /> Amazon Time Sync with microsecond-accurate time is available in US East (N. Virginia) and the Tokyo regions on all R7g as well as C7i, M7i, R7i, C7a, M7a, R7a, M7g, C7gd, R7gd, and M7gd instance types. We will be expanding support to additional AWS Regions. There is no additional charge for using this service.<br /> <br /> Instructions to configure, and more information on the Amazon Time Sync Service, are available in <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-time.html\" target=\"_blank\">the EC2 User Guide</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>The Amazon Time Sync Service now supports clock synchronization within microseconds of UTC on 27 additional Amazon Elastic Compute Cloud (Amazon EC2) instance types in supported regions, including all C7gd, M7gd, and R7gd instances.<br /> <br /> Built on Amazon's proven network infrastructure and the <a href=\"https://aws.amazon.com/ec2/nitro/\" target=\"_blank\">AWS Nitro System</a>, customers can now access local, GPS-disciplined reference clocks on additional EC2 instance types. These clocks can be used to more easily order application events, measure 1-way network latency, increase distributed application transaction speed, and incorporate in-region and cross-region scalability features while also simultaneously simplifying technical designs. Additionally, you can audit your clock accuracy from your instance to monitor the expected microsecond-range accuracy. Customers already using the Amazon Time Sync Service on these newly supported instance types will see improved clock accuracy automatically, without needing to adjust their AMI or NTP client settings. Customers can also use standard PTP clients and configure a PTP Hardware Clock (PHC) to get the best accuracy possible. Both NTP and PTP can be used without needing any updates to VPC configurations.<br /> <br /> Amazon Time Sync with microsecond-accurate time is available in US East (N. Virginia) and the Tokyo regions on all R7g as well as C7i, M7i, R7i, C7a, M7a, R7a, M7g, C7gd, R7gd, and M7gd instance types. We will be expanding support to additional AWS Regions. There is no additional charge for using this service.<br /> <br /> Instructions to configure, and more information on the Amazon Time Sync Service, are available in <a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-time.html\" target=\"_blank\">the EC2 User Guide</a>.</p>"}, "published": "Tue, 25 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 25, 17, 0, 0, 1, 177, 0], "tags": [{"term": "marketing:marchitecture/compute", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-time-sync-service-microsecond-27-ec2-types/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-time-sync-service-microsecond-27-ec2-types/"}
{"id": "a24466d0e4ab8ed9c1dcf3dd79b4beef4baccce5", "guidislink": false, "title": "Amazon RDS for MySQL announces Extended Support minor 5.7.44-RDS.20240529", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon RDS for MySQL announces Extended Support minor 5.7.44-RDS.20240529"}, "summary": "<p><a href=\"https://aws.amazon.com/rds/mysql/\" target=\"_blank\">Amazon Relational Database Service (RDS)</a> for MySQL announces Amazon RDS Extended Support minor version 5.7.44-RDS.20240529. We recommend that you upgrade to this version to fix known security vulnerabilities and bugs in prior versions of MySQL. Learn more about the bug fixes and patches in this version in the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MySQL.Concepts.VersionMgmt.html#mysql-extended-support-releases\" target=\"_blank\">Amazon RDS User Guide</a>.<br /> <br /> Amazon RDS Extended Support provides you more time, up to three years, to upgrade to a new major version to help you meet your business requirements. During Extended Support, Amazon RDS will provide critical security and bug fixes for your MySQL on Aurora and RDS after the community ends support for a major version. You can run your MySQL databases on Amazon RDS with Extended Support for up to three years beyond a major version\u2019s end of standard support date. Learn more about Extended Support in the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/extended-support.html\" target=\"_blank\">Amazon RDS User Guide</a> and the <a href=\"https://aws.amazon.com/rds/mysql/pricing/#faqs:~:text=How%20can%20I%20estimate%20my%20RDS%20Extended%20Support%20charges%3F\" target=\"_blank\">Pricing FAQs</a>.<br /> <br /> Amazon RDS for MySQL makes it simple to set up, operate, and scale MySQL deployments in the cloud. See <a href=\"https://aws.amazon.com/rds/mysql/pricing/\" target=\"_blank\">Amazon RDS for MySQL Pricing</a> for pricing details and regional availability. Create or update a fully managed Amazon RDS database in the <a href=\"https://console.aws.amazon.com/rds/home\" target=\"_blank\">Amazon RDS Management Console</a>.<br /> &nbsp;</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://aws.amazon.com/rds/mysql/\" target=\"_blank\">Amazon Relational Database Service (RDS)</a> for MySQL announces Amazon RDS Extended Support minor version 5.7.44-RDS.20240529. We recommend that you upgrade to this version to fix known security vulnerabilities and bugs in prior versions of MySQL. Learn more about the bug fixes and patches in this version in the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/MySQL.Concepts.VersionMgmt.html#mysql-extended-support-releases\" target=\"_blank\">Amazon RDS User Guide</a>.<br /> <br /> Amazon RDS Extended Support provides you more time, up to three years, to upgrade to a new major version to help you meet your business requirements. During Extended Support, Amazon RDS will provide critical security and bug fixes for your MySQL on Aurora and RDS after the community ends support for a major version. You can run your MySQL databases on Amazon RDS with Extended Support for up to three years beyond a major version\u2019s end of standard support date. Learn more about Extended Support in the <a href=\"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/extended-support.html\" target=\"_blank\">Amazon RDS User Guide</a> and the <a href=\"https://aws.amazon.com/rds/mysql/pricing/#faqs:~:text=How%20can%20I%20estimate%20my%20RDS%20Extended%20Support%20charges%3F\" target=\"_blank\">Pricing FAQs</a>.<br /> <br /> Amazon RDS for MySQL makes it simple to set up, operate, and scale MySQL deployments in the cloud. See <a href=\"https://aws.amazon.com/rds/mysql/pricing/\" target=\"_blank\">Amazon RDS for MySQL Pricing</a> for pricing details and regional availability. Create or update a fully managed Amazon RDS database in the <a href=\"https://console.aws.amazon.com/rds/home\" target=\"_blank\">Amazon RDS Management Console</a>.<br /> &nbsp;</p>"}, "published": "Tue, 25 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 25, 17, 0, 0, 1, 177, 0], "tags": [{"term": "general:products/amazon-rds,marketing:marchitecture/databases", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-rds-mysql-extended-support-minor-5/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-rds-mysql-extended-support-minor-5/"}
{"id": "4942277e4250fdaf35e5ab0ae3f18d04c7ccd035", "guidislink": false, "title": "Amazon Redshift Concurrency Scaling is now available in three additional regions", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Amazon Redshift Concurrency Scaling is now available in three additional regions"}, "summary": "<p>Amazon Redshift Concurrency Scaling is now available in the AWS Europe (Zurich), Europe (Spain), and Middle East (UAE) regions.<br /> <br /> Amazon Redshift Concurrency Scaling elastically scales query processing power to provide consistently fast performance for hundreds of concurrent queries. Concurrency Scaling resources are added to your Redshift cluster transparently in seconds, as concurrency increases, to process queries without wait time. Amazon Redshift customers with an active Redshift cluster earn up to one hour of free Concurrency Scaling credits, which is sufficient for the concurrency needs of most customers. Concurrency scaling allows you to specify usage control providing customers with predictability in their month-to-month cost, even during periods of fluctuating analytical demand.<br /> <br /> To enable Concurrency Scaling, set the Concurrency Scaling Mode to Auto in your <a href=\"http://console.amazonaws.cn/\" target=\"_blank\">Amazon Web Services Management Console</a>. You can allocate Concurrency Scaling usage to specific user groups and workloads, control the number of Concurrency Scaling clusters that can be used, and monitor Cloudwatch performance and usage metrics.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p>Amazon Redshift Concurrency Scaling is now available in the AWS Europe (Zurich), Europe (Spain), and Middle East (UAE) regions.<br /> <br /> Amazon Redshift Concurrency Scaling elastically scales query processing power to provide consistently fast performance for hundreds of concurrent queries. Concurrency Scaling resources are added to your Redshift cluster transparently in seconds, as concurrency increases, to process queries without wait time. Amazon Redshift customers with an active Redshift cluster earn up to one hour of free Concurrency Scaling credits, which is sufficient for the concurrency needs of most customers. Concurrency scaling allows you to specify usage control providing customers with predictability in their month-to-month cost, even during periods of fluctuating analytical demand.<br /> <br /> To enable Concurrency Scaling, set the Concurrency Scaling Mode to Auto in your <a href=\"http://console.amazonaws.cn/\" target=\"_blank\">Amazon Web Services Management Console</a>. You can allocate Concurrency Scaling usage to specific user groups and workloads, control the number of Concurrency Scaling clusters that can be used, and monitor Cloudwatch performance and usage metrics.</p>"}, "published": "Mon, 24 Jun 2024 19:00:00 GMT", "published_parsed": [2024, 6, 24, 19, 0, 0, 0, 176, 0], "tags": [{"term": "marketing:marchitecture/analytics,general:products/amazon-redshift", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-redshift-concurrency-scaling-additional-regions"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/amazon-redshift-concurrency-scaling-additional-regions"}
{"id": "f5f32e47d7d6d8154da7ca48efa8d8c090447ab1", "guidislink": false, "title": "Knowledge Bases for Amazon Bedrock now offers observability logs", "title_detail": {"type": "text/plain", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "Knowledge Bases for Amazon Bedrock now offers observability logs"}, "summary": "<p><a href=\"https://aws.amazon.com/bedrock/knowledge-bases/\" target=\"_blank\">Knowledge Bases</a> for Amazon Bedrock is a fully managed Retrieval-Augmented Generation (RAG) capability that allows you to connect foundation models (FMs) to internal company data sources to deliver relevant and accurate responses. Knowledge Bases now supports observability, offering log delivery choice through CloudWatch, S3 buckets, and Firehose streams. This capability provides enhanced visibility and timely insights into the execution of knowledge ingestion steps.<br /> <br /> Previously, Knowledge Bases provided basic statistics regarding content ingestion. However, this new feature offers more insights on the ingestion process, indicating whether each document was successfully processed or encountered failures. Having comprehensive insights in a timely manner ensure customers can promptly determine when their documents are ready for use with the Retrieve and RetrieveAndGenerate API calls.</p> \n<p>This capability is supported in the all AWS Regions where Knowledge Bases is available. To learn more about these features and how to get started, refer to the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\" target=\"_blank\">Knowledge Bases for Amazon Bedrock documentation</a> and visit the <a href=\"https://console.aws.amazon.com/bedrock/\" target=\"_blank\">Amazon Bedrock console</a>.</p>", "summary_detail": {"type": "text/html", "language": null, "base": "https://aws.amazon.com/about-aws/whats-new/recent/feed/", "value": "<p><a href=\"https://aws.amazon.com/bedrock/knowledge-bases/\" target=\"_blank\">Knowledge Bases</a> for Amazon Bedrock is a fully managed Retrieval-Augmented Generation (RAG) capability that allows you to connect foundation models (FMs) to internal company data sources to deliver relevant and accurate responses. Knowledge Bases now supports observability, offering log delivery choice through CloudWatch, S3 buckets, and Firehose streams. This capability provides enhanced visibility and timely insights into the execution of knowledge ingestion steps.<br /> <br /> Previously, Knowledge Bases provided basic statistics regarding content ingestion. However, this new feature offers more insights on the ingestion process, indicating whether each document was successfully processed or encountered failures. Having comprehensive insights in a timely manner ensure customers can promptly determine when their documents are ready for use with the Retrieve and RetrieveAndGenerate API calls.</p> \n<p>This capability is supported in the all AWS Regions where Knowledge Bases is available. To learn more about these features and how to get started, refer to the <a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html\" target=\"_blank\">Knowledge Bases for Amazon Bedrock documentation</a> and visit the <a href=\"https://console.aws.amazon.com/bedrock/\" target=\"_blank\">Amazon Bedrock console</a>.</p>"}, "published": "Mon, 24 Jun 2024 17:00:00 GMT", "published_parsed": [2024, 6, 24, 17, 0, 0, 0, 176, 0], "tags": [{"term": "general:products/amazon-machine-learning,marketing:marchitecture/artificial-intelligence,general:products/amazon-bedrock", "scheme": null, "label": null}], "authors": [{"email": "aws@amazon.com"}], "author": "aws@amazon.com", "author_detail": {"email": "aws@amazon.com"}, "links": [{"rel": "alternate", "type": "text/html", "href": "https://aws.amazon.com/about-aws/whats-new/2024/06/knowledge-bases-amazon-bedrock-observability-logs/"}], "link": "https://aws.amazon.com/about-aws/whats-new/2024/06/knowledge-bases-amazon-bedrock-observability-logs/"}
